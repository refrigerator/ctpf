0
"The metabolic world of Escherichia coli is not small. To elucidate the organizational and evolutionary principles of the metabolism of living organisms, recent studies have addressed the graph-theoretic analysis of large biochemical networks responsible for the synthesis and degradation of cellular building blocks [Jeong, H., Tombor, B., Albert, R., Oltvai, Z. N. & Barabási, A. L. (2000) Nature 407, 651-654; Wagner, A. & Fell, D. A. (2001) Proc. R. Soc. London Ser. B 268, 1803-1810; and Ma, H.-W. & Zeng, A.-P. (2003) Bioinformatics 19, 270-277]. In such studies, the global properties of the network are computed by considering enzymatic reactions as links between metabolites. However, the pathways computed in this manner do not conserve their structural moieties and therefore do not correspond to biochemical pathways on the traditional metabolic map. In this work, we reassessed earlier results by digitizing carbon atomic traces in metabolic reactions annotated for Escherichia coli. Our analysis revealed that the average path length of its metabolism is much longer than previously thought and that the metabolic world of this organism is not small in terms of biosynthesis and degradation. "
"Reverse Engineering of Biological ComplexityAdvanced technologies and biology have extremely different physical implementations, but they are far more alike in systems-level organization than is widely appreciated. Convergent evolution in both domains produces modular architectures that are composed of elaborate hierarchies of protocols and layers of feedback regulation, are driven by demand for robustness to uncertain environments, and use often imprecise components. This complexity may be largely hidden in idealized laboratory settings and in normal operation, becoming conspicuous only when contributing to rare cascading failures. These puzzling and paradoxical features are neither accidental nor artificial, but derive from a deep and necessary interplay between complexity and robustness, modularity, feedback, and fragility. This review describes insights from engineering theory and practice that can shed some light on biological complexity."
"Exploring complex networksThe study of networks pervades all of science, from neurobiology to statistical physics. The most basic issues are structural: how does one characterize the wiring diagram of a food web or the Internet or the metabolic network of the bacterium Escherichia coli? Are there any unifying principles underlying their topology? From the perspective of nonlinear dynamics, we would also like to understand how an enormous network of interacting dynamical systems — be they neurons, power stations or lasers — will behave collectively, given their individual dynamics and coupling architecture. Researchers are only now beginning to unravel the structure and dynamics of complex networks."
"Wrestling with pleiotropy: genomic and topological analysis of the yeast gene expression network.The vast majority (>95%) of single-gene mutations in yeast affect not only the expression of the mutant gene, but also the expression of many other genes. These data suggest the presence of a previously uncharacterized ""gene expression network""--a set of interactions between genes which dictate gene expression in the native cell environment. Here, we quantitatively analyze the gene expression network revealed by microarray expression data from 273 different yeast gene deletion mutants.(1) We find that gene expression interactions form a robust, error-tolerant ""scale-free"" network, similar to metabolic pathways(2) and artificial networks such as power grids and the internet.(3-5) Because the connectivity between genes in the gene expression network is unevenly distributed, a scale-free organization helps make organisms resistant to the deleterious effects of mutation, and is thus highly adaptive. The existence of a gene expression network poses practical considerations for the study of gene function, since most mutant phenotypes are the result of changes in the expression of many genes. Using principles of scale-free network topology, we propose that fragmenting the gene expression network via ""genome-engineering"" may be a viable and practical approach to isolating gene function."
"Comparative assessment of large-scale data sets of protein-protein interactionsComprehensive protein protein interaction maps promise to reveal many aspects of the complex regulatory network underlying cellular function. Recently, large-scale approaches have predicted many new protein interactions in yeast. To measure their accuracy and potential as well as to identify biases, strengths and weaknesses, we compare the methods with each other and with a reference set of previously reported protein interactions."
"Navigation in a small worldIt is easier to find short chains between points in some networks than others. The small-world phenomenon — the principle that most of us are linked by short chains of acquaintances — was first investigated as a question in sociology1, 2 and is a feature of a range of networks arising in nature and technology3, 4, 5. Experimental study of the phenomenon1 revealed that it has two fundamental components: first, such short chains are ubiquitous, and second, individuals operating with purely local information are very adept at finding these chains. The first issue has been analysed2, 3, 4, and here I investigate the second by modelling how individuals can find short chains in a large social network."
"Random graphs with arbitrary degree distributions and their applications.Recent work on the structure of social networks and the internet has focused attention on graphs with distributions of vertex degree that are significantly different from the Poisson degree distributions that have been widely studied in the past. In this paper we develop in detail the theory of random graphs with arbitrary degree distributions. In addition to simple undirected, unipartite graphs, we examine the properties of directed and bipartite graphs. Among other results, we derive exact expressions for the position of the phase transition at which a giant component first forms, the mean component size, the size of the giant component if there is one, the mean number of vertices a certain distance away from a randomly chosen vertex, and the average vertex-vertex distance within a graph. We apply our theory to some real-world graphs, including the world-wide web and collaboration graphs of scientists and Fortune 1000 company directors. We demonstrate that in some cases random graphs with appropriate distributions of vertex degree predict with surprising accuracy the behavior of the real world, while in others there is a measurable discrepancy between theory and reality, perhaps indicating the presence of additional social structure in the network that is not captured by the random graph."
"Artificial gene networks for objective comparison of analysis algorithmsMotivation: Large-scale gene expression profiling generates data sets that are rich in observed features but poor in numbers of observations. The analysis of such data sets is a challenge that has been object of vigorous research. The algorithms in use for this purpose have been poorly documented and rarely compared objectively, posing a problem of uncertainty about the outcomes of the analyses. One way to objectively test such analysis algorithms is to apply them on computational gene network models for which the mechanisms are completely know.Results: We present a system that generates random artificial gene networks according to well-defined topological and kinetic properties. These are used to run in silico experiments simulating real laboratory microarray experiments. Noise with controlled properties is added to the simulation results several times emulating measurement replicates, before expression ratios are calculated.Availability: The data sets and kinetic models described here are available from http://www.vbi.vt.edu/~mendes/AGN/as biochemical dynamic models in SBML and Gepasi formats.Contact: mendes@vt.edu"
"The segment polarity network is a robust developmental moduleAll insects possess homologous segments, but segment specification differs radically among insect orders. In Drosophila, maternal morphogens control the patterned activation of gap genes, which encode transcriptional regulators that shape the patterned expression of pair-rule genes. This patterning cascade takes place before cellularization. Pair-rule gene products subsequently 'imprint' segment polarity genes with reiterated patterns, thus defining the primordial segments. This mechanism must be greatly modified in insect groups in which many segments emerge only after cellularization1. In beetles and parasitic wasps, for instance, pair-rule homologues are expressed in patterns consistent with roles during segmentation, but these patterns emerge within cellular fields2, 3, 4. In contrast, although in locusts pair-rule homologues may not control segmentation5, 6, some segment polarity genes and their interactions are conserved3, 7, 8, 9, 10. Perhaps segmentation is modular, with each module autonomously expressing a characteristic intrinsic behaviour in response to transient stimuli. If so, evolution could rearrange inputs to modules without changing their intrinsic behaviours. Here we suggest, using computer simulations, that the Drosophila segment polarity genes constitute such a module, and that this module is resistant to variations in the kinetic constants that govern its behaviour."
"Control of spatially heterogeneous and time-varying cellular reaction networks: a new summation law.A hallmark of a plethora of intracellular signaling pathways is the spatial separation of activation and deactivation processes that potentially results in precipitous gradients of activated proteins. The classical metabolic control analysis (MCA), which quantifies the influence of an individual process on a system variable as the control coefficient, cannot be applied to spatially separated protein networks. The present paper unravels the principles that govern the control over the fluxes and intermediate concentrations in spatially heterogeneous reaction networks. Our main results are two types of control summation theorems. The first type is a non-trivial generalization of the classical theorems to systems with spatially and temporally varying concentrations. In this generalization, the process of diffusion, which enters as the result of spatial concentration gradients, plays a role similar to other processes such as chemical reactions and membrane transport. The second summation theorem is completely novel. It states that the control by the membrane transport, the diffusion control coefficient multiplied by two, and a newly introduced control coefficient associated with changes in the spatial size of a system (e.g., cell), all add up to one and zero for the control over flux and concentration. Using a simple example of a kinase/phosphatase system in a spherical cell, we speculate that unless active mechanisms of intracellular transport are involved, the threshold cell size is limited by the diffusion control, when it is beginning to exceed the spatial control coefficient significantly."
"The evolutionary origin of complex featuresA long-standing challenge to evolutionary theory has been whether it can explain the origin of complex organismal features. We examined this issue using digital organisms—computer programs that self-replicate, mutate, compete and evolve. Populations of digital organisms often evolved the ability to perform complex logic functions requiring the coordinated execution of many genomic instructions. Complex functions evolved by building on simpler functions that had evolved earlier, provided that these were also selectively favoured. However, no particular intermediate stage was essential for evolving complex functions. The first genotypes able to perform complex functions differed from their non-performing parents by only one or two mutations, but differed from the ancestor by many mutations that were also crucial to the new functions. In some cases, mutations that were deleterious when they appeared served as stepping-stones in the evolution of complex features. These findings show how complex functions can originate by random mutation and natural selection."
"Early language acquisition: cracking the speech codeInfants learn language with remarkable speed, but how they do it remains a mystery. New data show that infants use computational strategies to detect the statistical and prosodic patterns in language input, and that this leads to the discovery of phonemes and words. Social interaction with another human being affects speech learning in a way that resembles communicative learning in songbirds. The brain's commitment to the statistical and prosodic patterns that are experienced early in life might help to explain the long-standing puzzle of why infants are better language learners than adults. Successful learning by infants, as well as constraints on that learning, are changing theories of language acquisition."
"Organization, development and function of complex brain networksRecent research has revealed general principles in the structural and functional organization of complex networks which are shared by various natural, social and technological systems. This review examines these principles as applied to the organization, development and function of complex brain networks. Specifically, we examine the structural properties of large-scale anatomical and functional brain networks and discuss how they might arise in the course of network growth and rewiring. Moreover, we examine the relationship between the structural substrate of neuroanatomy and more dynamic functional and effective connectivity patterns that underlie human cognition. We suggest that network analysis offers new fundamental insights into global and integrative aspects of brain function, including the origin of flexible and coherent cognitive states within the neural architecture."
"Motifs in brain networks.Complex brains have evolved a highly efficient network architecture whose structural connectivity is capable of generating a large repertoire of functional states. We detect characteristic network building blocks (structural and functional motifs) in neuroanatomical data sets and identify a small set of structural motifs that occur in significantly increased numbers. Our analysis suggests the hypothesis that brain networks maximize both the number and the diversity of functional motifs, while the repertoire of structural motifs remains small. Using functional motif number as a cost function in an optimization algorithm, we obtain network topologies that resemble real brain networks across a broad spectrum of structural measures, including small-world attributes. These results are consistent with the hypothesis that highly evolved neural architectures are organized to maximize functional repertoires and to support highly efficient integration of information."
"MOLECULAR MECHANISMS OF MAMMALIAN DNA REPAIR AND THE DNA DAMAGE CHECKPOINTS▪ Abstract  DNA damage is a relatively common event in the life of a cell and may lead to mutation, cancer, and cellular or organismic death. Damage to DNA induces several cellular responses that enable the cell either to eliminate or cope with the damage or to activate a programmed cell death process, presumably to eliminate cells with potentially catastrophic mutations. These DNA damage response reactions include: (a) removal of DNA damage and restoration of the continuity of the DNA duplex; (b) activation of a DNA damage checkpoint, which arrests cell cycle progression so as to allow for repair and prevention of the transmission of damaged or incompletely replicated chromosomes; (c) transcriptional response, which causes changes in the transcription profile that may be beneficial to the cell; and (d) apoptosis, which eliminates heavily damaged or seriously deregulated cells. DNA repair mechanisms include direct repair, base excision repair, nucleotide excision repair, double-strand break repair, and cross-link repair. The DNA damage checkpoints employ damage sensor proteins, such as ATM, ATR, the Rad17-RFC complex, and the 9-1-1 complex, to detect DNA damage and to initiate signal transduction cascades that employ Chk1 and Chk2 Ser/Thr kinases and Cdc25 phosphatases. The signal transducers activate p53 and inactivate cyclin-dependent kinases to inhibit cell cycle progression from G1 to S (the G1/S checkpoint), DNA replication (the intra-S checkpoint), or G2 to mitosis (the G2/M checkpoint). In this review the molecular mechanisms of DNA repair and the DNA damage checkpoints in mammalian cells are analyzed."
"The DNA double-strand break response pathway: becoming more BRCAish than ever.Breast carcinoma is the leading cause of cancer incidence, and second in cancer mortality to lung cancer, in women of the Western hemisphere. Germ line mutations in the breast cancer susceptibility gene, BRCA1, is responsible for half of all cases of hereditary breast cancer, which constitutes about 5-10% of all cases of breast cancer. Current hypothesis has ascribed a role for Brca1 in maintaining genomic stability, through its involvement in cellular response pathway to the DNA double-strand breaks (DSB). DNA DSB, which are the most deleterious form of DNA damage, are repaired through a series of coordinated steps embedded in a signal transduction pathway that ultimately ensure the elimination of potentially harmful mutations to the genome. This pathway can be crudely divided into a primary and secondary phase. The primary response phase is initiated by sensor proteins that activate transducer protein kinases Atm and Atr, which target downstream effector proteins, such as Chk1 and Chk2, to elicit the secondary response phase. Brca1 has been intimately linked with various aspects of this signaling pathway. However, the precise role of Brca1 in this process remains unclear. In this review, we will provide a simple model in an attempt to clarify the role of Brca1 during cellular response to DNA DSB."
"A Note on May Eve, Good Friday, and the Full Moon in Bulgakov's The Master and Margarita"
"Initiating cellular stress responses.The phosphoinositide 3-kinase related kinases (PIKKs) mediate responses to diverse stresses, including DNA double-strand breaks (DSBs), abnormal replication fork progression, the recognition of premature termination codons in mRNAs, and inadequate nutrient availability. Rigorous control of these kinases limits cellular damage and promotes cell viability in the presence of stress. Control mechanisms include the localization of PIKKs into multiprotein complexes at the sites of damage and mediation of protein-protein contacts such that substrates are allowed access to the PIKK catalytic domains."
"Membrane structure and interactions with protein and DNA in bacteriophage PRD1.Membranes are essential for selectively controlling the passage of molecules in and out of cells and mediating the response of cells to their environment. Biological membranes and their associated proteins present considerable difficulties for structural analysis. Although enveloped viruses have been imaged at about 9 A resolution by cryo-electron microscopy and image reconstruction, no detailed crystallographic structure of a membrane system has been described. The structure of the bacteriophage PRD1 particle, determined by X-ray crystallography at about 4 A resolution, allows the first detailed analysis of a membrane-containing virus. The architecture of the viral capsid and its implications for virus assembly are presented in the accompanying paper. Here we show that the electron density also reveals the icosahedral lipid bilayer, beneath the protein capsid, enveloping the viral DNA. The viral membrane contains about 26,000 lipid molecules asymmetrically distributed between the membrane leaflets. The inner leaflet is composed predominantly of zwitterionic phosphatidylethanolamine molecules, facilitating a very close interaction with the viral DNA, which we estimate to be packaged to a pressure of about 45 atm, factors that are likely to be important during membrane-mediated DNA translocation into the host cell. In contrast, the outer leaflet is enriched in phosphatidylglycerol and cardiolipin, which show a marked lateral segregation within the icosahedral asymmetric unit. In addition, the lipid headgroups show a surprising degree of order."
"CK2 constitutively associates with and phosphorylates chicken erythroid ankyrin and regulates its ability to bind to spectrin.Previous analyses have shown that the phosphorylation state of chicken erythroid ankyrin regulates its association with the spectrin cytoskeleton in vivo. Treatment of erythroid cells with serine and threonine phosphatase inhibitors stimulates the hyperphosphorylation of ankyrin and its dissociation from spectrin. In this study, we demonstrate that a kinase that directs the phosphorylation of ankyrin in vivo coprecipitates with ankyrin-containing complexes and has properties identical to CK2. Studies using CK2-specific inhibitors have indicated that all of the phosphorylation events associated with erythroid ankyrin in vivo are CK2 dependent. Furthermore, inhibitor studies combined with in vitro binding analyses have indicated that the phosphorylation of erythroid ankyrin by CK2 regulates its ability to associate with spectrin. Additional analyses revealed that CK2 coprecipitates with ankyrin-3-containing complexes isolated from Madin Darby canine kidney epithelial cells and phosphorylates this epithelial ankyrin isoform in vivo. These results are the first demonstration of a kinase constitutively associating with the ankyrin-spectrin cytoskeleton in erythroid and kidney epithelial cells. This association provides a mechanism for rapidly reorganizing the membrane cytoskeleton in these cell types through the phosphorylation of ankyrin."
"Defining 'Intrinsic'Something could be round even if it were the only thing in the universe, unaccompanied by anything distinct from itself. Jaegwon Kim once suggested that we define an intrinsic property as one that can belong to something unaccompanied. Wrong: unaccompaniment itself is not intrinsic, yet it can belong to something unaccompanied. But there is a better Kim-style definition. Say that P is independent of accompaniment iff four different cases are possible: something accompanied may have P or lack P, something unaccompanied may have P or lack P. P is basic intrinsic iff (1) P and not-P are nondisjunctive and contingent, and (2) P is independent of accompaniment. Two things (actual or possible) are duplicates iff they have exactly the same basic intrinsic properties. P is intrinsic iff no two duplicates differ with respect to P."
"Diffusion on Complex Networks : A way to probe their large scale topological structuresA diffusion process on complex networks is introduced in order to uncover their large scale topological structures. This is achieved by focusing on the slowest decaying diffusive modes of the network. The proposed procedure is applied to real-world networks like a friendship network of known modular structure, and an Internet routing network. For the friendship network, its known structure is well reproduced. In case of the Internet, where the structure is far less well-known, one indeed finds a modular structure, and modules can roughly be associated with individual countries. Quantitatively the modular structure of the Internet manifests itself in an approximately 10 times larger participation ratio of its slowest decaying modes as compared to the null model -- a random scale-free network. The extreme edges of the Internet are found to correspond to Russian and US military sites."
"Topological Generalizations of network motifsBiological and technological networks contain patterns, termed network motifs, which occur far more often than in randomized networks. Network motifs were suggested to be elementary building blocks that carry out key functions in the network. It is of interest to understand how network motifs combine to form larger structures. To address this, we present a systematic approach to define 'motif generalizations': families of motifs of different sizes that share a common architectural theme. To define motif generalizations, we first define 'roles' in a subgraph according to structural equivalence. For example, the feedforward loop triad, a motif in transcription, neuronal and some electronic networks, has three roles, an input node, an output node and an internal node. The roles are used to define possible generalizations of the motif. The feedforward loop can have three simple generalizations, based on replicating each of the three roles and their connections. We present algorithms for efficiently detecting motif generalizations. We find that the transcription networks of bacteria and yeast display only one of the three generalizations, the multi-output feedforward generalization. In contrast, the neuronal network of "
"Collective dynamics of ‘small-world’ networksNetworks of coupled dynamical systems have been used to model biological oscillators1, 2, 3, 4, Josephson junction arrays5,6, excitable media7, neural networks8, 9, 10, spatial games11, genetic control networks12 and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon13,14 (popularly known as six degrees of separation15). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices."
"Comment on ""Network Motifs: Simple Building Blocks of Complex Networks"" and ""Superfamilies of Evolved and Designed Networks""10.1126/science.1099334"
"Network Motifs: Simple Building Blocks of Complex NetworksComplex networks are studied across many fields of science. To uncover their structural design principles, we defined “network motifs,” patterns of interconnections occurring in complex networks at numbers that are significantly higher than those in randomized networks. We found such motifs in networks from biochemistry, neurobiology, ecology, and engineering. The motifs shared by ecological food webs were distinct from the motifs shared by the genetic networks of Escherichia coli and Saccharomyces cerevisiae or from those found in the World Wide Web. Similar motifs were found in networks that perform information processing, even though they describe elements as different as biomolecules within a cell and synaptic connections between neurons in Caenorhabditis elegans. Motifs may thus define universal classes of networks. This approach may uncover the basic building blocks of most networks."
"Authoritative Sources in a Hyperlinked EnvironmentThe network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of “authorative” information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of “hub pages” that join them together in the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis."
Discovering authorities and hubs in different topological web graph structures
"The anatomy of a large-scale hypertextual Web search engineIn this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/ To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of Web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the Web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and Web proliferation, creating a Web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scale Web search engine — the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want."
Spectral Analysis of Protein-Protein Interactions in Drosophila melanogasterWithin a case study on the protein-protein interaction network (PIN) of Drosophila melanogaster we investigate the relation between the network's spectral properties and its structural features such as the prevalence of specific subgraphs or duplicate nodes as a result of its evolutionary history. The discrete part of the spectral density shows fingerprints of the PIN's topological features including a preference for loop structures. Duplicate nodes are another prominent feature of PINs and we discuss their representation in the PIN's spectrum as well as their biological implications.
"Spectra and eigenvectors of scale-free networks.We study the spectra and eigenvectors of the adjacency matrices of scale-free networks when bidirectional interaction is allowed, so that the adjacency matrix is real and symmetric. The spectral density shows an exponential decay around the center, followed by power-law long tails at both spectrum edges. The largest eigenvalue lambda1 depends on system size N as lambda1 approximately N1/4 for large N, and the corresponding eigenfunction is strongly localized at the hub, the vertex with largest degree. The component of the normalized eigenfunction at the hub is of order unity. We also find that the mass gap scales as N(-0.68)."
"Spectra of random graphs with given expected degreesIn the study of the spectra of power-law graphs, there are basically two competing approaches. One is to prove analogues of Wigner's semicircle law, whereas the other predicts that the eigenvalues follow a power-law distribution. Although the semicircle law and the power law have nothing in common, we will show that both approaches are essentially correct if one considers the appropriate matrices. We will prove that (under certain mild conditions) the eigenvalues of the (normalized) Laplacian of a random power-law graph follow the semicircle law, whereas the spectrum of the adjacency matrix of a power-law graph obeys the power law. Our results are based on the analysis of random graphs with given expected degrees and their relations to several key invariants. Of interest are a number of (new) values for the exponent β, where phase transitions for eigenvalue distributions occur. The spectrum distributions have direct implications to numerous graph algorithms such as, for example, randomized algorithms that involve rapidly mixing Markov chains."
"Functional discovery via a compendium of expression profiles.Ascertaining the impact of uncharacterized perturbations on the cell is a fundamental problem in biology. Here, we describe how a single assay can be used to monitor hundreds of different cellular functions simultaneously. We constructed a reference database or ""compendium"" of expression profiles corresponding to 300 diverse mutations and chemical treatments in S. cerevisiae, and we show that the cellular pathways affected can be determined by pattern matching, even among very subtle profiles. The utility of this approach is validated by examining profiles caused by deletions of uncharacterized genes: we identify and experimentally confirm that eight uncharacterized open reading frames encode proteins required for sterol metabolism, cell wall function, mitochondrial respiration, or protein synthesis. We also show that the compendium can be used to characterize pharmacological perturbations by identifying a novel target of the commonly used drug dyclonine."
Having Concepts: a Brief Refutation of the Twentieth Century
"Growing and navigating the small world Web by local contentCan we model the scale-free distribution of Web hypertext degree under realistic assumptions about the behavior of page authors? Can a Web crawler efficiently locate an unknown relevant page? These questions are receiving much attention due to their potential impact for understanding the structure of the Web and for building better search engines. Here I investigate the connection between the linkage and content topology of Web pages. The relationship between a text-induced distance metric and a link-based neighborhood probability distribution displays a phase transition between a region where linkage is not determined by content and one where linkage decays according to a power law. This relationship is used to propose a Web growth model that is shown to accurately predict the distribution of Web page degree, based on textual content and assuming only local knowledge of degree for existing pages. A qualitatively similar phase transition is found between linkage and semantic distance, with an exponential decay tail. Both relationships suggest that efficient paths can be discovered by decentralized Web navigation algorithms based on textual and/or categorical cues."
"The structure of scientific collaboration networksThe structure of scientific collaboration networks is investigated. Two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including MEDLINE (biomedical research), the Los Alamos e-Print Archive (physics), and NCSTRL (computer science). I show that these collaboration networks form “small worlds,” in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. I further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied."
"Classes of small-world networksWe study the statistical properties of a variety of diverse real-world networks. We present evidence of the occurrence of three classes of small-world networks: (a) scale-free networks, characterized by a vertex connectivity distribution that decays as a power law; (b) broad-scale networks, characterized by a connectivity distribution that has a power law regime followed by a sharp cutoff; and (c) single-scale networks, characterized by a connectivity distribution with a fast decaying tail. Moreover, we note for the classes of broad-scale and single-scale networks that there are constraints limiting the addition of new links. Our results suggest that the nature of such constraints may be the controlling factor for the emergence of different classes of networks."
"Rock-scissors-paper game on regular small-world networks The spatial rock-scissors-paper game (or cyclic Lotka-Volterra system) is extended to study how the spatiotemporal patterns are affected by the constructed backgrounds providing uniform number of neighbors (degree) at each site. On the square lattice this system exhibits a self-organizing pattern with equal concentration of the competing strategies (species). If the quenched background is constructed by substituting random links for the nearest neighbor bonds of a square lattice then a limit cycle occurs when the portion of random links exceeds a threshold value. This transition can also be observed if the standard link is replaced temporarily by a random one with a probability $P$ at each step of iteration. Above a second threshold value of $P$ the amplitude of global oscillation increases with time and finally the system reaches one of the homogeneous (absorbing) states. In this case the results of Monte Carlo simulations are compared with the predictions of the dynamical cluster technique evaluating all the configuration probabilities on one-, two-, four-, and six-site clusters."
"DNA damage checkpoint control in cells exposed to ionizing radiation.Damage induced in the DNA after exposure of cells to ionizing radiation activates checkpoint pathways that inhibit progression of cells through the G1 and G2 phases and induce a transient delay in the progression through S phase. Checkpoints together with repair and apoptosis are integrated in a circuitry that determines the ultimate response of a cell to DNA damage. Checkpoint activation typically requires sensors and mediators of DNA damage, signal transducers and effectors. Here, we review the current state of knowledge regarding mechanisms of checkpoint activation and proteins involved in the different steps of the process. Emphasis is placed on the role of ATM and ATR, as well on CHK1 and CHK2 kinases in checkpoint response. The roles of downstream effectors, such as P53 and the CDC25 family of proteins, are also described, and connections between repair and checkpoint activation are attempted. The role of checkpoints in genomic stability and the potential of improving the treatment of cancer by DNA damage inducing agents through checkpoint abrogation are also briefly outlined."
"Phosphorylation of SMC1 is a critical downstream event in the ATM-NBS1-BRCA1 pathway.The ATM protein kinase is activated by intermolecular autophosphorylation in response to DNA damage and initiates cellular signaling pathways that facilitate cell survival and reduce chromosomal breakage. Here, we show that NBS1 and BRCA1 are required for the recruitment of previously activated ATM to the sites of DNA breaks after ionizing irradiation, and that this recruitment is required for the phosphorylation of SMC1 by ATM. To explore the functional importance of SMC1 phosphorylation, murine cells were generated, in which the two damage-induced phosphorylation sites in SMC1 are mutated. Although these cells demonstrate normal phosphorylation and focus formation of ATM, NBS1, and BRCA1 proteins after IR, they exhibit a defective S-phase checkpoint, decreased survival, and increased chromosomal aberrations after DNA damage. These observations suggest that many of the abnormal stress responses seen in cells lacking ATM, NBS1, or BRCA1 result from a failure of ATM migration to sites of DNA breaks and a resultant lack of SMC1 phosphorylation."
"Role for ATM in DNA damage-induced phosphorylation of BRCA1.The human genetic disorder ataxia-telangiectasia is characterized by immunodeficiency, progressive cerebellar ataxia, radiosensitivity, cell cycle checkpoint defects, and cancer predisposition. The gene product [ataxia-telangiectasia mutation (ATM)] mutated in this syndrome is a component of the DNA damage detection pathway. Loss of ATM function in human and mouse cells causes defects in DNA repair and cell cycle checkpoint control and, not surprisingly, humans and mice with compromised ATM function are prone to cancers. An excess of breast cancer in the relatives of ataxia-telangiectasia patients has also been reported by epidemiological studies. Predisposition to breast and ovarian cancers is also observed in women with germline mutations in BRCA1, a tumor suppressor gene. BRCA1 is a nuclear protein with a cell cycle-regulated expression pattern and is hyperphosphorylated in response to DNA-damaging agents. Here we show that rapid ionizing radiation-induced in vivo phosphorylation of BRCA1 requires the presence of functional ATM protein. Furthermore, we show that ATM interacts with BRCA1, and this association is enhanced by radiation. We also demonstrate that BRCA1 is a substrate of ATM kinase in vitro and in vivo. Using phospho-specific antibodies against serines 1387, 1423, and 1457 of BRCA1, we demonstrate radiation-induced, ATM-dependent phosphorylation of BRCA1 at these sites. These findings show that BRCA1 is regulated by an ATM-dependent mechanism as a part of the cellular response to DNA damage. This interaction between ATM and BRCA1 argues in favor of the involvement of particular aspects of ATM function in breast cancer predisposition."
"DNA damage activates ATM through intermolecular autophosphorylation and dimer dissociation. The ATM protein kinase, mutations of which are associated with the human disease ataxia-telangiectasia, mediates responses to ionizing radiation in mammalian cells. Here we show that ATM is held inactive in unirradiated cells as a dimer or higher-order multimer, with the kinase domain bound to a region surrounding serine 1981 that is contained within the previously described 'FAT' domain. Cellular irradiation induces rapid intermolecular autophosphorylation of serine 1981 that causes dimer dissociation and initiates cellular ATM kinase activity. Most ATM molecules in the cell are rapidly phosphorylated on this site after doses of radiation as low as 0.5 Gy, and binding of a phosphospecific antibody is detectable after the introduction of only a few DNA double-strand breaks in the cell. Activation of the ATM kinase seems to be an initiating event in cellular responses to irradiation, and our data indicate that ATM activation is not dependent on direct binding to DNA strand breaks, but may result from changes in the structure of chromatin. "
"Topology and robustness in the Drosophila segment polarity network.A complex hierarchy of genetic interactions converts a single-celled Drosophila melanogaster egg into a multicellular embryo with 14 segments. Previously, von Dassow et al. reported that a mathematical model of the genetic interactions that defined the polarity of segments (the segment polarity network) was robust (von Dassow et al. 2000). As quantitative information about the system was unavailable, parameters were sampled randomly. A surprisingly large fraction of these parameter sets allowed the model to maintain and elaborate on the segment polarity pattern. This robustness is due to the positive feedback of gene products on their own expression, which induces individual cells in a model segment to adopt different stable expression states (bistability) corresponding to different cell types in the segment polarity pattern. A positive feedback loop will only yield multiple stable states when the parameters that describe it satisfy a particular inequality. By testing which random parameter sets satisfy these inequalities, I show that bistability is necessary to form the segment polarity pattern and serves as a strong predictor of which parameter sets will succeed in forming the pattern. Although the original model was robust to parameter variation, it could not reproduce the observed effects of cell division on the pattern of gene expression. I present a modified version that incorporates recent experimental evidence and does successfully mimic the consequences of cell division. The behavior of this modified model can also be understood in terms of bistability in positive feedback of gene expression. I discuss how this topological property of networks provides robust pattern formation and how large changes in parameters can change the specific pattern produced by a network."
"Multistability in the lactose utilization network of Escherichia coli.Multistability, the capacity to achieve multiple internal states in response to a single set of external inputs, is the defining characteristic of a switch. Biological switches are essential for the determination of cell fate in multicellular organisms, the regulation of cell-cycle oscillations during mitosis and the maintenance of epigenetic traits in microbes. The multistability of several natural and synthetic systems has been attributed to positive feedback loops in their regulatory networks. However, feedback alone does not guarantee multistability. The phase diagram of a multistable system, a concise description of internal states as key parameters are varied, reveals the conditions required to produce a functional switch. Here we present the phase diagram of the bistable lactose utilization network of Escherichia coli. We use this phase diagram, coupled with a mathematical model of the network, to quantitatively investigate processes such as sugar uptake and transcriptional regulation in vivo. We then show how the hysteretic response of the wild-type system can be converted to an ultrasensitive graded response. The phase diagram thus serves as a sensitive probe of molecular interactions and as a powerful tool for rational network design."
"Modeling and computational analysis of EGF receptor-mediated cell communication in Drosophila oogenesis.Autocrine signaling through the Epidermal Growth Factor Receptor (EGFR) operates at various stages of development across species. A recent hypothesis suggested that a distributed network of EGFR autocrine loops was capable of spatially modulating a simple single-peaked input into a more complex two-peaked signaling pattern, specifying the formation of a pair organ in Drosophila oogenesis (two respiratory appendages on the eggshell). To test this hypothesis, we have integrated genetic and biochemical information about the EGFR network into a mechanistic model of transport and signaling. The model allows us to estimate the relative spatial ranges and time scales of the relevant feedback loops, to interpret the phenotypic transitions in eggshell morphology and to predict the effects of new genetic manipulations. We have found that the proposed mechanism with a single diffusing inhibitor is sufficient to convert a single-peaked extracellular input into a two-peaked pattern of intracellular signaling. Based on extensive computational analysis, we predict that the same mechanism is capable of generating more complex patterns. At least indirectly, this can be used to account for more complex eggshell morphologies observed in related fly species. We propose that versatility in signaling mediated by autocrine loops can be systematically explored using experiment-based mechanistic models and their analysis."
"MAP kinase phosphatase as a locus of flexibility in a mitogen-activated protein kinase signaling network.Intracellular signaling networks receive and process information to control cellular machines. The mitogen-activated protein kinase (MAPK) 1,2/protein kinase C (PKC) system is one such network that regulates many cellular machines, including the cell cycle machinery and autocrine/paracrine factor synthesizing machinery. We used a combination of computational analysis and experiments in mouse NIH-3T3 fibroblasts to understand the design principles of this controller network. We find that the growth factor-stimulated signaling network containing MAPK 1, 2/PKC can operate with one (monostable) or two (bistable) stable states. At low concentrations of MAPK phosphatase, the system exhibits bistable behavior, such that brief stimulus results in sustained MAPK activation. The MAPK-induced increase in the amounts of MAPK phosphatase eliminates the prolonged response capability and moves the network to a monostable state, in which it behaves as a proportional response system responding acutely to stimulus. Thus, the MAPK 1, 2/PKC controller network is flexibly designed, and MAPK phosphatase may be critical for this flexible response."
"Protein complexes and functional modules in molecular networksProteins, nucleic acids, and small molecules form a dense network of molecular interactions in a cell. Molecules are nodes of this network, and the interactions between them are edges. The architecture of molecular networks can reveal important principles of cellular organization and function, similarly to the way that protein structure tells us about the function and organization of a protein. Computational analysis of molecular networks has been primarily concerned with node degree [Wagner, A. & Fell, D. A. (2001) Proc. R. Soc. London Ser. B 268, 1803–1810; Jeong, H., Tombor, B., Albert, R., Oltvai, Z. N. & Barabasi, A. L. (2000) Nature 407, 651–654] or degree correlation [Maslov, S. & Sneppen, K. (2002) Science 296, 910–913], and hence focused on single/two-body properties of these networks. Here, by analyzing the multibody structure of the network of protein–protein interactions, we discovered molecular modules that are densely connected within themselves but sparsely connected with the rest of the network. Comparison with experimental data and functional annotation of genes showed two types of modules: (i) protein complexes (splicing machinery, transcription factors, etc.) and (ii) dynamic functional units (signaling cascades, cell-cycle regulation, etc.). Discovered modules are highly statistically significant, as is evident from comparison with random graphs, and are robust to noise in the data. Our results provide strong support for the network modularity principle introduced by Hartwell et al. [Hartwell, L. H., Hopfield, J. J., Leibler, S. & Murray, A. W. (1999) Nature 402, C47–C52], suggesting that found modules constitute the “building blocks” of molecular networks."
"Finding and evaluating community structure in networksWe propose and study a set of algorithms for discovering community structure in networks -- natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using one of a number of possible ""betweenness"" measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems."
"The structure and function of complex networksInspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks."
"Matching words and picturesWe present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
Semantic Modeling and Knowledge Representation in Multimedia Databases
"Personalization of user profiles for content-based music retrieval based on relevance feedbackNumerous efforts on content-based music information retrieval have been presented in recent years. However, the object of such existing research is to retrieve a specific song from a large music database. In this research, we propose a music retrieval method which retrieves songs based on the user's musical preferences. This enables users to discover new songs which they are expected to like. Since music preferences are expected to be highly ambiguous, we propose the implementation of relevance feedback methods to improve the performance of our music information retrieval method. In order to reduce the burden of users to input learning data to the system, we also propose a method to generate user profiles based on genre preferences, and refinement of such profiles based on relevance feedback. Evaluation experiments are conducted based on a corpus of music data with user ratings. Results of these experiments prove the effectiveness of our method."
"Organization Theory and the Market for Corporate Control: A Dynamic Analysis of the Characteristics of Large Takeover Targets, 1980-1990This paper describes how takeovers are accomplished and why they are not readily accommodated by existing organizational theories. We examined the factors that made organizations vulnerable to takeovers during the 1980s, using event-history techniques on time-series data covering all takeover bids for Fortune 500 firms between January 1980 and December 1990. The paper shows that greater organizational slack, age, and having a finance chief executive officer increased the risk of takeover; family control and financial characteristics such as a higher market-to-book ratio lowered the risk; while bank control and intercorporate network ties had no discernable effect. The results indicate an irony: Large corporations that were most successful by the standards of organization theory were most likely to be taken over in the 1980s. We argue that theory about organizations and environments has been premised on an assumption of managerialism that is no longer tenable and that it must adjust to the financial model of the corporation that now dominates economic and policy discourse."
On the Negative Delay Time of a Narrow-Band Signal as It Passes Through the Resonant Filter of Absorption
The Literary Image of Joan of Arc: Prior Influences
Semantic information portals
"The F-signature of an affine semigroup ringWe prove that the F-signature of an affine semigroup ring of positive characteristic is always a rational number, and describe a method for computing this number. We use this method to determine the F-signature of Segre products of polynomial rings, and of Veronese subrings of polynomial rings. Our technique involves expressing the F-signature of an affine semigroup ring as the difference of the Hilbert-Kunz multiplicities of two monomial ideals, and then using Watanabe's result that these Hilbert-Kunz multiplicities are rational numbers."
"Besides Fists and Blood: Hong Kong Comedy and Its Master of the EightiesAn analysis of ""Modern Security Guards"" (1981) reveals the importance of comedy to Hong Kong cinema during the 1980s and demonstrates how Hong Kong films should be read within their own sophisticated cultural and political context."
"Space, Place, and Spectacle: The Crisis Cinema of John WooThe post-1986 Hong Kong cinema of John Woo is an apocalyptic crisis cinema, an urban vision forming part of a ""legitimation crisis"" that involves an aesthetic of political, historical, and cultural density."
"The Phantom Strikes Back: Triangulating Hollywood, Shanghai and Hong Kong"
Information in space
"New media, new practices"
Information design and the new media
Inventing new media
An overview of audio information retrieval
"A chemical genetic screen for direct v-Src substrates reveals ordered assembly of a retrograde signaling pathway.Using an ATP analog that is a specific substrate for an analog-specific allele of v-Src, we identified several novel cytoskeletal substrates that control actin assembly processes. A screen for less abundant v-Src substrates revealed the scaffolding protein Dok-1 as a direct substrate of v-Src. Further studies suggest that v-Src phosphorylation sites on Dok-1 are critical for its binding to RasGAP and Csk, negative regulators of Src signaling. This results in the downregulation of growth-promoting signals of the Src family kinases and the Ras pathway. Identification of the direct substrates of v-Src leads to a model for the precise order of assembly of a retrograde signaling pathway in v-Src-transformed cells and has provided new insight into the balance between those signals that promote cell transformation mediated by v-Src catalyzed tyrosine phosphorylation and those that inhibit it."
Lessons Learned from Building a Terabyte Digital Video Library
"Combinatorial efficacy achieved through two-point blockade within a signaling pathway-a chemical genetic approach.Whether the apparent efficacy of a specific kinase inhibitor is attributable solely to inhibition of its primary target, or to combined inhibition of additional unidentified kinases, is a critical issue in cancer therapy. We used a chemical genetic approach to generate a selective inhibitor of v-erbB [a transforming allele of epidermal growth factor receptor (EGFR)] and interrogated inhibition in known downstream signaling pathways. On the basis of this analysis, we hypothesized that dual inhibition of v-erbB and phosphatidylinositol 3' (PI3) kinases could show improved potency. We, therefore, used two different cell lines to examine the effects of v-erbB or EGFR inhibitors, in combination with PI3 kinase inhibitors, in mouse models for EGFR-driven cancers. When treated with NaPP1, v-erbB-as1-transformed fibroblasts showed cell-cycle arrest and decreased activity of Akt kinase. Inhibitors of v-erbB-as1 and of PI3 kinase showed enhanced efficacy in treating established 3T3:v-erbB-as1 tumor allografts. We extended these results to the human glioma cell line U87:MG transduced with DeltaEGFR, a tumor-derived activated allele, treating tumor-bearing mice with vehicle, the EGFR inhibitor ZD1839, LY294002, or ZD1839 plus LY294002. In human glioma xenografts, inhibition of EGFR cooperated similarly with inhibition of PI3 kinase. Our experiments provide a preclinical mechanistic basis for combining biologically based therapies directed against two targets within a complex signaling cascade."
"The use of claims databases for outcomes research: rationale, challenges, and strategies.Health care payers and policy makers need information about the cost and effectiveness of medical treatments. While randomized controlled trials historically are the primary source of medical information, they are expensive and labor-intensive, and often have limited utility for answering questions about ""real-world"" patient populations. These problems have led to an increasing reliance on claims database research in making policy decisions about treatment options. However, both researchers and decision makers should recognize the limitations and unique features of claims databases. Recommendations for avoiding or minimizing threats to internal validity, construct validity, and external validity are: (1) use of a study design that includes comparisons; (2) ensuring that the study design and conclusions are consistent with the database; (3) a priori conceptual modeling of the research question; (4) use of appropriate constructs; (5) explicit examination of alternative explanations for study findings; (6) sensitivity analyses of key assumptions; (7) awareness of the distinction between statistical and practical significance of findings; (8) generalization only when appropriate; and (9) reporting of relevant information. Given that any study design or data source has limitations, we hope that this paper will encourage a philosophy of methodological pluralism in outcomes research. Awareness and accurate reporting of validity issues will strengthen and extend the information resources currently available to decision makers."
The Decomposition of an Event
"Developments in ocean climate modellingThis paper presents some research developments in primitive equation ocean models which could impact the ocean component of realistic global coupled climate models aimed at large-scale, low frequency climate simulations and predictions. It is written primarily to an audience of modellers concerned with the ocean component of climate models, although not necessarily experts in the design and implementation of ocean model algorithms."
"Programmed population control by cell–cell communication and regulated killingDe novo engineering of gene circuits inside cells is extremely difficult1, 2, 3, 4, 5, 6, 7, 8, 9, and efforts to realize predictable and robust performance must deal with noise in gene expression and variation in phenotypes between cells10, 11, 12. Here we demonstrate that by coupling gene expression to cell survival and death using cell–cell communication, we can programme the dynamics of a population despite variability in the behaviour of individual cells. Specifically, we have built and characterized a 'population control' circuit that autonomously regulates the density of an Escherichia coli population. The cell density is broadcasted and detected by elements from a bacterial quorum-sensing system13, 14, which in turn regulate the death rate. As predicted by a simple mathematical model, the circuit can set a stable steady state in terms of cell density and gene expression that is easily tunable by varying the stability of the cell–cell communication signal. This circuit incorporates a mechanism for programmed death in response to changes in the environment, and allows us to probe the design principles of its more complex natural counterparts."
"Streptomyces-derived quorum-sensing systems engineered for adjustable transgene expression in mammalian cells and mice.Prokaryotic transcriptional regulatory elements have been adopted for controlled expression of cloned genes in mammalian cells and animals, the cornerstone for gene-function correlations, drug discovery, biopharmaceutical manufacturing as well as advanced gene therapy and tissue engineering. Many prokaryotes have evolved specific molecular communication systems known as quorum-sensing to coordinate population-wide responses to physiological and/or physicochemical signals. A generic bacterial quorum-sensing system is based on a diffusible signal molecule that prevents binding of a repressor to corresponding operator sites thus resulting in derepression of a target regulon. In Streptomyces, a family of butyrolactones and their corresponding receptor proteins, serve as quorum-sensing systems that control morphological development and antibiotic biosynthesis. Fusion of the Streptomyces coelicolor quorum-sensing receptor (ScbR) to a eukaryotic transactivation domain (VP16) created a mammalian transactivator (SCA) which binds and adjusts transcription from chimeric promoters containing an SCA-specific operator module (P(SPA)). Expression of erythropoietin or the human secreted alkaline phosphatase (SEAP) by this quorum-sensor-regulated gene expression system (QuoRex) could be fine-tuned by non-toxic butyrolactones in a variety of mammalian cells including human primary and mouse embryonic stem cells. Following intraperitoneal implantation of microencapsulated Chinese hamster ovary cells transgenic for QuoRex-controlled SEAP expression into mice, the serum levels of this model glycoprotein could be adjusted to desired concentrations using different butyrolactone dosing regimes."
A bibliographic metadata infrastructure for the twenty-first century
Managing ski resorts: the National Ski Areas Association (NSAA) of the United States 2001 and 2002 Annual Progress Reports on the Environmental Charter and the reaction from conservations groups
PreSense
"Interaction effects of virtual structuresComplex Collaborative Virtual Environments (CVEs) are usually partitioned into a structure of discrete or nested graphical objects and spaces. The use of a structure for managing graphics and spaces allows users to perform certain actions. For example, objects can then be picked up and moved around; spaces can be separated into discrete units and individually broadcast to certain users, reducing network bandwidth requirements. However, the effects of providing particular structures on users' interaction have not been investigated. In this paper, we present an analysis of pairs of users interacting in a CVE. Our analysis highlights behaviours that are caused by the simple virtual structures it provides. We derive design issues to be considered when defining the structure of a shared virtual world."
Orchestrating a mixed reality game 'on the ground'
Citywide: Supporting Interactive Digital Experiences Across Physical Space
The augurscope
Mobility in collaborationNote: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.
Paperwork at 78kph
GestureMan
"Risk factors associated with earlier age of onset in familial pancreatic carcinoma.BACKGROUND: An estimated 5-10% of all pancreatic adenocarcinomas have a hereditary association. The objective of the current study was to characterize the clinical and pathologic features of familial pancreatic carcinoma and to determine potential differences in demographics, risk factors, and outcomes between familial and sporadic pancreatic carcinoma populations. METHODS: A retrospective review was performed to identify patients diagnosed with pancreatic carcinoma who had an associated familial disposition. Demographic analyses and assessment of clinical features and treatment outcomes were performed for the familial subgroup, and the results were compared with observations made in the nonfamilial, or 'sporadic', population. RESULTS: Thirty of 826 patients (3.6%) had familial pancreatic carcinoma. Baseline demographics, resectability, and metastases were similar in both the familial cohort and the sporadic cohort. The mean age of onset was slightly lower in the familial cohort (57.6 years, compared with 61 years in the sporadic cohort). However, the familial population had a significantly greater proportion of patients who were diagnosed at age < 50 years compared with the sporadic population (36.7% vs. 18.3%; P = 0.017). A positive smoking history was more commonly associated with familial pancreatic carcinoma (87% vs. 66%; P = 0.06). The overall median survival durations were 7 months and 6 months for the familial group and the sporadic group, respectively. CONCLUSIONS: Patients with familial pancreatic carcinoma present at an earlier age compared with their counterparts who have nonfamilial disease. Smoking may play a significant role in the risk or promotion of pancreatic carcinoma in patients with an inherited predisposition. Cancer 2004. (c) 2004 American Cancer Society."
"Female swallow preference for symmetrical male sexual ornaments.Many secondary sexual characters are supposed to have evolved as a response to female choice of the most extravagantly ornamented males, a hypothesis supported by studies demonstrating female preferences for the most ornamented males. Comparative studies of elaborate feather ornaments in birds have shown that (1) ornaments have larger degrees of fluctuating asymmetry (small, random deviations from bilateral symmetry caused by an inability of individuals to cope with environmental and genetic stress during development of a character) than other morphological traits, and (2) the degree of fluctuating asymmetry is often negatively related to the size of the ornament. The negative relationship between ornament asymmetry and size suggests that ornament size reliably reflects male quality because the largest secondary sex traits demonstrate the least degree of fluctuating asymmetry. I manipulated tail length and tail asymmetry independently in male swallows (Hirundo rustica) to determine whether ornament size or asymmetry were used as cues in mate choice. Male swallows with elongated, symmetric tails mated earlier, and enjoyed larger annual reproductive success than did males with shortened tails and increased asymmetry. Females therefore prefer large as well as symmetric ornaments, which suggests that females in their mate choice use ornament asymmetry and size as reliable indicators of male quality."
Large negative and positive delay of optical pulses in coherently prepared dense Rb vapor with buffer gas We experimentally study the group time delay for a light pulse propagating through hot Rb vapor in the presence of a strong coupling field in a $Λ$ configuration. We demonstrate that the ultra-slow pulse propagation is transformed into superluminal propagation as the one-photon detuning of the light increases due to the change in the transmission resonance lineshape. Negative group velocity as low as -c/10^6=-80 m/s is recorded. We also find that the advance time in the regime of the superluminal propagation grows linearly with increasing laser field power.
"Negative Group Delay and Superluminal Propagation: An Electronic Circuit ApproachWe present a simple electronic circuit which provides negative group delays for band-limited, base-band pulses. It is shown that large time advancement comparable to the pulse width can be achieved with appropriate cascading of negative-delay circuits but eventually the out-of-band gain limits the number of cascading. The relations to superluminality and causality are also discussed."
"Demonstration of negative group delays in a simple electronic circuitWe present a simple electronic circuit which produces negative group delays for base-band pulses. When a band-limited pulse is applied as the input, a forwarded pulse appears at the output. The negative group delays in lumped systems share the same mechanism with the superluminal light propagation, which is recently demonstrated in an absorption-free, anomalous dispersive medium [Wang et al., Nature 406, 277 (2000)]. In this circuit, the advance time more than twenty percent of the pulse width can easily be achieved. The time constants, which can be in the order of seconds, is slow enough to be observed with the naked eye by looking at the lamps driven by the pulses."
"Question: Negative Group Delays and Action-at-a-DistanceWe comment on the paper by M. W. Mitchell and R. Y. Chiao, “Causality and negative group delay in a simple bandpass amplifier"", Am. J. Phys. 66 (1), 14-19 (1998)."
"The sociocognitive psychology of computer-mediated communication: the present and future of technology-based interactions.The increased diffusion of the Internet has made computer-mediated communication (CMC) very popular. However, a difficult question arises for psychologists and communication researchers: ""What are the communicative characteristics of CMC?"" According to the ""cues-filtered-out"" approach, CMC lacks the specifically relational features (social cues), which enable the interlocutors to identify correctly the kind of interpersonal situations they find themselves in. This paper counters this vision by integrating in its theoretical frame the different psycho-social approaches available in current literature. In particular, the paper describes the characteristics of the socio-cognitive processes-emotional expression, context definition, and identity creation-used by the interlocutors to make order and create relationships out of the miscommunication processes typical of CMC. Moreover, it presents the emerging forms of CMC-instant messaging, shared hypermedia, weblogs, and graphical chats-and their possible social and communicative effects."
"Content-based retrieval of historical Ottoman documents stored as textual images.There is an accelerating demand to access the visual content of documents stored in historical and cultural archives. Availability of electronic imaging tools and effective image processing techniques makes it feasible to process the multimedia data in large databases. In this paper, a framework for content-based retrieval of historical documents in the Ottoman Empire archives is presented. The documents are stored as textual images, which are compressed by constructing a library of symbols occurring in a document, and the symbols in the original image are then replaced with pointers into the codebook to obtain a compressed representation of the image. The features in wavelet and spatial domain based on angular and distance span of shapes are used to extract the symbols. In order to make content-based retrieval in historical archives, a query is specified as a rectangular region in an input image and the same symbol-extraction process is applied to the query region. The queries are processed on the codebook of documents and the query images are identified in the resulting documents using the pointers in textual images. The querying process does not require decompression of images. The new content-based retrieval framework is also applicable to many other document archives using different scripts."
"An integrated content and metadata based retrieval system for art.A new approach to image retrieval is presented in the domain of museum and gallery image collections. Specialist algorithms, developed to address specific retrieval tasks, are combined with more conventional content and metadata retrieval approaches, and implemented within a distributed architecture to provide cross-collection searching and navigation in a seamless way. External systems can access the different collections using interoperability protocols and open standards, which were extended to accommodate content based as well as text based retrieval paradigms. After a brief overview of the complete system, we describe the novel design and evaluation of some of the specialist image analysis algorithms including a method for image retrieval based on sub-image queries, retrievals based on very low quality images and retrieval using canvas crack patterns. We show how effective retrieval results can be achieved by real end-users consisting of major museums and galleries, accessing the distributed but integrated digital collections."
Intentional Systems
"The effect of dopamine depletion from the caudate nucleus of the common marmoset (Callithrix jacchus) on tests of prefrontal cognitive function.This study examined the effects of depletion of dopamine from the caudate nucleus of the common marmoset (Callithrix jacchus), on tasks sensitive to prefrontal damage (attentional set-shifting and spatial delayed response). There was a marked impairment in performance on the spatial delayed response task, but performance on the attentional set-shifting task was relatively preserved except for an impairment in re-engagement of a previously relevant perceptual dimension. This pattern of impairment is distinct from that seen after excitotoxic lesions of the prefrontal cortex and in patients with Parkinson's disease. Though it is not possible to identify specific cognitive functions that are independent of dopaminergic modulation of the caudate nucleus, due to the partial nature of the lesion, the results do provide insight into those cognitive processes that appear most dependent on caudate dopamine."
"Co-mutation of p53, K-ras genes and accumulation of p53 protein and its correlation to clinicopathological features in rectal cancer.AIM: To determine the accuracy of p53 gene mutations predicted by overexpression of p53 protein immunohistochemically, and to investigate the co-mutation of p53 and K-ras genes in rectal cancer and its effect on promoting malignant biologic behaviors of tumors. METHODS: Ninety-seven specimens of rectal cancer were surgically resected in our hospital from August 1996 to October 1997. The hot mutation areas of p53 gene (in exons 5-8) and K-ras gene (in codon 5/12 and 13) were detected with polymerase chain reaction-single strand conformation polymorphism (PCR-SSCP), and overexpression of p53 protein was detected with immunohistochemistry (IHC) in the 97 specimens of rectal cancer. Correlation between gene mutations and tumor clinicopathologic factors was studied, and survival analysis was penfomed as well. RESULTS: There were 36 cases of p53 gene mutations in 61 p53 protein positive cases, and 21 cases of p53 gene non-mutation in 36 p53 protein negative cases respectively. The coincidence rate of p53 gene mutation by IHC method with PCR-SSCP method was 58.8% (57/97). The mutation rate of p53 gene was 52.6% (51/97), while K-ras gene mutation was observed in codons 12 and 13 in 61 cases with a mutation rate of 62.9% (61/97). Single gene mutation of p53 or K-ras was found in 32 cases. Both p53 and K-ras gene mutation were found in 48 cases. Statistical analysis showed that p53 and K-ras gene mutations were not related to the clinicopathologic factors, including tumor size, gross tumor type, histological classification, differentiation, invasion to intestinal veins, lymphatics and nerves, invasive depth to wall, lymph node metastasis, and Dukes' stages (P>0.05). The survival in patients with no gene mutation, single gene mutation and both gene mutations were similar (P>0.05). CONCLUSION: IHC has a certain false positive and false negative rate in detecting p53 gene mutations. Malignant biological behaviours of rectal cancer are not enhanced by p53 and K-ras gene mutations. Co-mutation of p53 and K-ras gene has neither synergic carcinogenesis-promoting effect, nor prognostic effect on rectal cancer."
"Perseveration and strategy in a novel spatial self-ordered sequencing task for nonhuman primates: effects of excitotoxic lesions and dopamine depletions of the prefrontal cortex.Damage to the prefrontal cortex disrupts the performance of self-ordered sequencing tasks, although the precise mechanisms by which this effect occurs is unclear. Active working memory, inhibitory control, and the ability to generate and perform a sequence of responses are all putative cognitive abilities that may be responsible for the impaired performance that results from disruption of prefrontal processing. In addition, the neurochemical substrates underlying prefrontal cognitive function are not well understood, although active working memory appears to depend upon an intact mesocortical dopamine system. The present experiments were therefore designed to evaluate explicitly the contribution of each of these abilities to successful performance of a novel spatial self-ordered sequencing task and to examine the contribution of the prefrontal cortex and its dopamine innervation to each ability in turn. Excitotoxic lesions of the prefrontal cortex of the common marmoset profoundly impaired the performance of the self-ordered sequencing task and induced robust perseverative responding. Task manipulations that precluded perseveration ameliorated the effect of this lesion and revealed that the ability to generate and perform sequences of responses was unaffected by excitotoxic damage to prefrontal cortex. In contrast, large dopamine and noradrenaline depletions within the same areas of prefrontal cortex had no effect on any aspect of the self-ordered task but did impair the acquisition of an active working memory task, spatial delayed response, to the same degree as the excitotoxic lesion. These results demonstrate that a lesion of the ascending monoamine projections to the prefrontal cortex is not always synonymous with a lesion of the prefrontal cortex itself and thereby challenge existing concepts concerning the neuromodulation of prefrontal cognitive function."
"Clinical Versus Actuarial JudgmentProfessionals are frequently consulted to diagnose and predict human behavior; optimal treatment and planning often hinge on the consultant's judgmental accuracy. The consultant may rely on one of two contrasting approaches to decision-making--the clinical and actuarial methods. Research comparing these two approaches shows the actuarial method to be superior. Factors underlying the greater accuracy of actuarial methods, sources of resistance to the scientific findings, and the benefits of increased reliance on actuarial approaches are discussed."
"Oscillations in NF-κB Signaling Control the Dynamics of Gene ExpressionSignaling by the transcription factor nuclear factor kappa B (NF-κB) involves its release from inhibitor kappa B (IκB) in the cytosol, followed by translocation into the nucleus. NF-κB regulation of IκBα transcription represents a delayed negative feedback loop that drives oscillations in NF-κB translocation. Single-cell time-lapse imaging and computational modeling of NF-κB (RelA) localization showed asynchronous oscillations following cell stimulation that decreased in frequency with increased IκBα transcription. Transcription of target genes depended on oscillation persistence, involving cycles of RelA phosphorylation and dephosphorylation. The functional consequences of NF-κB signaling may thus depend on number, period, and amplitude of oscillations."
"Discrimination of modes of action of antifungal substances by use of metabolic footprinting.Diploid cells of Saccharomyces cerevisiae were grown under controlled conditions with a Bioscreen instrument, which permitted the essentially continuous registration of their growth via optical density measurements. Some cultures were exposed to concentrations of a number of antifungal substances with different targets or modes of action (sterol biosynthesis, respiratory chain, amino acid synthesis, and the uncoupler). Culture supernatants were taken and analyzed for their ""metabolic footprints"" by using direct-injection mass spectrometry. Discriminant function analysis and hierarchical cluster analysis allowed these antifungal compounds to be distinguished and classified according to their modes of action. Genetic programming, a rule-evolving machine learning strategy, allowed respiratory inhibitors to be discriminated from others by using just two masses. Metabolic footprinting thus represents a rapid, convenient, and information-rich method for classifying the modes of action of antifungal substances."
"Cryptanalysis of a secure communication scheme combining chaos and noiseThis paper studies the security of a secure communication scheme based on two discrete-time intermittently-chaotic systems synchronized via a common random driving signal. Some security defects of the secure communication scheme are revealed: 1) the key space can be remarkably reduced; 2) the decryption is insensitive to the mismatch of the secret key; 3) the key-generation process used in this secure communication scheme is insecure against known/chosen-plaintext attacks. The first two defects mean that the secure communication scheme is not secure enough against brute-force attacks, and the third means that an attacker can easily break the cryptosystem by approximately estimating the secret key once he has a chance to access a fragment of the generated keystream. A direct result of the cryptanalysis given in this paper is the unsuitability of intermittent chaos in the design of secure chaotic cryptosystems."
"Design of artificial cell–cell communication using gene and metabolic networksArtificial transcriptional networks have been used to achieve novel, nonnative behavior in bacteria. Typically, these artificial circuits are isolated from cellular metabolism and are designed to function without intercellular communication. To attain concerted biological behavior in a population, synchronization through intercellular communication is highly desirable. Here we demonstrate the design and construction of a gene-metabolic circuit that uses a common metabolite to achieve tunable artificial cell–cell communication. This circuit uses a threshold concentration of acetate to induce gene expression by acetate kinase and part of the nitrogen-regulation two-component system. As one application of the cell–cell communication circuit we created an artificial quorum sensor. Engineering of carbon metabolism in Escherichia coli made acetate secretion proportional to cell density and independent of oxygen availability. In these cells the circuit induced gene expression in response to a threshold cell density. This threshold can be tuned effectively by controlling ΔpH over the cell membrane, which determines the partition of acetate between medium and cells. Mutagenesis of the enhancer sequence of the glnAp2 promoter produced variants of the circuit with changed sensitivity demonstrating tunability of the circuit by engineering of its components. The behavior of the circuit shows remarkable predictability based on a mathematical design model."
Teaching bacteria a new language.
"Initial sequencing and comparative analysis of the mouse genomeThe sequence of the mouse genome is a key informational tool for understanding the contents of the human genome and a key experimental tool for biomedical research. Here, we report the results of an international collaboration to produce a high-quality draft sequence of the mouse genome. We also present an initial comparative analysis of the mouse and human genomes, describing some of the insights that can be gleaned from the two sequences. We discuss topics including the analysis of the evolutionary forces shaping the size, structure and sequence of the genomes; the conservation of large-scale synteny across most of the genomes; the much lower extent of sequence orthology covering less than half of the genomes; the proportions of the genomes under selection; the number of protein-coding genes; the expansion of gene families related to reproduction and immunity; the evolution of proteins; and the identification of intraspecies polymorphism."
Dynamic conditional random fields
"Large N Field Theories, String Theory and GravityWe review the holographic correspondence between field theories and string/M theory, focusing on the relation between compactifications of string/M theory on Anti-de Sitter spaces and conformal field theories. We review the background for this correspondence and discuss its motivations and the evidence for its correctness. We describe the main results that have been derived from the correspondence in the regime that the field theory is approximated by classical or semiclassical gravity. We focus on the case of the N=4 supersymmetric gauge theory in four dimensions, but we discuss also field theories in other dimensions, conformal and non-conformal, with or without supersymmetry, and in particular the relation to QCD. We also discuss some implications for black hole physics."
"Surface mapping of peripheral nerves in children with a nerve stimulator.Defining anatomical landmarks may be difficult in the growing child. With the aid of a peripheral nerve stimulator, the path of many superficial peripheral nerves can be 'mapped' prior to skin penetration by stimulating the motor component of the peripheral nerve percutaneously with a 2-3.5 mA output. The required current will vary and is dependent upon the depth of the nerve and the moistness of the overlying skin. This 'nerve mapping technique' has proved particularly useful for brachial plexus, axillary, ulna and median nerve blocks in the upper limb and femoral and popliteal nerve blocks in the lower limb. It is a useful teaching tool and improves the success rate of peripheral nerve blocks in children of all ages."
"Thrombin-activable fibrinolysis inhibitor levels in the acute phase of ischemic stroke.BACKGROUND AND PURPOSE: Thrombin-activable fibrinolysis inhibitor (TAFI) is a recently identified fibrinolysis inhibitor in plasma. The purpose of this work was to study TAFI levels in the acute phase of ischemic stroke and their relationship with stroke evolution. METHODS: In 30 consecutive ischemic stroke patients, TAFI plasma levels were measured by means of enzyme-linked immunosorbent assay (percentage of the pooled reference kit expressed as mean+/-SD) and compared with the values obtained in 30 healthy control subjects. All samples were drawn within the first 24 hours after symptom onset (mean, 4.6 hours) and before any treatment was started. RESULTS: TAFI plasma concentration was significantly higher (P<0.001) in stroke patients (158.4+/-53.2%) than in healthy control subjects (105.6+/-30.2%). The highest TAFI levels were found in cases of neurological deterioration (worsening, 198.1+/-63.0%; stability, 130.5+/-39.3%; improvement, 173.9+/-52.0%; P=0.057). CONCLUSIONS: High levels of TAFI are found in the acute phase of ischemic stroke."
"Cochlear implantation in patients with a history of chronic otitis media.Objective To propose management options for cochlear implantation in chronic otitis media based on our experiences. Material and Methods A retrospective review of 418 cochlear implantations performed by the 2 senior authors between November 1988 and February 2004 was conducted. Nine patients who had chronic otitis media in the ear to be implanted were included. Of these, three showed active inflammation at presentation; the other six cases had undergone previous tympanomastoidectomy surgery and did not show active inflammation at presentation. Results Five patients with active inflammation or without an adequate soft tissue layer in the mastoid bowl underwent a two-stage procedure. Four cases who showed inactive inflammation and had an adequate tissue layer to protect the electrode array underwent a single-stage technique, although two of them showed dry tympanic membrane perforation. No local or intracranial inflammation recurred. The electrode was exposed in the mastoid bowl in one case, who was managed with revisional mastoid obliteration with soft tissue. Conclusion Complete eradication of inflammation and the securing of a strong protective soft tissue layer over the electrode are prerequisites for cochlear implantation in ears with chronic otitis media."
"Progression of cognitive impairment in stroke patients.OBJECTIVE: To examine the progression of neuropsychological deficits in stroke patients with and without cognitive impairment. METHODS: The authors assessed the Sydney Stroke Study cohort 1 year after index assessment with detailed neuropsychological and medical-psychiatric assessments. The neuropsychological tests were classified into cognitive domains, and composite z-scores adjusted for age and education. Changes in cognitive test scores were compared between groups and predictors of cognitive change examined. RESULTS: Patients (n = 128) had a mean decline of 0.83 (SD 2.2) points on the Mini-Mental State Examination (MMSE) compared to an increase of 0.76 (1.3) in controls (n = 78) (p < 0.0001), and a small but significant decline in informant ratings of function and cognition. The decline on a composite index of cognitive function was not significantly different in the groups after correction for age, education, and index assessment cognitive function. Stroke/transient ischemic attack patients, however, had greater decline in verbal memory and visuoconstructive function. The occurrence of an interval stroke (n = 14) significantly increased the cognitive decline to a mean 2.0 points on the MMSE. The rate of change had a significant correlation (r = 0.24) with white matter hyperintensity volume at index assessment. On regression analysis the only predictor of cognitive change was years of education, which had a protective function. CONCLUSIONS: Subjects with cerebrovascular disease have a slow decline in cognitive functioning in the absence of further cerebrovascular events, although the occurrence of such an event accentuates the dysfunction. Education plays a protective role."
Automatic topics discovery from hyperlinked documents
"The large-scale organization of metabolic networksIn a cell or microorganism, the processes that generate mass, energy, information transfer and cell-fate specification are seamlessly integrated through a complex network of cellular constituents and reactions1. However, despite the key role of these networks in sustaining cellular functions, their large-scale structure is essentially unknown. Here we present a systematic comparative mathematical analysis of the metabolic networks of 43 organisms representing all three domains of life. We show that, despite significant variation in their individual constituents and pathways, these metabolic networks have the same topological scaling properties and show striking similarities to the inherent organization of complex non-biological systems2. This may indicate that metabolic organization is not only identical for all living organisms, but also complies with the design principles of robust and error-tolerant scale-free networks2, 3, 4, 5, and may represent a common blueprint for the large-scale organization of interactions among all cellular constituents."
"Functional and topological characterization of protein interaction networksThe elucidation of the cell's large-scale organization is a primary challenge for post-genomic biology, and understanding the structure of protein interaction networks offers an important starting point for such studies. We compare four available databases that approximate the protein interaction network of the yeast, Saccharomyces cerevisiae, aiming to uncover the network's generic large-scale properties and the impact of the proteins' function and cellular localization on the network topology. We show how each database supports a scale-free, topology with hierarchical modularity, indicating that these features represent a robust and generic property of the protein interactions network. We also find strong correlations between the network's structure and the functional role and subcellular localization of its protein constituents, concluding that most functional and/or localization classes appear as relatively segregated subnetworks of the full protein interaction network. The uncovered systematic differences between the four protein interaction databases reflect their relative coverage for different functional and localization classes and provide a guide for their utility in various bioinformatics studies."
"SNOW: standard nomenclature wizard to help searching for (bio) chemical standardized names.SUMMARY: When developing bioinformatical tools dealing with enzymatic activity, metabolism or enzymatic networks, the problem of the lack of a clear nomenclature for biochemical compounds often arises. This problem leads us to develop a small web-based tool (SNOW, Standard NOmenclature Wizard) which may help to find recommended and trivial names or the correct closest spelling for a query compound name, if it exists. AVAILABILITY: Web-based interface available at http://ibb.uab.es/snow/ SUPPLEMENTARY INFORMATION: http://ibb.uab.es/snow/snow_moreinfo.html"
"XML, bioinformatics and data integration. Motivation: The eXtensible Markup Language (XML) is an emerging standard for structuring documents, notably for the World Wide Web. In this paper, the authors present XML and examine its use as a data language for bioinformatics. In particular, XML is compared to other languages, and some of the potential uses of XML in bioinformatics applications are presented. The authors propose to adopt XML for data interchange between databases and other sources of data. Finally the discussion is illustrated by a test case of a pedigree data model in XML. Contact: Emmanuel.Barillot@infobiogen.fr "
"GIMS: an integrated data storage and analysis environment for genomic and functional data.Effective analyses in functional genomics require access to many kinds of biological data. For example, the analysis of upregulated genes in a microarray experiment might be aided by information concerning protein interactions or proteins' cellular locations. However, such information is often stored in different formats at different sites, in ways that may not be amenable to integrated analysis. The Genome Information Management System (GIMS) is an object database that integrates genomic data with data on the transcriptome, protein-protein interactions, metabolic pathways and annotations, such as gene ontology terms and identifiers. The resulting system supports the running of analyses over this integrated data resource, and provides comprehensive facilities for handling and interrelating the results of these analyses. GIMS has been used to store Saccharomyces cerevisiae data, and we demonstrate how the integrated storage of diverse types of data can be beneficial for analysis, using combinations of complex queries. As an example, we describe how GIMS has been used to analyse a collection of aryl alcohol dehydrogenase gene deletion mutants. The GIMS database can be accessed remotely using a Java application that can be downloaded from http://img.cs.man.ac.uk/gims."
"Advancing drug discovery through systems biology.Pharmaceutical companies are facing an urgent need to both increase their lead compound and clinical candidate portfolios and satisfy market demands for continued innovation and revenue growth. Here, we outline an emerging approach that attempts to facilitate and alleviate many of the current drug discovery issues and problems. This is, in part, achieved through the systematic integration of technologies, which results in a superior output of data and information, thereby enhancing our understanding of biological function, chemico-biological interactions and, ultimately, drug discovery. Systems biology is one new discipline that is positioned to significantly impact this process."
The CCPN project: an interim report on a data model for the NMR communityA recent workshop discusses the progress toward integrating NMR data into a unifying data model.
"Pedro: a configurable data entry tool for XML.Pedro is a Java application that dynamically generates data entry forms for data models expressed in XML Schema, producing XML data files that validate against this schema. The software uses an intuitive tree-based navigation system, can supply context-sensitive help to users and features a sophisticated interface for populating data fields with terms from controlled vocabularies. The software also has the ability to import records from tab delimited text files and features various validation routines. AVAILABILITY: The application, source code, example models from several domains and tutorials can be downloaded from http://pedro.man.ac.uk/."
"PEDRo: A database for storing, searching and disseminating experimental proteomics dataBACKGROUND:Proteomics is rapidly evolving into a high-throughput technology, in which substantial and systematic studies are conducted on samples from a wide range of physiological, developmental, or pathological conditions. Reference maps from 2D gels are widely circulated. However, there is, as yet, no formally accepted standard representation to support the sharing of proteomics data, and little systematic dissemination of comprehensive proteomic data sets.RESULTS:This paper describes the design, implementation and use of a Proteome Experimental Data Repository (PEDRo), which makes comprehensive proteomics data sets available for browsing, searching and downloading. It is also serves to extend the debate on the level of detail at which proteomics data should be captured, the sorts of facilities that should be provided by proteome data management systems, and the techniques by which such facilities can be made available.CONCLUSIONS:The PEDRo database provides access to a collection of comprehensive descriptions of experimental data sets in proteomics. Not only are these data sets interesting in and of themselves, they also provide a useful early validation of the PEDRo data model, which has served as a starting point for the ongoing standardisation activity through the Proteome Standards Initiative of the Human Proteome Organisation."
"Systems biology: a brief overview.To understand biology at the system level, we must examine the structure and dynamics of cellular and organismal function, rather than the characteristics of isolated parts of a cell or organism. Properties of systems, such as robustness, emerge as central issues, and understanding these properties may have an impact on the future of medicine. However, many breakthroughs in experimental devices, advanced software, and analytical methods are required before the achievements of systems biology can live up to their much-touted potential."
"Computational systems biology.To understand complex biological systems requires the integration of experimental and computational research -- in other words a systems biology approach. Computational biology, through pragmatic modelling and theoretical exploration, provides a powerful foundation from which to address critical scientific questions head-on. The reviews in this Insight cover many different aspects of this energetic field, although all, in one way or another, illuminate the functioning of modular circuits, including their robustness, design and manipulation. Computational systems biology addresses questions fundamental to our understanding of life, yet progress here will lead to practical innovations in medicine, drug discovery and engineering."
Standards for modeling
"Can a biologist fix a radio?--Or, what I learned while studying apoptosis."
"StarDOM: from STAR format to XML.StarDOM is a software package for the representation of STAR files as document object models and the conversion of STAR files into XML. This allows interactive navigation by using the Document Object Model representation of the data as well as easy access by XML query languages. As an example application, the entire BioMagResBank has been transformed into XML format. Using an XML query language, statistical queries on the collected NMR data sets can be constructed with very little effort. The BioMagResBank/XML data and the software can be obtained at http://www.nmr.embl-heidelberg.de/nmr/StarDOM linge@embl-heidelberg.de"
"BioBuilder as a database development and functional annotation platform for proteins.BACKGROUND: The explosion in biological information creates the need for databases that are easy to develop, easy to maintain and can be easily manipulated by annotators who are most likely to be biologists. However, deployment of scalable and extensible databases is not an easy task and generally requires substantial expertise in database development. RESULTS: BioBuilder is a Zope-based software tool that was developed to facilitate intuitive creation of protein databases. Protein data can be entered and annotated through web forms along with the flexibility to add customized annotation features to protein entries. A built-in review system permits a global team of scientists to coordinate their annotation efforts. We have already used BioBuilder to develop Human Protein Reference Database http://www.hprd.org, a comprehensive annotated repository of the human proteome. The data can be exported in the extensible markup language (XML) format, which is rapidly becoming as the standard format for data exchange. CONCLUSIONS: As the proteomic data for several organisms begins to accumulate, BioBuilder will prove to be an invaluable platform for functional annotation and development of customizable protein centric databases. BioBuilder is open source and is available under the terms of LGPL."
"Rapid and quantitative detection of the microbial spoilage of meat by fourier transform infrared spectroscopy and machine learning.Fourier transform infrared (FT-IR) spectroscopy is a rapid, noninvasive technique with considerable potential for application in the food and related industries. We show here that this technique can be used directly on the surface of food to produce biochemically interpretable ""fingerprints."" Spoilage in meat is the result of decomposition and the formation of metabolites caused by the growth and enzymatic activity of microorganisms. FT-IR was exploited to measure biochemical changes within the meat substrate, enhancing and accelerating the detection of microbial spoilage. Chicken breasts were purchased from a national retailer, comminuted for 10 s, and left to spoil at room temperature for 24 h. Every hour, FT-IR measurements were taken directly from the meat surface using attenuated total reflectance, and the total viable counts were obtained by classical plating methods. Quantitative interpretation of FT-IR spectra was possible using partial least-squares regression and allowed accurate estimates of bacterial loads to be calculated directly from the meat surface in 60 s. Genetic programming was used to derive rules showing that at levels of 10(7) bacteria.g(-1) the main biochemical indicator of spoilage was the onset of proteolysis. Thus, using FT-IR we were able to acquire a metabolic snapshot and quantify, noninvasively, the microbial loads of food samples accurately and rapidly in 60 s, directly from the sample surface. We believe this approach will aid in the Hazard Analysis Critical Control Point process for the assessment of the microbiological safety of food at the production, processing, manufacturing, packaging, and storage levels."
"Governing the Arts, Governing the State: Peking Opera and Political Authority in Taiwan"
"""Power"" against Ideology: A Critique of Foucaultian Usage"
"The Architecture of Economic Systems: Hierarchies and PolyarchiesThis paper presents some new ways of looking at economic systems and organizations. Individuals' judgments entail errors; they sometimes reject good projects and accept bad projects (or ideas). The architecture of an economic system (i.e., how the decision-making units are organized together within a system, who gathers what information, and who communicates what with whom) affects the errors made by individuals within the system, as well as how those errors are aggregated."
"Mapping weblog communitiesWebsites of a particular class form increasingly complex networks, and new tools are needed to map and understand them. A way of visualizing this complex network is by mapping it. A map highlights which members of the community have similar interests, and reveals the underlying social network. In this paper, we will map a network of websites using Kohonen's self-organizing map (SOM), a neural-net like method generally used for clustering and visualization of complex data sets. The set of websites considered has been the Blogalia weblog hosting site (based at <A HREF=""http://www.blogalia.com/"">this http URL</A>), a thriving community of around 200 members, created in January 2002. In this paper we show how SOM discovers interesting community features, its relation with other community-discovering algorithms, and the way it highlights the set of communities formed over the network."
"Joking, storytelling, artsharing, expressing affection"
"Understanding mobile contextsMobile urban environments present a challenge for context-aware computers because they differ from fixed indoor contexts such as offices, meeting rooms, and lecture halls in many important ways. Internal factors such as tasks and goals are different—external factors such as social resources are dynamic and unpredictable. An empirical, user-centred approach is needed to understand mobile contexts. In this paper, we present insights from an ethnomethodologically inspired study of 25 adult urbanites in Helsinki. The results describe typical phenomena in mobility: how situational and planned acts intermesh in navigation, how people construct personal and group spaces, and how temporal tensions develop and dissolve. Furthermore, we provide examples of social solutions to navigation problems, examine mobile multitasking, and consider design implications for mobile and context-aware human–computer interaction."
"Sheepskin Effects by Cohort: Implications of Job Matching in a Signaling ModelIn the presence of job matching, the returns to education signals are shown to decline in value as additional work experience allows more direct observation of productivity. This is tested by estimating sheepskin effects across five age cohorts of non-minority males in 1991. The effects are large and significant in early cohorts and virtually nonexistent in later cohorts. This pattern is partially confirmed with estimations within cohorts showing sheepskin returns declining from 1979 to 1991. The pattern within cohorts suggests that the 1991 pattern is not merely the result of vintage effects but caution is expressed in drawing conclusions."
"FBF-1 and FBF-2 Regulate the Size of the Mitotic Region in the C. elegans Germline.In the C. elegans germline, GLP-1/Notch signaling and two nearly identical RNA binding proteins, FBF-1 and FBF-2, promote proliferation. Here, we show that the fbf-1 and fbf-2 genes are largely redundant for promoting mitosis but that they have opposite roles in fine-tuning the size of the mitotic region. The mitotic region is smaller than normal in fbf-1 mutants but larger than normal in fbf-2 mutants. Consistent with gene-specific roles, fbf-2 expression is limited to the distal germline, while fbf-1 expression is broader. The fbf-2 gene, but apparently not fbf-1, is controlled by GLP-1/Notch signaling, and the abundance of FBF-1 and FBF-2 proteins is limited by reciprocal 3'UTR repression. We propose that the divergent fbf genes and their regulatory subnetwork enable a precise control over size of the mitotic region. Therefore, fbf-1 and fbf-2 provide a paradigm for how recently duplicated genes can diverge to fine-tune patterning during animal development."
"Shortest paths and load scaling in scale-free trees.Szabó, Alava, and Kertész [Phys. Rev. E 66, 026101 (2002)] considered two questions about the scale-free random tree given by the m=1 case of the Barabási-Albert (BA) model (identical with a random tree model introduced by Szymański in 1987): what is the distribution of the node to node distances, and what is the distribution of node loads, where the load on a node is the number of shortest paths passing through it? They gave heuristic answers to these questions using a ""mean-field"" approximation, replacing the random tree by a certain fixed tree with carefully chosen branching ratios. By making use of our earlier results on scale-free random graphs, we shall analyze the random tree rigorously, obtaining and proving very precise answers to these questions. We shall show that, after dividing by N (the number of nodes), the load distribution converges to an integer distribution X with Pr(X=c)=2/[(2c+1)(2c+3)], c=0,1,2,..., confirming the asymptotic power law with exponent -2 predicted by Szabó, Alava, and Kertész. For the distribution of node-node distances, we show asymptotic normality, and give a precise form for the (far from normal) large deviation law. We note that the mean-field methods used by Szabó, Alava, and Kertész give very good results for this model."
"Network biology: understanding the cell's functional organizationA key aim of postgenomic biomedical research is to systematically catalogue all molecules and their interactions within a living cell. There is a clear need to understand how these molecules and the interactions between them determine the function of this enormously complex machinery, both in isolation and when surrounded by other cells. Rapid advances in network biology indicate that cellular networks are governed by universal laws and offer a new conceptual framework that could potentially revolutionize our view of biology and disease pathologies in the twenty-first century."
"Bose-Einstein condensation in complex networks.The evolution of many complex systems, including the World Wide Web, business, and citation networks, is encoded in the dynamic web describing the interactions between the system's constituents. Despite their irreversible and nonequilibrium nature these networks follow Bose statistics and can undergo Bose-Einstein condensation. Addressing the dynamical properties of these nonequilibrium systems within the framework of equilibrium quantum gases predicts that the ""first-mover-advantage,"" ""fit-get-rich,"" and ""winner-takes-all"" phenomena observed in competitive systems are thermodynamically distinct phases of the underlying evolving networks."
"The small world of human languageWords in human language interact in sentences in non–random ways, and allow humans to construct an astronomic variety of sentences from a limited number of discrete units. This construction process is extremely fast and robust. The co–occurrence of words in sentences reflects language organization in a subtle manner that can be described in terms of a graph of word interactions. Here, we show that such graphs display two important features recently found in a disparate number of complex systems. (i) The so called small–world effect. In particular, the average distance between two words, d (i.e. the average minimum number of links to be crossed from an arbitrary word to another), is shown to be d≈ 2–3, even though the human brain can store many thousands. (ii) A scale–free distribution of degrees. The known pronounced effects of disconnecting the most connected vertices in such networks can be identified in some language disorders. These observations indicate some unexpected features of language organization that might reflect the evolutionary and social history of lexicons and the origins of their flexibility and combinatorial nature."
"Spectra of ""real-world"" graphs: beyond the semicircle law.Many natural and social systems develop complex networks that are usually modeled as random graphs. The eigenvalue spectrum of these graphs provides information about their structural properties. While the semicircle law is known to describe the spectral densities of uncorrelated random graphs, much less is known about the spectra of real-world graphs, describing such complex systems as the Internet, metabolic pathways, networks of power stations, scientific collaborations, or movie actors, which are inherently correlated and usually very sparse. An important limitation in addressing the spectra of these systems is that the numerical determination of the spectra for systems with more than a few thousand nodes is prohibitively time and memory consuming. Making use of recent advances in algorithms for spectral characterization, here we develop methods to determine the eigenvalues of networks comparable in size to real systems, obtaining several surprising results on the spectra of adjacency matrices corresponding to models of real-world graphs. We find that when the number of links grows as the number of nodes, the spectral density of uncorrelated random matrices does not converge to the semicircle law. Furthermore, the spectra of real-world graphs have specific features, depending on the details of the corresponding models. In particular, scale-free graphs develop a trianglelike spectral density with a power-law tail, while small-world graphs have a complex spectral density consisting of several sharp peaks. These and further results indicate that the spectra of correlated graphs represent a practical tool for graph classification and can provide useful insight into the relevant structural properties of real networks."
"Local versus global knowledge in the Barabási-Albert scale-free network model.The scale-free model of Barabási and Albert (BA) gave rise to a burst of activity in the field of complex networks. In this paper, we revisit one of the main assumptions of the model, the preferential attachment (PA) rule. We study a model in which the PA rule is applied to a neighborhood of newly created nodes and thus no global knowledge of the network is assumed. We numerically show that global properties of the BA model such as the connectivity distribution and the average shortest path length are quite robust when there is some degree of local knowledge. In contrast, other properties such as the clustering coefficient and degree-degree correlations differ and approach the values measured for real-world networks."
"Metabolomics and systems biology: making sense of the soup.Novel techniques for acquiring metabolomics data continue to emerge. Such data require proper storage in suitably configured databases, which then permit one to establish the size of microbial metabolomes (hundreds of major metabolites) and allow the nature, organisation and control of metabolic networks to be investigated. A variety of algorithms for metabolic network reconstruction coupled to suitable modelling algorithms are the ground substances for the development of metabolic network and systems biology. Even qualitative models of metabolic networks, when subject to stoichiometric constraints, can prove highly informative, and are the first step to the quantitative models, which alone can allow the true representation of complex biochemical systems."
"Genomic analysis of regulatory network dynamics reveals large topological changesNetwork analysis has been applied widely, providing a unifying language to describe disparate systems ranging from social interactions to power grids. It has recently been used in molecular biology, but so far the resulting networks have only been analysed statically1, 2, 3, 4, 5, 6, 7, 8. Here we present the dynamics of a biological network on a genomic scale, by integrating transcriptional regulatory information9, 10, 11 and gene-expression data12, 13, 14, 15, 16 for multiple conditions in Saccharomyces cerevisiae. We develop an approach for the statistical analysis of network dynamics, called SANDY, combining well-known global topological measures, local motifs and newly derived statistics. We uncover large changes in underlying network architecture that are unexpected given current viewpoints and random simulations. In response to diverse stimuli, transcription factors alter their interactions to varying degrees, thereby rewiring the network. A few transcription factors serve as permanent hubs, but most act transiently only during certain conditions. By studying sub-network structures, we show that environmental responses facilitate fast signal propagation (for example, with short regulatory cascades), whereas the cell cycle and sporulation direct temporal progression through multiple stages (for example, with highly inter-connected transcription factors). Indeed, to drive the latter processes forward, phase-specific transcription factors inter-regulate serially, and ubiquitously active transcription factors layer above them in a two-tiered hierarchy. We anticipate that many of the concepts presented here—particularly the large-scale topological changes and hub transience—will apply to other biological networks, including complex sub-systems in higher eukaryotes."
Petri Net representations in systems biology.The mathematical structures known as Petri Nets have recently become the focus of much research effort in both the structural and quantitative analysis of all kinds of biological networks. This review provides a very brief summary of these interesting new research directions.
"Can one factor the classical adjoint of a generic matrix?Let k be a field, n a positive integer, X a generic nxn matrix over k (i.e., a matrix (x_ij) of n^2 independent indeterminates over the polynomial ring k[x_ij]), and adj(X) its classical adjoint. It is shown that if char k=0 and n is odd, then adj(X) is not the product of two noninvertible nxn matrices over k[x_ij]. If n is even and >2, a restricted class of nontrivial factorizations occur. The nonzero-characteristic case remains open. The operation adj on matrices arises from the (n-1)st exterior power functor on modules; the same question can be posed for matrix operations arising from other functors."
"Robustness as a Measure of Plausibility in Models of Biochemical NetworksTheory, experiment, and observation suggest that biochemical networks which are conserved across species are robust to variations in concentrations and kinetic parameters. Here, we exploit this expectation to propose an approach to model building and selection. We represent a model as a mapping from parameter space to behavior space, and utilize bifurcation analysis to study the robustness of each region of steady-state behavior to parameter variations. The hypothesis that potential errors in models will result in parameter sensitivities is tested by analysis of two models of the biochemical oscillator underlying the Xenopus cell cycle. Our analysis successfully identifies known weaknesses in the older model and suggests areas for further investigation in the more recent, more plausible model. It also correctly highlights why the more recent model is more plausible."
"On the synchronization of networks with prescribed degree distributionsWe show that the degree distributions of graphs do not suffice to characterize the synchronization of systems evolving on them. We prove that, for any given degree sequence satisfying certain conditions, a connected graph having that degree sequence exists for which the first nontrivial eigenvalue of the graph Laplacian is arbitrarily close to zero. Consequently, dynamical systems defined on such graphs have poor synchronization properties. The result holds under quite mild assumptions, and shows that there exists classes of random, scale-free, regular, small-world, and other common network architectures which impede synchronization. The proof is based on a construction that also serves as an algorithm for building non-synchronizing networks having a prescribed degree distribution."
"Delays, connection topology, and synchronization of coupled chaotic mapsWe consider networks of coupled maps where the connections between units involve time delays. We show that, similar to the undelayed case, the synchronization of the network depends on the connection topology, characterized by the spectrum of the graph Laplacian. Consequently, scale-free and random networks are capable of synchronizing despite the delayed flow of information, whereas regular networks with nearest-neighbor connections and their small-world variants generally exhibit poor synchronization. On the other hand, connection delays can actually be conducive to synchronization, so that it is possible for the delayed system to synchronize where the undelayed system does not. Furthermore, the delays determine the synchronized dynamics, leading to the emergence of a wide range of new collective behavior which the individual units are incapable of producing in isolation."
"Fluctuations in network dynamics.Most complex networks serve as conduits for various dynamical processes, ranging from mass transfer by chemical reactions in the cell to packet transfer on the Internet. We collected data on the time dependent activity of five natural and technological networks, finding that for each the coupling of the flux fluctuations with the total flux on individual nodes obeys a unique scaling law. We show that the observed scaling can explain the competition between the system's internal collective dynamics and changes in the external environment, allowing us to predict the relevant scaling exponents."
"Analysis of weighted networksThe connections in many networks are not merely binary entities, either present or not, but have associated weights that record their strengths relative to one another. Recent studies of networks have, by and large, steered clear of such weighted networks, which are often perceived as being harder to analyze than their unweighted counterparts. Here we point out that weighted networks can in many cases be analyzed using a simple mapping from a weighted network to an unweighted multigraph, allowing us to apply standard techniques for unweighted graphs to weighted ones as well. We give a number of examples of the method, including an algorithm for detecting community structure in weighted networks and a new and simple proof of the max-flow/min-cut theorem."
"Inferring Network Mechanisms: The Drosophila melanogaster Protein Interaction NetworkNaturally occurring networks exhibit quantitative features revealing underlying growth mechanisms. Numerous network mechanisms have recently been proposed to reproduce specific properties such as degree distributions or clustering coefficients. We present a method for inferring the mechanism most accurately capturing a given network topology, exploiting discriminative tools from machine learning. The Drosophila melanogaster protein network is confidently and robustly (to noise and training data subsampling) classified as a duplication-mutation-complementation network over preferential attachment, small-world, and other duplication-mutation mechanisms. Systematic classification, rather than statistical study of specific properties, provides a discriminative approach to understand the design of complex networks."
"Toward improving Caenorhabditis elegans phenome mapping with an ORFeome-based RNAi library.The recently completed Caenorhabditis elegans genome sequence allows application of high-throughput (HT) approaches for phenotypic analyses using RNA interference (RNAi). As large phenotypic data sets become available, ""phenoclustering"" strategies can be used to begin understanding the complex molecular networks involved in development and other biological processes. The current HT-RNAi resources represent a great asset for phenotypic profiling but are limited by lack of flexibility. For instance, existing resources do not take advantage of the latest improvements in RNAi technology, such as inducible hairpin RNAi. Here we show that a C. elegans ORFeome resource, generated with the Gateway cloning system, can be used as a starting point to generate alternative HT-RNAi resources with enhanced flexibility. The versatility inherent to the Gateway system suggests that additional HT-RNAi libraries can now be readily generated to perform gene knockdowns under various conditions, increasing the possibilities for phenome mapping in C. elegans."
"A positive-feedback-based bistable 'memory module' that governs a cell fate decision.The maturation of Xenopus oocytes can be thought of as a process of cell fate induction, with the immature oocyte representing the default fate and the mature oocyte representing the induced fate. Crucial mediators of Xenopus oocyte maturation, including the p42 mitogen-activated protein kinase (MAPK) and the cell-division cycle protein kinase Cdc2, are known to be organized into positive feedback loops. In principle, such positive feedback loops could produce an actively maintained 'memory' of a transient inductive stimulus and could explain the irreversibility of maturation. Here we show that the p42 MAPK and Cdc2 system normally generates an irreversible biochemical response from a transient stimulus, but the response becomes transient when positive feedback is blocked. Our results explain how a group of intrinsically reversible signal transducers can generate an irreversible response at a systems level, and show how a cell fate can be maintained by a self-sustaining pattern of protein kinase activation."
"Building a cell cycle oscillator: hysteresis and bistability in the activation of Cdc2In the early embryonic cell cycle, Cdc2–cyclin B functions like an autonomous oscillator, whose robust biochemical rhythm continues even when DNA replication or mitosis is blocked1. At the core of the oscillator is a negative feedback loop; cyclins accumulate and produce active mitotic Cdc2–cyclin B2, 3; Cdc2 activates the anaphase-promoting complex (APC); the APC then promotes cyclin degradation and resets Cdc2 to its inactive, interphase state. Cdc2 regulation also involves positive feedback4, with active Cdc2–cyclin B stimulating its activator Cdc25 (refs 5–7) and inactivating its inhibitors Wee1 and Myt1 (refs 8–11). Under the correct circumstances, these positive feedback loops could function as a bistable trigger for mitosis12, 13, and oscillators with bistable triggers may be particularly relevant to biological applications such as cell cycle regulation14, 15, 16, 17. Therefore, we examined whether Cdc2 activation is bistable. We confirm that the response of Cdc2 to non-degradable cyclin B is temporally abrupt and switch-like, as would be expected if Cdc2 activation were bistable. We also show that Cdc2 activation exhibits hysteresis, a property of bistable systems with particular relevance to biochemical oscillators. These findings help establish the basic systems-level logic of the mitotic oscillator."
"Selective detection of proteins in mixtures using electrospray ionization mass spectrometry: influence of instrumental settings and implications for proteomics.We studied the effects of electrospray mass spectrometric instrumental settings on the relative and absolute detection of individual proteins in a five-component mixture. Conditions that were effective for a given protein could be very poor for the others, and vice versa, such that to a good approximation it was possible to find conditions for selective detection of individual proteins in a complex mixture without prior analytical separation. Some of these could be rationalized on the basis of the known biophysical properties of the individual proteins. The ability to vary the conditions of a mass spectrometric detection method on-line provides an important degree of freedom for the selective detection, and hence discrimination, of individual proteins and peptides in complex mixtures and has implications in proteomics, in particular with respect to top-down strategies for proteomic characterizations."
"Fast automatic registration of images using the phase of a complex wavelet transform: application to proteome gels.Image registration describes the process of manipulating a distorted version of an image such that its pixels overlay the equivalent pixels in a clean, master or reference image. The need for it has assumed particular prominence in the analysis of images of electrophoretic gels used in the analysis of protein expression levels in living cells, but also has fundamental applications in most other areas of image analysis. Much of the positional information of a data feature is carried in the phase of a complex transform, so a complex transform allows explicit specification of the phase, and hence of the position of features in the image. Registration of a test gel to a reference gel is achieved by using a multiresolution movement map derived from the phase of a complex wavelet transform (the Q-shift wavelet transform) to dictate the warping directly via movement of the nodes of a Delaunay-triangulated mesh of points. This warping map is then applied to the original untransformed image such that the absolute magnitude of the spots remains unchanged. The technique is general to any type of image. Results are presented for a simple computer simulated gel, a simple real gel registration between similar ""clean"" gels with local warping vectors distributed about one main direction, a hard problem between a reference gel and a ""dirty"" test gel with multi-directional warping vectors and many artifacts, and some typical gels of present interest in post-genomic biology. The method compares favourably with others, since it is computationally rapid, effective and entirely automatic."
"Metabolomics by numbers: acquiring and understanding global metabolite dataIn this postgenomic era, there is a specific need to assign function to orphan genes in order to validate potential targets for drug therapy and to discover new biomarkers of disease. Metabolomics is an emerging field that is complementary to the other ‘omics and proving to have unique advantages. As in transcriptomics or proteomics, a typical metabolic fingerprint or metabolomic experiment is likely to generate thousands of data points, of which only a handful might be needed to describe the problem adequately. Extracting the most meaningful elements of these data is thus key to generating useful new knowledge with mechanistic or explanatory power."
"Single-nucleotide polymorphism detection using nanomolar nucleotides and single-molecule fluorescence.We have exploited three methods for discriminating single-nucleotide polymorphisms (SNPs) by detecting the incorporation or otherwise of labeled dideoxy nucleotides at the end of a primer chain using single-molecule fluorescence detection methods. Good discrimination of incorporated vs free nucleotide may be obtained in a homogeneous assay (without washing steps) via confocal fluorescence correlation spectroscopy or by polarization anisotropy obtained from confocal fluorescence intensity distribution analysis. Moreover, the ratio of the fluorescence intensities on each polarization channel may be used directly to discriminate the nucleotides incorporated. Each measurement took just a few seconds and was done in microliter volumes with nanomolar concentrations of labeled nucleotides. Since the confocal volumes interrogated are approximately 1fL and the reaction volume could easily be lowered to nanoliters, the possibility of SNP analysis with attomoles of reagents opens up a route to very rapid and inexpensive SNP detection. The method was applied with success to the detections of SNPs that are known to occur in the BRCA1 and CFTR genes."
"High-throughput metabolic fingerprinting of legume silage fermentations via Fourier transform infrared spectroscopy and chemometrics.Silage quality is typically assessed by the measurement of several individual parameters, including pH, lactic acid, acetic acid, bacterial numbers, and protein content. The objective of this study was to use a holistic metabolic fingerprinting approach, combining a high-throughput microtiter plate-based fermentation system with Fourier transform infrared (FT-IR) spectroscopy, to obtain a snapshot of the sample metabolome (typically low-molecular-weight compounds) at a given time. The aim was to study the dynamics of red clover or grass silage fermentations in response to various inoculants incorporating lactic acid bacteria (LAB). The hyperspectral multivariate datasets generated by FT-IR spectroscopy are difficult to interpret visually, so chemometrics methods were used to deconvolute the data. Two-phase principal component-discriminant function analysis allowed discrimination between herbage types and different LAB inoculants and modeling of fermentation dynamics over time. Further analysis of FT-IR spectra by the use of genetic algorithms to identify the underlying biochemical differences between treatments revealed that the amide I and amide II regions (wavenumbers of 1,550 to 1,750 cm(-1)) of the spectra were most frequently selected (reflecting changes in proteins and free amino acids) in comparisons between control and inoculant-treated fermentations. This corresponds to the known importance of rapid fermentation for the efficient conservation of forage proteins."
"Functional genomic hypothesis generation and experimentation by a robot scientistThe question of whether it is possible to automate the scientific process is of both great theoretical interest1, 2 and increasing practical importance because, in many scientific areas, data are being generated much faster than they can be effectively analysed. We describe a physically implemented robotic system that applies techniques from artificial intelligence3, 4, 5, 6, 7, 8 to carry out cycles of scientific experimentation. The system automatically originates hypotheses to explain observations, devises experiments to test these hypotheses, physically runs the experiments using a laboratory robot, interprets the results to falsify hypotheses inconsistent with the data, and then repeats the cycle. Here we apply the system to the determination of gene function using deletion mutants of yeast (Saccharomyces cerevisiae) and auxotrophic growth experiments9. We built and tested a detailed logical model (involving genes, proteins and metabolites) of the aromatic amino acid synthesis pathway. In biological experiments that automatically reconstruct parts of this model, we show that an intelligent experiment selection strategy is competitive with human performance and significantly outperforms, with a cost decrease of 3-fold and 100-fold (respectively), both cheapest and random-experiment selection."
"Here is the evidence, now what is the hypothesis? The complementary roles of inductive and hypothesis-driven science in the post-genomic era.It is considered in some quarters that hypothesis-driven methods are the only valuable, reliable or significant means of scientific advance. Data-driven or 'inductive' advances in scientific knowledge are then seen as marginal, irrelevant, insecure or wrong-headed, while the development of technology--which is not of itself 'hypothesis-led' (beyond the recognition that such tools might be of value)--must be seen as equally irrelevant to the hypothetico-deductive scientific agenda. We argue here that data- and technology-driven programmes are not alternatives to hypothesis-led studies in scientific knowledge discovery but are complementary and iterative partners with them. Many fields are data-rich but hypothesis-poor. Here, computational methods of data analysis, which may be automated, provide the means of generating novel hypotheses, especially in the post-genomic era. Copyright 2003 Wiley Periodicals, Inc."
"Explanatory optimization of protein mass spectrometry via genetic search.Optimizing experimental conditions for the effective analysis of intact proteins by mass spectrometry is challenging, as many analytical factors influence the spectral quality, often in very different ways for different proteins and especially with complex protein mixtures. We show that genetic search methods are highly effective in this kind of optimization and that it was possible in 6 generations with a total of <500 experiments out of some 10(14) to find good combinations of experimental variables (electrospray ionization mass spectral settings) that would not have been detected by optimizing each variable alone (i.e., the search space is epistatic). Moreover, by inspecting the evolution of the variables to be optimized using genetic programming, we discovered an important relationship between two of the mass spectrometer settings that accounts for much of this success. Specifically, the conditions that were evolved included very low values of skimmer 1 voltage (the sample cone) and a skimmer 2 voltage (extraction cone) above a threshold that would nevertheless minimize the potential difference between the sample and extraction skimmers. The discovery of this relationship demonstrates the hypothesis-generating ability of genetic search in optimization processes where the size of the search space means that little or no a priori knowledge of the optimal conditions is available."
"Adoption of the transiently non-culturable state--a bacterial survival strategy?Microbial culturability can be ephemeral. Cells are not merely either dead or alive but can adopt physiological states in which they appear to be (transiently) non-culturable under conditions in which they are known normally to be able to grow and divide. The reacquisition of culturability from such states is referred to as resuscitation. We here develop the idea that this ""transient non-culturability"" is a consequence of a special survival strategy, and summarise the morphological, physiological and genetic evidence underpinning such behaviour and its adaptive significance."
"High-throughput classification of yeast mutants for functional genomics using metabolic footprinting.Many technologies have been developed to help explain the function of genes discovered by systematic genome sequencing. At present, transcriptome and proteome studies dominate large-scale functional analysis strategies. Yet the metabolome, because it is 'downstream', should show greater effects of genetic or physiological changes and thus should be much closer to the phenotype of the organism. We earlier presented a functional analysis strategy that used metabolic fingerprinting to reveal the phenotype of silent mutations of yeast genes. However, this is difficult to scale up for high-throughput screening. Here we present an alternative that has the required throughput (2 min per sample). This 'metabolic footprinting' approach recognizes the significance of 'overflow metabolism' in appropriate media. Measuring intracellular metabolites is time-consuming and subject to technical difficulties caused by the rapid turnover of intracellular metabolites and the need to quench metabolism and separate metabolites from the extracellular space. We therefore focused instead on direct, noninvasive, mass spectrometric monitoring of extracellular metabolites in spent culture medium. Metabolic footprinting can distinguish between different physiological states of wild-type yeast and between yeast single-gene deletion mutants even from related areas of metabolism. By using appropriate clustering and machine learning techniques, the latter based on genetic programming, we show that metabolic footprinting is an effective method to classify 'unknown' mutants by genetic defect."
"A systematic approach to modeling, capturing, and disseminating proteomics experimental data.Both the generation and the analysis of proteome data are becoming increasingly widespread, and the field of proteomics is moving incrementally toward high-throughput approaches. Techniques are also increasing in complexity as the relevant technologies evolve. A standard representation of both the methods used and the data generated in proteomics experiments, analogous to that of the MIAME (minimum information about a microarray experiment) guidelines for transcriptomics, and the associated MAGE (microarray gene expression) object model and XML (extensible markup language) implementation, has yet to emerge. This hinders the handling, exchange, and dissemination of proteomics data. Here, we present a UML (unified modeling language) approach to proteomics experimental data, describe XML and SQL (structured query language) implementations of that model, and discuss capture, storage, and dissemination strategies. These make explicit what data might be most usefully captured about proteomics experiments and provide complementary routes toward the implementation of a proteome repository."
"Metabolic profiling using direct infusion electrospray ionisation mass spectrometry for the characterisation of olive oils.There is a continuing need for improved methods for assessing the adulteration of foodstuffs. We report some highly encouraging data, where we have developed direct infusion electrospray ionisation mass spectrometry (ESI-MS) together with chemometrics as a novel, rapid (1 min per sample) and powerful technique to elucidate key metabolite differences in vegetable and nut oils. Principal components analysis of these ESI-MS spectra show that the reproducibility of this approach is high and that olive oil can be discriminated from oils which are commonly used as adulterants. These adulterants include refined hazelnut oil, which is particularly challenging given its chemical similarity to olive oils."
"Primary and secondary metabolism, and post-translational protein modifications, as portrayed by proteomic analysis of Streptomyces coelicolor.The newly sequenced genome of Streptomyces coelicolor is estimated to encode 7825 theoretical proteins. We have mapped approximately 10% of the theoretical proteome experimentally using two-dimensional gel electrophoresis and matrix-assisted laser desorption ionization time-of-flight (MALDI-TOF) mass spectrometry. Products from 770 different genes were identified, and the types of proteins represented are discussed in terms of their annotated functional classes. An average of 1.2 proteins per gene was observed, indicating extensive post-translational regulation. Examples of modification by N-acetylation, adenylylation and proteolytic processing were characterized using mass spectrometry. Proteins from both primary and certain secondary metabolic pathways are strongly represented on the map, and a number of these enzymes were identified at more than one two-dimensional gel location. Post-translational modification mechanisms may therefore play a significant role in the regulation of these pathways. Unexpectedly, one of the enzymes for synthesis of the actinorhodin polyketide antibiotic appears to be located outside the cytoplasmic compartment, within the cell wall matrix. Of 20 gene clusters encoding enzymes characteristic of secondary metabolism, eight are represented on the proteome map, including three that specify the production of novel metabolites. This information will be valuable in the characterization of the new metabolites."
"Genotype-phenotype mapping: genes as computer programs.The effects of genes on phenotype are mediated by processes that are typically unknown but whose determination is desirable. The conversion from gene to phenotype is not a simple function of individual genes, but involves the complex interactions of many genes; it is what is known as a nonlinear mapping problem. A computational method called genetic programming allows the representation of candidate nonlinear mappings in several possible trees. To find the best model, the trees are 'evolved' by processes akin to mutation and recombination, and the trees that more closely represent the actual data are preferentially selected. The result is an improved tree of rules that represent the nonlinear mapping directly. In this way, the encoding of cellular and higher-order activities by genes is seen as directly analogous to computer programs. This analogy is of utility in biological genetics and in problems of genotype-phenotype mapping."
"A family of autocrine growth factors in Mycobacterium tuberculosis.Mycobacterium tuberculosis and its close relative, Mycobacterium bovis (BCG) contain five genes whose predicted products resemble Rpf from Micrococcus luteus. Rpf is a secreted growth factor, active at picomolar concentrations, which is required for the growth of vegetative cells in minimal media at very low inoculum densities, as well as the resuscitation of dormant cells. We show here that the five cognate proteins from M. tuberculosis have very similar characteristics and properties to those of Rpf. They too stimulate bacterial growth at picomolar (and in some cases, subpicomolar) concentrations. Several lines of evidence indicate that they exert their activity from an extra-cytoplasmic location, suggesting that they are also involved in intercellular signalling. The five M. tuberculosis proteins show cross-species activity against M. luteus, Mycobacterium smegmatis and M. bovis (BCG). Actively growing cells of M. bovis (BCG) do not respond to these proteins, whereas bacteria exposed to a prolonged stationary phase do. Affinity-purified antibodies inhibit bacterial growth in vitro, suggesting that sequestration of these proteins at the cell surface might provide a means to limit or even prevent bacterial multiplication in vivo. The Rpf family of bacterial growth factors may therefore provide novel opportunities for preventing and controlling mycobacterial infections."
"Differentiation of Micromonospora Isolates from a Coastal Sediment in Wales on the Basis of Fourier Transform Infrared Spectroscopy, 16S rRNA Sequence Analysis, and the Amplified Fragment Length Polymorphism Technique.A number of actinomycetes isolates were recovered from coastal sediments in Aberystwyth (Wales, United Kingdom) with standard isolation techniques. Most of them were putatively assigned to the genera Streptomyces and Micromonospora on the basis of their morphological characteristics, and there appeared to be no difference whether the isolation media contained distilled water or seawater. A group of 20 Micromonospora isolates was selected to undergo further polyphasic taxonomic investigation. Three approaches were used to analyze the diversity of these isolates, 16S rDNA sequencing, fluorescent amplified fragment length polymorphism (AFLP), and Fourier transform infrared spectroscopy (FT-IR). The 16S rDNA sequence analysis confirmed that all of these isolates should be classified to the genus Micromonospora, and they were analyzed with a group of other Micromonospora 16S rDNA sequences available from the Ribosomal Database Project. The relationships of the 20 isolates were observed after hierarchical clustering, and almost identical clusters were obtained with these three techniques. This has obvious implications for high-throughput screening for novel actinomycetes because FT-IR spectroscopy, which is a rapid and reliable whole-organism fingerprinting method, can be applied as a very useful dereplication tool to indicate which environmental isolates have been cultured previously."
"The rpf gene of Micrococcus luteus encodes an essential secreted growth factor.Micrococcus luteus secretes a small protein called Rpf, which has autocrine and paracrine signalling functions and is required for the resuscitation of dormant cells. Originally isolated from the supernatant of actively growing cultures, Rpf was also detected on the surface of actively growing bacteria. Most molecules may be sequestered non-productively at the cell surface, as a truncated form of the protein, encompassing only the 'Rpf domain' is fully active. The C-terminal LysM module, which probably mediates binding to the cell envelope, is not required for biological activity. Rpf was essential for growth of M. luteus. Washed cells, inoculated at low density into a minimal medium, could not grow in its absence. Moreover, the incorporation of anti-Rpf antibodies into the culture medium at the time of inoculation also prevented bacterial growth. We were unable to inactivate rpf using a disrupted form of the gene, in which most of the coding sequence was replaced with a selectable thiostrepton resistance marker. Gene disruption was possible in the presence of a second, functional, plasmid-located copy of rpf, but not in the presence of a rpf derivative whose protein product lacked the secretory signal sequence. As far as we are aware, Rpf is the first example of a truly secreted protein that is essential for bacterial growth. If the Rpf-like proteins elaborated by Mycobacterium tuberculosis and other mycobacteria prove similarly essential, interference with their proper functioning may offer novel opportunities for protecting against, and treating, tuberculosis and other mycobacterial disease."
Metabolic control analysis and engineering of the yeast sterol biosynthetic pathway.
"Metabolomics and machine learning: explanatory analysis of complex metabolome data using genetic programming to produce simple, robust rules."
"Schemes of flux control in a model of Saccharomyces cerevisiae glycolysis.We used parameter scanning to emulate changes to the limiting rate for steps in a fitted model of glucose-derepressed yeast glycolysis. Three flux-control regimes were observed, two of which were under the dominant control of hexose transport, in accordance with various experimental studies and other model predictions. A third control regime in which phosphofructokinase exerted dominant glycolytic flux control was also found, but it appeared to be physiologically unreachable by this model, and all realistically obtainable flux control regimes featured hexose transport as a step involving high flux control."
"Monitoring of complex industrial bioprocesses for metabolite concentrations using modern spectroscopies and machine learning: application to gibberellic acid production.Two rapid vibrational spectroscopic approaches (diffuse reflectance-absorbance Fourier transform infrared [FT-IR] and dispersive Raman spectroscopy), and one mass spectrometric method based on in vacuo Curie-point pyrolysis (PyMS), were investigated in this study. A diverse range of unprocessed, industrial fed-batch fermentation broths containing the fungus Gibberella fujikuroi producing the natural product gibberellic acid, were analyzed directly without a priori chromatographic separation. Partial least squares regression (PLSR) and artificial neural networks (ANNs) were applied to all of the information-rich spectra obtained by each of the methods to obtain quantitative information on the gibberellic acid titer. These estimates were of good precision, and the typical root-mean-square error for predictions of concentrations in an independent test set was <10% over a very wide titer range from 0 to 4925 ppm. However, although PLSR and ANNs are very powerful techniques they are often described as ""black box"" methods because the information they use to construct the calibration model is largely inaccessible. Therefore, a variety of novel evolutionary computation-based methods, including genetic algorithms and genetic programming, were used to produce models that allowed the determination of those input variables that contributed most to the models formed, and to observe that these models were predominantly based on the concentration of gibberellic acid itself. This is the first time that these three modern analytical spectroscopies, in combination with advanced chemometric data analysis, have been compared for their ability to analyze a real commercial bioprocess. The results demonstrate unequivocally that all methods provide very rapid and accurate estimates of the progress of industrial fermentations, and indicate that, of the three methods studied, Raman spectroscopy is the ideal bioprocess monitoring method because it can be adapted for on-line analysis."
"Motifs, modules and games in bacteria.Global explorations of regulatory network dynamics, organization and evolution have become tractable thanks to high-throughput sequencing and molecular measurement of bacterial physiology. From these, a nascent conceptual framework is developing, that views the principles of regulation in term of motifs, modules and games. Motifs are small, repeated, and conserved biological units ranging from molecular domains to small reaction networks. They are arranged into functional modules, genetically dissectible cellular functions such as the cell cycle, or different stress responses. The dynamical functioning of modules defines the organism's strategy to survive in a game, pitting cell against cell, and cell against environment. Placing pathway structure and dynamics into an evolutionary context begins to allow discrimination between those physical and molecular features that particularize a species to its surroundings, and those that provide core physiological function. This approach promises to generate a higher level understanding of cellular design, pathway evolution and cellular bioengineering."
"Network dynamics and cell physiologyComplex assemblies of interacting proteins carry out most of the interesting jobs in a cell, such as metabolism, DNA synthesis, movement and information processing. These physiological properties play out as a subtle molecular dance, choreographed by underlying regulatory networks. To understand this dance, a new breed of theoretical molecular biologists reproduces these networks in computers and in the mathematical language of dynamical systems."
"Construction of a genetic toggle switch in Escherichia coliIt has been proposed1 that gene-regulatory circuits with virtually any desired property can be constructed from networks of simple regulatory elements. These properties, which include multistability and oscillations, have been found in specialized gene circuits such as the bacteriophage switch2 and the Cyanobacteria circadian oscillator3. However, these behaviours have not been demonstrated in networks of non-specialized regulatory components. Here we present the construction of a genetic toggle switch—a synthetic, bistable gene-regulatory network—in Escherichia coli and provide a simple theory that predicts the conditions necessary for bistability. The toggle is constructed from any two repressible promoters arranged in a mutually inhibitory network. It is flipped between stable states using transient chemical or thermal induction and exhibits a nearly ideal switching threshold. As a practical device, the toggle switch forms a synthetic, addressable cellular memory unit and has implications for biotechnology, biocomputing and gene therapy."
"Epigenes: design and construction of new hereditary units.A plasmid digene construction designed before [Tchuraev, R.N. (1982) J. Gen. Biol. 43, 79-87] has been realised, including feedback by repressing proteins with given trigger regime of gene functioning. Experimental tests of the expected epigene properties of the obtained pECPI recombinant plasmid involving lacI and cI(857) regulatory genes have shown a phenomenon of steady inheritance of two alternative epigenotypes lacI(1)cI(0) and lacI(0)cI(1), as well as an external toggle switch through metabolitic and temperature signals from one inherited functional state of the cyclic digene system into another. Thus, we have constructed a hereditary unit of a specific kind, namely, a two-component stationary epigene with preset properties."
"Engineering stability in gene networks by autoregulation. The genetic and biochemical networks which underlie such things as homeostasis in metabolism and the developmental programs of living cells, must withstand considerable variations and random perturbations of biochemical parameters. These occur as transient changes in, for example, transcription, translation, and RNA and protein degradation. The intensity and duration of these perturbations differ between cells in a population. The unique state of cells, and thus the diversity in a population, is owing to the different environmental stimuli the individual cells experience and the inherent stochastic nature of biochemical processes (for example, refs 5 and 6). It has been proposed, but not demonstrated, that autoregulatory, negative feedback loops in gene circuits provide stability, thereby limiting the range over which the concentrations of network components fluctuate. Here we have designed and constructed simple gene circuits consisting of a regulator and transcriptional repressor modules in Escherichia coli and we show the gain of stability produced by negative feedback. "
"Sample preparation in matrix-assisted laser desorption/ionization mass spectrometry of whole bacterial cells and the detection of high mass (>20 kDa) proteins.Three sample preparation strategies commonly employed in matrix-assisted laser desorption/ionization mass spectrometry (MALDI-TOFMS) of whole bacterial cells were investigated for the detection of high mass signals; these included the dried droplet, the seed-layer/two-layer, and the bottom-layer methods. Different sample preparation approaches favoured the detection of high- or low-mass proteins. The low-mass peaks were best detected using the bottom-layer method. By contrast, the dried droplet method using a solvent with higher water content, and hence effecting a slower crystallization process, gave the best results for the detection of high-mass signals. Signals up to m/z 158 000 could be detected with this methodology for Bacillus sphaericus. Sodium dodecyl sulphate polyacrylamide gel electrophoresis (SDS-PAGE) analysis of the same extracts used for MALDI-TOFMS showed bands in the molecular weight range in which high-mass peaks were observed in MALDI-MS, suggesting that the high-mass signals are not polymeric adducts of low-mass protein monomers. In addition, one of the high molecular weight proteins (approximately 126 kDa) was putatively identified as an S-layer protein by an in-gel tryptic digest. The bacterial samples spotted on the target wells for MALDI-TOFMS, using the different sample preparation strategies, were examined under a scanning electron microscope and differences were observed between the different strategies, suggesting that the nature of the crystals and the distribution of the analytes amidst the crystals could influence the spectral pattern observed in MALDI-TOFMS of whole bacterial cells. Finally, evidence is presented to indicate that, although the determinants are intact cells, cell lysis occurs both before and during the MALDI process."
"Formation and resuscitation of ""non-culturable"" cells of Rhodococcus rhodochrous and Mycobacterium tuberculosis in prolonged stationary phase.After growth of Rhodococcus rhodochrous in Sauton's medium, and further incubation for about 60 h in stationary phase, there was a transient (up to 5 log) decrease in the c.f.u. count, whereas the total count remained similar to its initial value. At the point of minimal viability, the most probable number (MPN) count was 10 times greater than the c.f.u. count. This difference was further magnified by 3-4 logs (giving values close to the total count) by incorporating supernatant taken from growing cultures. A small protein similar to Rpf (resuscitation-promoting factor of Micrococcus luteus) appeared to be responsible for some of the activity in the culture supernatant. The formation of ""non-culturable"" cells of the ""Academia"" strain of Mycobacterium tuberculosis was similarly observed following growth in Sauton's medium containing Tween 80 in sealed culture vessels, and further incubation for an extended stationary phase. This resulted in the formation, 4-5 months post-inoculation, of a homogeneous population of ostensibly ""non-culturable"" cells (zero c.f.u.). Remarkably, the MPN count for these cultures was 10(5) organisms ml(-1), and this value was further increased by one log using supernatant from an actively growing culture. Populations of ""non-culturable"" cells of Mycobacterium tuberculosis were also obtained by the filtration of ""clumpy"" cultures, which were grown in the absence of Tween 80. These small cells could only be grown in liquid medium (MPN) and their viability was enhanced by the addition of culture supernatant or Rpf. The ""non-culturable"" cells that accumulated during prolonged stationary phase in both the R. rhodochrous and the Mycobacterium tuberculosis cultures were small ovoid and coccoid forms with an intact permeability barrier, but with undetectable respiratory activity. The authors consider these non-culturable bacteria to be dormant. The observed activity of culture supernatants and Rpf with ""non-culturable"" bacterial suspensions invites the speculation that one, or more, of the cognate Mycobacterium tuberculosis Rpf-like molecule(s) could be involved in mechanisms of latency and reactivation of tuberculosis in vivo."
"The cytochrome P450 complement (CYPome) of Streptomyces coelicolor A3(2).In the present study we describe the complete cytochrome P450 complement, the ""CYPome,"" of Streptomyces coelicolor A3(2). Eighteen cytochromes P450 (CYP) are described, in contrast to the absence of CYPs in Escherichia coli, and the twenty observed in Mycobacterium tuberculosis. Here we confirm protein identity as cytochromes P450 by heterologous expression in E. coli and measurement of reduced carbon monoxide difference spectra. We also report on their arrangement in the linear chromosome and relatedness to other CYPs in the superfamily. The future development of manipulation of antibiotic pathways and the use of streptomycetes in bioremediation and biotransformations will involve many of the new CYP forms identified here."
"Histometrics: improvement of the dynamic range of fluorescently stained proteins resolved in electrophoretic gels using hyperspectral imaging.Most image-based analyses, using absorbance or fluorescence of the spatial distribution of identifiable structures in complex biological systems, use only a very small number of dimensions of possible spectral data for the generation and interpretation of the image. We here extend the concepts of hyperspectral imaging, being developed in remote sensing, into analytical biotechnology. The massive volume of information contained in hyperspectral spectroscopic images requires multivariate analysis in order to extract the chemical and spatial information contained within the data. We here describe the use of multivariate statistical methods to map and quantify common protein staining fluorophores (SYPRO Red, Orange and Tangerine) in electrophoretic gels. Specifically, we find (a) that the 'background' underpinning limits of detection is due more to proteins that have not migrated properly than to impurities or to ineffective destaining, (b) the detailed mechanisms of staining of SYPRO red and orange are apparently not identical, and in particular (c) that these methods can provide two orders of magnitude improvement in the detection limit per pixel, to levels well below the limit observable optically."
"Flow-injection electrospray ionization mass spectrometry of crude cell extracts for high-throughput bacterial identification.Flow-injection electrospray ionization mass spectrometry (FI-ESI-MS) of unfractionated cell-free extracts obtained from bacterial cells suspended in a solvent mixture was investigated as a rapid analytical method for reproducible, high-throughput bacterial identification. Five bacterial strains (two Escherichia coli, two Bacillus spp. and one Brevibacillus laterosporus) were studied in this investigation. Axenically grown bacterial cells were suspended in an acidic organic solvent and the cell-free extract was sequentially injected into a solvent flow stream that was sprayed into the ionization chamber of the ESI-MS. The spectra produced contained reproducible information, which was useful for discriminating between the bacteria. Tandem mass spectrometry was used to characterize further the peaks, and at least three classes of macromolecules, namely phospholipids, glycolipids, and proteins, were found to contribute most to the spectral information. Bacterial extracts stored under different conditions gave very similar mass spectra for each of the five bacterial strains, indicating that the extracts were stable even at room temperature for up to 24 h, with no loss of information content, which has obvious implications for automated high-throughput analysis. An analysis of the components of the extracting solvent mixture and their effects on the spectral information showed that acetonitrile contributes most significantly to the extraction process and hence to the information content of the spectra."
"Differentiation of Phytophthora infestans sporangia from other airborne biological particles by flow cytometry.The ability of two different flow cytometers, the Microcyte (Optoflow) and the PAS-III (Partec), to differentiate sporangia of the late-blight pathogen Phytophthora infestans from other potential airborne particles was compared. With the PAS-III, light scatter and intrinsic fluorescence parameters could be used to differentiate sporangia from conidia of Alternaria or Botrytis spp., rust urediniospores, and pollen of grasses and plantain. Differentiation between P. infestans sporangia and powdery mildew conidia was not possible by these two methods but, when combined with analytical rules evolved by genetic programming methods, could be achieved after staining with the fluorescent brightener Calcofluor white M2R. The potential application of these techniques to the prediction of late-blight epiphytotics in the field is discussed."
"Discrimination of aerobic endospore-forming bacteria via electrospray-lonization mass spectrometry of whole cell suspensions.Direct injection electrospray ionization mass spectrometry (ESI-MS) without prior analyte separation was investigated for the analysis of whole cell suspensions of bacteria. Thirty-six strains of aerobic endospore-forming bacteria, consisting of six Bacillus species and one Brevibacillus species, were studied"
Genomic computing. Explanatory analysis of plant expression profiling data using machine learning.
"Characterization of an autostimulatory substance produced by Escherichia coli.The recovery of dilute populations of stationary phase cells of Escherichia coli was studied using an automatic growth analyser. The addition of 30% supernatant from 2-d-old stationary phase cells of the organism reproducibly shortened the apparent lag times by 22-57.5%, depending on the age of the inoculum. True lag times, as determined by colony counts, of stationary phase cells were reduced by supernatant addition by 41-62%. The growth-stimulating substance was characterized and partly purified from supernatants: the active material was shown to be dialysable, heat-stable, acid- and alkali-stable and protease-resistant. Extraction with ethyl acetate or ion-exchange resins was not successful, but the active material could be quantitatively extracted with ethanol after saturation with salt. It is concluded that the active substance is a small, non-proteinaceous, non-ionic organic molecule. Separation of extracts by HPLC indicated that the stimulatory substance is weakly hydrophobic and has retention times similar to those of uracil. So far, however, the exact chemical identity of the active substance has not been elucidated."
"MEG (Model Extender for Gepasi): a program for the modelling of complex, heterogeneous, cellular systems.SUMMARY: We describe a program for the construction of spatially distributed metabolic models, which may then be simulated using the metabolic simulator GEPASI: This is useful for the modelling of heterogeneous systems whether as liquid cultures or as spatially organised systems with specified interconnections."
"On-line, real-time measurements of cellular biomass using dielectric spectroscopy."
"A functional genomics strategy that uses metabolome data to reveal the phenotype of silent mutations.A large proportion of the 6,000 genes present in the genome of Saccharomyces cerevisiae, and of those sequenced in other organisms, encode proteins of unknown function. Many of these genes are ""silent, "" that is, they show no overt phenotype, in terms of growth rate or other fluxes, when they are deleted from the genome. We demonstrate how the intracellular concentrations of metabolites can reveal phenotypes for proteins active in metabolic regulation. Quantification of the change of several metabolite concentrations relative to the concentration change of one selected metabolite can reveal the site of action, in the metabolic network, of a silent gene. In the same way, comprehensive analyses of metabolite concentrations in mutants, providing ""metabolic snapshots,"" can reveal functions when snapshots from strains deleted for unstudied genes are compared to those deleted for known genes. This approach to functional analysis, using comparative metabolomics, we call FANCY-an abbreviation for functional analysis by co-responses in yeast."
"Culturability of Mycobacterium tuberculosis cells isolated from murine macrophages: a bacterial growth factor promotes recovery.Very little is known about the culturability and viability of mycobacteria following their phagocytosis by macrophages. We therefore studied populations of the avirulent 'Academia' strain of Mycobacterium tuberculosis isolated from murine peritoneal macrophage lysates several days post-infection in vivo. The resulting bacterial suspensions contained a range of morphological types including rods, ovoid forms and coccoid forms. Bacterial viability measured using the MPN method (dilution to extinction in liquid medium) was often much higher than that measured by CFU (plating on solid medium). Viability in the MPN assay was further enhanced when the Micrococcus luteus protein, Rpf, was incorporated into the liquid culture medium at picomolar concentrations. Rpf is an example of a family of autocrine growth factors found throughout the high G+C cohort of Gram-positive bacteria including M. tuberculosis. M. tuberculosis cells obtained from macrophages had altered surface properties, as compared with bacteria grown in vitro. This was indicated by loss of the ability to adsorb bacteriophage DS6A, a reduced tendency to form clumps, acquisition of ethidium bromide stainability following heat treatment, and loss of Rpf-mediated resuscitation following freezing and thawing. These results indicate that a proportion of 'unculturable' M. tuberculosis cells obtained from macrophages is either injured or dormant and that these cells may be recovered or resuscitated using Rpf in liquid medium."
Bacterial dormancy and culturability: the role of autocrine growth factors.
"Correction of the influence of baseline artefacts and electrode polarisation on dielectric spectra.The deconvolution of biological dielectric spectra can be difficult enough with artefact-free spectra but is more problematic when machine baseline artefacts and electrode polarisation are present as well. In addition, these two sources of anomalies can be responsible for significant interference with dielectric biomass measurements made using one- or two-spot frequencies. The aim of this paper is to develop mathematical models of baseline artefacts and electrode polarisation which can be used to remove these anomalies from dielectric spectra in a way that can be easily implemented on-line and in real-time on the Biomass Monitor (BM). We show that both artefacts can be successfully removed in solutions of organic and inorganic ions; in animal cell and microbial culture media; and in yeast suspensions of varying biomass. The high quality of the compensations achieved were independent of whether gold and platinum electrodes were used; the electrode geometry; electrode fouling; current density; the type of BM; and of whether electrolytic cleaning pulses had been applied. In addition, the calibration experiments required could be done off-line using a simple aqueous KCl dilution series with the calibration constants being automatically calculated by a computer without the need for user intervention. The calibration values remained valid for a minimum of 3 months for the baseline model and indefinitely for the electrode polarisation one. Importantly, application of baseline correction prior to polarisation correction allowed the latter's application to the whole conductance range of the BM. These techniques are therefore exceptionally convenient to use under practical conditions."
"Non-linear dielectric spectroscopy: antifouling and stabilisation of electrodes by a polymer coating.Non-linear dielectric spectroscopy (NLDS) has previously been shown to produce quantitative information that is indicative of the metabolic state of various organisms, by modeling the non-linear effects of their membranous enzymes on an applied oscillating electromagnetic field using supervised multivariate analysis methods. However, the instability of the characteristics of the measuring apparatus rendered the process temperamental at best in the laboratory and impractical for field use. The main practical problem, of the non-stationarity of the electrode-solution interface and the ease with which the electrode surfaces are subject to protein fouling. It is addressed by applying a thin, electrically transparent antifouling coat to the electrodes. This reduces the interminable cleaning procedures previously required to prepare the electrodes for use, increases their usable lifetime before recleaning, and also improves the precision and linearity of multivariate models on NLDS data."
"Efficient improvement of silage additives by using genetic algorithms.The enormous variety of substances which may be added to forage in order to manipulate and improve the ensilage process presents an empirical, combinatorial optimization problem of great complexity. To investigate the utility of genetic algorithms for designing effective silage additive combinations, a series of small-scale proof of principle silage experiments were performed with fresh ryegrass. Having established that significant biochemical changes occur over an ensilage period as short as 2 days, we performed a series of experiments in which we used 50 silage additive combinations (prepared by using eight bacterial and other additives, each of which was added at six different levels, including zero [i.e. , no additive]). The decrease in pH, the increase in lactate concentration, and the free amino acid concentration were measured after 2 days and used to calculate a ""fitness"" value that indicated the quality of the silage (compared to a control silage made without additives). This analysis also included a ""cost"" element to account for different total additive levels. In the initial experiment additive levels were selected randomly, but subsequently a genetic algorithm program was used to suggest new additive combinations based on the fitness values determined in the preceding experiments. The result was very efficient selection for silages in which large decreases in pH and high levels of lactate occurred along with low levels of free amino acids. During the series of five experiments, each of which comprised 50 treatments, there was a steady increase in the amount of lactate that accumulated; the best treatment combination was that used in the last experiment, which produced 4.6 times more lactate than the untreated silage. The additive combinations that were found to yield the highest fitness values in the final (fifth) experiment were assessed to determine a range of biochemical and microbiological quality parameters during full-term silage fermentation. We found that these combinations compared favorably both with uninoculated silage and with a commercial silage additive. The evolutionary computing methods described here are a convenient and efficient approach for designing silage additives."
"On the optimization of classes for the assignment of unidentified reading frames in functional genomics programmes: the need for machine learning.At present, the assignment of function to novel genes uncovered by the systematic genome-sequencing programmes is a problem. Many studies anticipate that this can be achieved by analysing patterns of gene expression via the transcriptome, proteome and metabolome. Thus, functional genomics is, in part, an exercise in pattern classification. Because many genes have known functional classes, the problem of predicting their functional class is a supervised learning problem. However, most pattern classification methods that have been applied to the problem have been unsupervised clustering methods. Consequently, the best classification tools have not always been used. Furthermore, the present functional classes are suboptimal and new unsupervised clustering methods are needed to improve them. Better-structured functional classes will facilitate the prediction of biochemically testable functions."
"Detection of the dipicolinic acid biomarker in Bacillus spores using Curie-point pyrolysis mass spectrometry and Fourier transform infrared spectroscopy.Thirty-six strains of aerobic endospore-forming bacteria confirmed by polyphasic taxonomic methods to belong to Bacillus amyloliquefaciens, Bacillus cereus, Bacillus licheniformis, Bacillus megaterium, Bacillus subtilis (including Bacillus niger and Bacillus globigii), Bacillus sphaericus, and Brevi laterosporus were grown axenically on nutrient agar, and vegetative and sporulated biomasses were analyzed by Curie-point pyrolysis mass spectrometry (PyMS) and diffuse reflectance-absorbance Fourier-transform infrared spectroscopy (FT-IR). Chemometric methods based on rule induction and genetic programming were used to determine the physiological state (vegetative cells or spores) correctly, and these methods produced mathematical rules which could be simply interpreted in biochemical terms. For PyMS it was found that m/z 105 was characteristic and is a pyridine ketonium ion (C6H3ON+) obtained from the pyrolysis of dipicolinic acid (pyridine-2,6-dicarboxylic acid; DPA), a substance found in spores but not in vegetative cells; this was confirmed using pyrolysis-gas chromatography/mass spectrometry. In addition, a pyridine ring vibration at 1447-1439 cm-1 from DPA was found to be highly characteristic of spores in FT-IR analysis. Thus, although the original data sets recorded hundreds of spectral variables from whole cells simultaneously, a simple biomarker can be used for the rapid and unequivocal detection of spores of these organisms."
"Variable selection and multivariate methods for the identification of microorganisms by flow cytometry.BACKGROUND: When exploited fully, flow cytometry can be used to provide multiparametric data for each cell in the sample of interest. While this makes flow cytometry a powerful technique for discriminating between different cell types, the data can be difficult to interpret. Traditionally, dual-parameter plots are used to visualize flow cytometric data, and for a data set consisting of seven parameters, one should examine 21 of these plots. A more efficient method is to reduce the dimensionality of the data (e.g., using unsupervised methods such as principal components analysis) so that fewer graphs need to be examined, or to use supervised multivariate data analysis methods to give a prediction of the identity of the analyzed particles. MATERIALS AND METHODS: We collected multiparametric data sets for microbiological samples stained with six cocktails of fluorescent stains. Multivariate data analysis methods were explored as a means of microbial detection and identification. RESULTS: We show that while all cocktails and all methods gave good accuracy of predictions (>94%), careful selection of both the stains and the analysis method could improve this figure (to > 99% accuracy), even in a data set that was not used in the formation of the supervised multivariate calibration model. CONCLUSIONS: Flow cytometry provides a rapid method of obtaining multiparametric data for distinguishing between microorganisms. Multivariate data analysis methods have an important role to play in extracting the information from the data obtained. Artificial neural networks proved to be the most suitable method of data analysis."
"Rapid analysis of high-dimensional bioprocesses using multivariate spectroscopies and advanced chemometrics.There are an increasing number of instrumental methods for obtaining data from biochemical processes, many of which now provide information on many (indeed many hundreds) of variables simultaneously. The wealth of data that these methods provide, however, is useless without the means to extract the required information. As instruments advance, and the quantity of data produced increases, the fields of bioinformatics and chemometrics have consequently grown greatly in importance. The chemometric methods nowadays available are both powerful and dangerous, and there are many issues to be considered when using statistical analyses on data for which there are numerous measurements (which often exceed the number of samples). It is not difficult to carry out statistical analysis on multivariate data in such a way that the results appear much more impressive than they really are. The authors present some of the methods that we have developed and exploited in Aberystwyth for gathering highly multivariate data from bioprocesses, and some techniques of sound multivariate statistical analyses (and of related methods based on neural and evolutionary computing) which can ensure that the results will stand up to the most rigorous scrutiny."
"Rapid analysis of the expression of heterologous proteins in Escherichia coli using pyrolysis mass spectrometry and Fourier transform infrared spectroscopy with chemometrics: application to alpha 2-interferon production.Cell pastes and supernatant Escherichia coli samples, taken from an industrial bioprocess overproducing recombinant alpha 2 IFN were analysed using pyrolysis mass spectrometry (PyMS) and diffuse reflectance-absorbance Fourier transform infrared spectroscopy (FT-IR). PyMS and FT-IR are physico-chemical methods which measure predominantly the bond strengths of molecules and the vibrations of bonds within functional groups, respectively. They therefore give quantitative information about the total biochemical composition of the bioprocess sample. The interpretation of these hyperspectral data, in terms of the quantity of alpha 2 IFN in the cell pastes and supernatant samples was possible only after the application of the 'supervised learning' methods of artificial neural networks (ANNs) and partial least squares (PLS) regression. Both PyMS and FT-IR are novel, rapid and economical methods for the screening and the quantitative analysis of complex biological bioprocess over producing recombinant proteins. Models established using either spectral data set had a similarly satisfactory predictive ability. This shows that whole-reaction mixture spectral methods, which measure all molecules simultaneously, do contain enough information to allow their quantification when the entire spectra are used as the inputs to methods based on supervised learning. Moreover, this is the first study where FT-IR in the mid-IR range has been used to quantify the expression of a heterologous protein directly from fermentation broths and the first study to compare the abilities of PyMS and FT-IR for the quantitative analyses of an industrial bioprocess."
"Stimulation of the multiplication of Micrococcus luteus by an autocrine growth factor.Viable cells of Micrococcus luteus secrete a proteineous growth factor (Rpf) which promotes the resuscitation of dormant, nongrowing cells to yield normal, colony-forming bacteria. When washed M. luteus cells were used as an inoculum, there was a pronounced influence of Rpf on the true lag phase and cell growth on lactate minimal medium. In the absence of Rpf, there was no increase in colony-forming units for up to 10 days. When the inoculum contained less than 10(5) cells ml-1, macroscopically observable M. luteus growth was not obtained in succinate minimal medium unless Rpf was added. Incubation of M. luteus in the stationary phase for 100 h resulted in a failure of the cells to grow in lactate minimal medium from inocula of small size although the viability of these cells was close to 100% as estimated using agar plates made from lactate minimal medium or rich medium. The underestimation of viable cells by the most-probable-number (MPN) method in comparison with colony-forming units was equivalent to the requirement that at least 10(5) cells grown on succinate medium, 10(3) cells from old stationary phase, or approximately 10-500 washed cells are required per millilitre of inoculum for growth to lead to visible turbidity. The addition of Rpf in the MPN dilutions led to an increase of the viable cell numbers estimated to approximately the same levels as those determined by colony-forming units. Thus, a basic principle of microbiology - ""one cell-one culture"" - may not be applicable in some circumstances in which the metabolic activity of ""starter"" cells is not sufficient to produce enough autocrine growth factor to support cell multiplication."
"Genetic programming as an analytical tool for non-linear dielectric spectroscopy.By modelling the non-linear effects of membranous enzymes on an applied oscillating electromagnetic field using supervised multivariate analysis methods, Non-Linear Dielectric Spectroscopy (NLDS) has previously been shown to produce quantitative information that is indicative of the metabolic state of various organisms. The use of Genetic Programming (GP) for the multivariate analysis of NLDS data recorded from yeast fermentations is discussed, and GPs are compared with previous results using Partial Least Squares (PLS) and Artificial Neural Nets (NN). GP considerably outperforms these methods, both in terms of the precision of the predictions and their interpretability."
"Quantification of microbial productivity via multi-angle light scattering and supervised learning.This article describes the use of chemometric methods for prediction of biological parameters of cell suspensions on the basis of their light scattering profiles. Laser light is directed into a vial or flow cell containing media from the suspension. The intensity of the scattered light is recorded at 18 angles. Supervised learning methods are then used to calibrate a model relating the parameter of interest to the intensity values. Using such models opens up the possibility of estimating the biological properties of fermentor broths extremely rapidly (typically every 4 sec), and, using the flow cell, without user interaction. Our work has demonstrated the usefulness of this approach for estimation of yeast cell counts over a wide range of values (10(5)-10(9) cells mL-1), although it was less successful in predicting cell viability in such suspensions."
Revolutionary ideas come round again.
"On resuscitation from the dormant state of Micrococcus luteus.It has been found previously that a significant number of Micrococcus luteus cells starved in a prolonged stationary phase (up to 2 months) and then held on the bench at room temperature without agitation for periods of up to a further 2-7 months can be resuscitated in liquid media which contained (statistically) no initially-viable (colony-forming) cells but which were fortified with sterile supernatant from the late logarithmic phase of batch growth. Here it was found that such resuscitation can be done only within a defined time period after taking the first sample from such cultures, necessarily involving agitation of the cells. The duration of this period depends on the age of the starved culture: cells kept on the bench for 3 months possess a 2 month period of resuscitability while cells starved for 6 months can be resuscitated only within 10 days after the beginning of sampling. It is suggested that the input of oxygen to the starved cultures while they are agitated may exert a negative influence on the cells, since cultures stored in anaerobic conditions (under nitrogen) had a more prolonged 'survival' time. The cells which experienced between 10 and 60 days of starvation on the bench could be resuscitated, although the number of resuscitable cells depended strongly on the concentration of yeast extract in the resuscitation medium. This concentration for cells stored on the bench for more than 2 months was 0.05% while '1-month-old' cells displayed a maximum resuscitability in the presence of 0.01% of yeast extract. Application of the fluorescent probe propidium iodide revealed the formation of cells with a damaged permeability barrier if resuscitation was performed by using concentrations of yeast extract of 0.1% and above. Thus the successful resuscitation of bacterial cultures under laboratory conditions may need rather strictly defined parameters if it is to be successfully performed for the majority of cells in a population."
Systematic functional analysis of the yeast genome. The genome sequence of the yeast Saccharomyces cerevisiae has provided the first complete inventory of the working parts of a eukaryotic cell. The challenge is now to discover what each of the gene products does and how they interact in a living yeast cell. Systematic and comprehensive approaches to the elucidation of yeast gene function are discussed and the prospects for the functional genomics of eukaryotic organisms evaluated. 
"Viability and activity in readily culturable bacteria: a review and discussion of the practical issues.In microbiology the terms 'viability' and 'culturability' are often equated. However, in recent years the apparently self-contradictory expression 'viable-but-nonculturable' ('VBNC') has been applied to cells with various and often poorly defined physiological attributes but which, nonetheless, could not be cultured by methods normally appropriate to the organism concerned. These attributes include apparent cell integrity, the possession of some form of measurable cellular activity and the apparent capacity to regain culturability. We review the evidence relating to putative VBNC cells and stress our view that most of the reports claiming a return to culturability have failed to exclude the regrowth of a limited number of cells which had never lost culturability. We argue that failure to differentiate clearly between use of the terms 'viability' and 'culturability' in an operational versus a conceptual sense is fuelling the current debate, and conclude with a number of proposals that are designed to help clarify the major issues involved. In particular, we suggest an alternative operational terminology that replaces 'VBNC' with expressions that are internally consistent."
"A bacterial cytokine.Viable cells of Micrococcus luteus secrete a factor, which promotes the resuscitation and growth of dormant, nongrowing cells of the same organism. The resuscitation-promoting factor (Rpf) is a protein, which has been purified to homogeneity. In picomolar concentrations, it increases the viable cell count of dormant M. luteus cultures at least 100-fold and can also stimulate the growth of viable cells. Rpf also stimulates the growth of several other high G+C Gram-positive organisms, including Mycobacterium avium, Mycobacterium bovis (BCG), Mycobacterium kansasii, Mycobacterium smegmatis, and Mycobacterium tuberculosis. Similar genes are widely distributed among high G+C Gram-positive bacteria; genome sequencing has uncovered examples in Mycobacterium leprae and Mb. tuberculosis and others have been detected by hybridization in Mb. smegmatis, Corynebacterium glutamicum, and Streptomyces spp. The mycobacterial gene products may provide different targets for the detection and control of these important pathogens. This report is thus a description of a proteinaceous autocrine or paracrine bacterial growth factor or cytokine."
"Rapid identification of urinary tract infection bacteria using hyperspectral whole-organism fingerprinting and artificial neural networks.Three rapid spectroscopic approaches for whole-organism fingerprinting-pyrolysis mass spectrometry (PyMS), Fourier transform infra-red spectroscopy (FT-IR) and dispersive Raman microscopy--were used to analyse a group of 59 clinical bacterial isolates associated with urinary tract infection. Direct visual analysis of these spectra was not possible, highlighting the need to use methods to reduce the dimensionality of these hyperspectral data. The unsupervised methods of discriminant function and hierarchical cluster analyses were employed to group these organisms based on their spectral fingerprints, but none produced wholly satisfactory groupings which were characteristic for each of the five bacterial types. In contrast, for PyMS and FT-IR, the artificial neural network (ANN) approaches exploiting multi-layer perceptrons or radial basis functions could be trained with representative spectra of the five bacterial groups so that isolates from clinical bacteriuria in an independent unseen test set could be correctly identified. Comparable ANNs trained with Raman spectra correctly identified some 80% of the same test set. PyMS and FT-IR have often been exploited within microbial systematics, but these are believed to be the first published data showing the ability of dispersive Raman microscopy to discriminate clinically significant intact bacterial species. These results demonstrate that modern analytical spectroscopies of high intrinsic dimensionality can provide rapid accurate microbial characterization techniques, but only when combined with appropriate chemometrics."
"The deconvolution of pyrolysis mass spectra using genetic programming: application to the identification of some Eubacterium species.Pyrolysis mass spectrometry was used to produce complex biochemical fingerprints of Eubacterium exiguum, E. infirmum, E. tardum and E. timidum. To examine the relationship between these organisms the spectra were clustered by canonical variates analysis, and four clusters, one for each species, were observed. In an earlier study we trained artificial neural networks to identify these clinical isolates successfully; however, the information used by the neural network was not accessible from this so-called 'black box' technique. To allow the deconvolution of such complex spectra (in terms of which masses were important for discrimination) it was necessary to develop a system that itself produces 'rules' that are readily comprehensible. We here exploit the evolutionary computational technique of genetic programming; this rapidly and automatically produced simple mathematical functions that were also able to classify organisms to each of the four bacterial groups correctly and unambiguously. Since the rules used only a very limited set of masses, from a search space some 50 orders of magnitude greater than the dimensionality actually necessary, visual discrimination of the organisms on the basis of these spectral masses alone was also then possible."
"Discrimination between methicillin-resistant and methicillin-susceptible Staphylococcus aureus using pyrolysis mass spectrometry and artificial neural networks.Curie-point pyrolysis mass spectra were obtained from 15 methicillin-resistant and 22 methicillin-susceptible Staphylococcus aureus strains. Cluster analysis showed that the major source of variation between the pyrolysis mass spectra resulted from the phage group of the bacteria, not their resistance or susceptibility to methicillin. By contrast, artificial neural networks could be trained to recognize those aspects of the pyrolysis mass spectra that differentiated methicillin-resistant from methicillin-sensitive strains. The trained neural network could then use pyrolysis mass spectral data to assess whether an unknown strain was resistant to methicillin. These results give the first demonstration that the combination of pyrolysis mass spectrometry with neural networks can provide a very rapid and accurate antibiotic susceptibility testing technique."
"Fluorescent brighteners: novel stains for the flow cytometric analysis of microorganisms.Flow cytometry is a rapid method for measuring the optical properties of individual cells. The technique has found great utility in the study of mammalian cells, but microbiological applications have been more limited. We here show that UV-excited fluorescent whitening agents, in particular Tinopal CBS-X, are effective stains for both vegetative microbial cells and for spores of Gram-positive bacteria. Pretreatment of samples with ethanol speeds the staining process. Under favourable conditions, Tinopal CBS-X may be used to discriminate among organisms, a fact that may be useful when screening for a target microorganism against a high biological background."
"If you've got it, flaunt it--rapid screening for microbial biocatalysts."
"Flow cytometry and cell sorting of heterogeneous microbial populations: the importance of single-cell analyses.The most fundamental questions such as whether a cell is alive, in the sense of being able to divide or to form a colony, may sometimes be very hard to answer, since even axenic microbial cultures are extremely heterogeneous. Analyses that seek to correlate such things as viability, which is a property of an individual cell, with macroscopic measurements of culture variables such as ATP content, respiratory activity, and so on, must inevitably fail. It is therefore necessary to make physiological measurements on individual cells. Flow cytometry is such a technique, which allows one to analyze cells rapidly and individually and permits the quantitative analysis of microbial heterogeneity. It therefore offers many advantages over conventional measurements for both routine and more exploratory analyses of microbial properties. While the technique has been widely applied to the study of mammalian cells, is use in microbiology has until recently been much more limited, largely because of the smaller size of microbes and the consequently smaller optical signals obtainable from them. Since these technical barriers no longer hold, flow cytometry with appropriate stains has been used for the rapid discrimination and identification of microbial cells, for the rapid assessment of viability and of the heterogeneous distributions of a wealth of other more detailed physiological properties, for the analysis of antimicrobial drug-cell interactions, and for the isolation of high-yielding strains of biotechnological interest. Flow cytometric analyses provide an abundance of multivariate data, and special methods have been devised to exploit these. Ongoing advances mean that modern flow cytometers may now be used by nonspecialists to effect a renaissance in our understanding of microbial heterogeneity."
"What bio technologists knew all along...?Qualitative, trial-and-error methods designed to increase the flux to desirable biotechnological products have led to new technologies and vast improvements in existing ones. However, these methods now appear in many cases to have approached their limit. In addition, there is a strong feeling in industry that much of the recent boom in academic knowledge of biochemistry and molecular biology passes biotechnology by, simply because one cannot evaluate the implications of molecular kinetics for the functioning of the producer organisms as a whole. New methods, or more rational methods, are called for. One, aimed at increasing only the concentration of a single metabolite by site-directed mutagenesis is developed here."
Going places: forced and natural molecular evolution.
"Quantitative analysis of multivariate data using artificial neural networks: a tutorial review and applications to the deconvolution of pyrolysis mass spectra.The implementation of artificial neural networks (ANNs) to the analysis of multivariate data is reviewed, with particular reference to the analysis of pyrolysis mass spectra. The need for and benefits of multivariate data analysis are explained followed by a discussion of ANNs and their optimisation. Finally, an example of the use of ANNs for the quantitative deconvolution of the pyrolysis mass spectra of Staphylococcus aureus mixed with Escherichia coli is demonstrated."
"Rapid identification of Streptococcus and Enterococcus species using diffuse reflectance-absorbance Fourier transform infrared spectroscopy and artificial neural networks.Diffuse reflectance-absorbance Fourier transform infrared spectroscopy (FT-IR) was used to analyse 19 hospital isolates which had been identified by conventional means to one Enterococcus faecalis, E. faecium, Streptococcus bovis, S. mitis, S. pneumoniae, or S. pyogenes. Principal components analysis of the FT-IR spectra showed that this 'unsupervised' learning method failed to form six separable clusters (one of each species) and thus could not be used to identify these bacteria base on their FT-IR spectra. By contrast, artificial neural networks (ANNs) could be trained by 'supervised' learning (using the back-propagation algorithm) with the principal components scores of derivatised spectra to recognise the strains from their FT-IR spectra. These results demonstrate that the combination of FT-IR and ANNs provides a rapid, novel and accurate bacterial identification technique."
"Do bacteria need to communicate with each other for growth?It is usually assumed that most prokaryotes, when given appropriate nutrients, can grow and divide in the absence of other cells of the same species. However, recent studies have suggested that, for growth, prokaryotes need to communicate with each other using signalling molecules, and a variety of 'eukaryotic' hormones have been shown to stimulate bacterial growth. These observations have important implications for our understanding of bacterial pathogenicity."
"Why and when channelling can decrease pool size at constant net flux in a simple dynamic channel.Cornish-Bowden and Cárdenas (Cornish-Bowden, A. and Cárdenas M.L. (1993) Eur. J. Biochem. 213, 87-92) have suggested that simulation results peviously published by us (Mendes, P., Kell, D.B. and Westerhoff, H.V. (1992) Eur. J. Biochem. 204, 255-266) which had demonstrated that large reductions of intermediate pool sizes could be accompanied by increasing channel flux in a model metabolic pathway, were an artefact of changes in the pathway's overall flux of the order of 0.0075%, or of inappropriate alterations of enzyme activities. They also asserted to prove that the ""channelling of an intermediate cannot affect its free concentration at constant net flux"". We consider the co-response of the intermediate metabolite concentration ('pool') and the channel flux to changes in kinetic (or thermodynamic) parameters. Both by analytical proofs and by numerical examples we show that this co-response can be positive, negative or null, depending on the parameter change. In particular, we prove that there is always a number of ways of changing parameters such that the intermediate metabolite concentration decreases with increasing channel flux, whether the total flux varies or is constant. We also show that increased stability of the (dynamic) enzyme-intermediate-enzyme complex, as well as a single parameter change that similarly displays no cross-over effects, can lead to decreased intermediate metabolite concentration and increased channel flux at constant total flux. In general, a non-zero co-response of the intermediate metabolite concentration ('pool') and the channel flux to changes in kinetic (or other) parameters is the rule rather than the exception. More specifically: (i) The algebraic analysis ('general proof') given in Cornish-Bowden and Cárdenas (1993) contains the constraint that the elasticities of various steps to the modulation parameters which were used to vary the channel flux at constant net flux were unity. This is an unfortunate and unnecessary constraint which, when lifted, means that the concentration of the pool in the general case can indeed change at constant net flux. A 'simplified proof' given in Cornish-Bowden and Cárdenas (1993) also fails, due in addition to the consequent failure to include mass conservation relations for some of the enzymes. (ii) In the systems studied by Cornish-Bowden and Cárdenas (1993), flux is properly to be considered as a variable (since it varies during the transition to the steady state), and not a parameter, and as such cannot per se affect the magnitude of other variables in the steady state. (iii) By relaxing the constraint referred to in (i), above, and by making dual modulations (i.e., of more than one parameter at once) which are different from those carried out in Cornish-Bowden and Cárdenas (1993) we find many instances in which channelling (described by a parameter p) does significantly affect the concentration of the pool intermediate C at constant total flux. (iv) In the same pathways, but in which the flux is held constant by setting it via a zero-order flux-generating reaction, the addition of a channel is also able to significantly to modulate the size of the pool at constant total flux. Our results show that the effectiveness of channelling in decreasing a pool, even at constant flux, is very much a reality."
Pyrolysis mass spectrometry and its applications in biotechnology.Pyrolysis mass spectrometry is a rapid and high-resolution method for the analysis of otherwise non-volatile material and has been widely applied for discriminating between closely related microbial strains. Recent advances in statistical and neural network methods based on supervised learning have now permitted exploitation of pyrolysis mass spectrometry in the quantitative analysis of many diverse samples of biotechnological interest; the technique may thus be regarded as an 'anything-sensor'.
"Correction of mass spectral drift using artificial neural networks.For pyrolysis mass spectrometry (PyMS) to be used for the routine identification of microorganisms, for quantifying determinands in biological and biotechnological systems, and in the production of useful mass spectral libraries, it is paramount that newly acquired spectra be compared to those previously collected. Neural network and other multivariate calibration models have been used to relate mass spectra to the biological features of interest. As commonly observed, however, mass spectral fingerprints showed a lack of long-term reproducibility, due to instrumental drift in the mass spectrometer; when identical materials were analyzed by PyMS at dates from 4 to 20 months apart, neural network models produced at earlier times could not be used to give accurate estimates of determinand concentrations or bacterial identities. Neural networks, however, can be used to correct for pyrolysis mass spectrometer instrumental drift itself, so that neural network or other multivariate calibration models created using previously collected data can be used to give accurate estimates of determinand concentration or the nature of bacteria (or, indeed, other materials) from newly acquired pyrolysis mass spectra. This approach is not limited solely to pyrolysis mass spectrometry but is generally applicable to any analytical tool which is prone to instrumental drift, such as IR, ESR, NMR and other spectroscopies, and gas and liquid chromatography, as well as other types of mass spectrometry."
"On the analysis of the inverse problem of metabolic pathways using artificial neural networks.Here we develop the use of artificial neural networks for solving the inverse metabolic problem, in other words, given a set of steady-state metabolite levels and fluxes in a pathway of known structure to obtain the parameters of the system, in this case the enzymatic limiting rate and Michaelis constants. This requires two main procedures: first the development of a computer program with which one can model metabolism in the forward direction (i.e. given the internal and parameters to determine the steady-state fluxes and metabolite concentrations), and second, given arrays of associated parameters and variables thereby obtained, to exploit artificial neural networks to form a model capable of obtaining the parameters from the variables. We studied 2-step pathways exhibiting first-order kinetics, 2-step pathways exhibiting reversible Michaelis-Menten kinetics and then 3-step pathways (again exhibiting reversible Michaelis-Menten kinetics), modelled using the program Gepasi. Whilst it was fairly easy for the networks to learn most of the parameters in the 2-step pathway, it was found helpful for the Michaelis-Menten case to vary the concentration of the starting pathway substrate for each set of internal parameters, and to train separate networks for each parameter. Some parameters were much easier to learn than others, reverse K(m) and V(max) values normally being the most difficult. For the 3-step pathway learning sometimes required as much as 3 days, and occasionally convergence was not obtained. Overall, neural networks of the present type, with fully interconnected feedforward architectures and trained according to the backpropagation algorithm, scaled poorly as the problem size was increased."
"Oscillatory, stochastic and chaotic growth rate fluctuations in permittistatically controlled yeast cultures.We describe a continuous culture system related to the turbidostat, but using a feedback system based on biomass estimation from the dielectric permittivity of the cell suspension rather than its optical density. It is shown that this system provides an excellent method of maintaining a constant biomass level within a fermentor. The computer-controlled system was able to effect the essentially continuous registration of growth rate by monitoring the rate of medium addition via the time-dependent activity of the pump. At some biomass setpoints for aerobically grown cultures of baker's yeast substantial time-dependent fluctuations in the growth rate of the culture were thereby observed. At some biomass setpoints, however, or under anaerobic conditions, or when using a non-Crabtree yeast, the growth rate was constant, indicating that the fluctuations were inherent to the biological system and not simply a property of the fermentor and control system. A variety of time series analyses (Fourier transformations, Hurst and Lyapunov exponents, the determination of embedding dimension, and non-linear time series predictions based on the methodology of Sugihara and May) were used to demonstrate, for the first time, that as well as stochastic and periodic components these fluctuations exhibited deterministic chaos. 'Trivial predictors' were unable to give accurate predictions of the growth rate in these cultures. The growth rate fluctuations were studied further by means of offline measurements of changes in percentage viability, bud count, and in the external ethanol and glucose concentrations; these data and other evidence suggested that the growth rate fluctuations were closely linked to the primary respiro-fermentative metabolism of this organism. The identification of chaotic growth rates in cell cultures suggests that there may be novel methods for controlling the growth of such cultures."
A series of cases in which metabolic channelling can decrease the pool size at constant net flux in a simple dynamic channel.
"Secretion of an antibacterial factor during resuscitation of dormant cells in Micrococcus luteus cultures held in an extended stationary phase.A high proportion of Micrococcus luteus cells in cultures starved for 3-6 months in spent medium following growth to stationary phase in batch culture lost the ability to grow and form colonies on agar plates, but could be resuscitated from dormancy by incubation in liquid medium containing supernatant taken from the late log phase of viable cultures of the same organism (Kaprelyants et al. 1994). In the present work, we found that during the first 50-70 h of such resuscitation the dormant cells actually divide for 10-17 generations in lactate minimal medium containing yeast extract whilst remaining nonculturable on agar plates. Further incubation results in a decrease in the total cell number in liquid medium. The addition of viable (culturable) Micrococcus luteus cells in concentrations of up to 10(4) ml-1 to test tubes containing either resuscitating cells or supernatant from these cultures revealed the excretion of a factor or factors which inhibited the proliferation of otherwise viable cells. The maximum production of this factor took place after some 96 h of incubation of starved cells in resuscitation medium. Supernatant from late logarithmic phase batch cultures of M. luteus abolished the antibacterial effect of starved cultures incubated in resuscitation medium. It is concluded that the stimulating effect of viable cells, and of supernatant taken from batch cultures, on the resuscitation of dormant cells might be connected in part with overcoming the activity of an antibacterial factor causing self-poisoning of dormant cells during their resuscitation."
"The use of dielectric permittivity for the control of the biomass level during biotransformations of toxic substrates in continuous culture.Since the permittivity signal of a cell suspension measured using dielectric spectroscopy at radio frequencies is essentially determined only by viable (intact) cells, it can be used to monitor the concentration of viable cells in a fermentor in which a large proportion of the cells is nonviable. This could be used to select for organisms that are highly resistant to stress, for example from toxic chemicals used in biotransformations. We sought to control the concentration of viable yeast cells in a fermentor by adding small amounts of benzaldehyde, thus imposing a selection regime for cells highly resistant to benzaldehyde. However, after the addition of benzaldehyde, an increase in the permittivity is seen first followed by a decrease, thus making the control of biomass using a standard on-off controller difficult. It is shown that it is possible effectively to control the level of viable biomass in the fermentor in the presence of a large concentration of necromass using a combination of an inverse response compensator and a PID controller."
"Solvent selection for whole cell biotransformations in organic media.Although they were used historically as antimicrobial agents, there is a modern requirement to devise organic solvent systems for exploitation in the biotransformation by intact cells of substrates that are poorly soluble in water. Water-immiscible solvents are normally less cytotoxic than are water-miscible ones. While a unitary mechanism is excluded, damage to the membrane remains the likeliest major mechanism of cytotoxicity, and may be conveniently assessed using an electronic biomass probe. Studies designed to account for the mechanisms of action of general anesthetics and of uncouplers parallel those designed to account for the cytotoxicity of organic solvents. Although there are hundreds of potential physical descriptors of solvent properties, many are broadly similar to each other, such that the intrinsic dimensionality of solvent space is relatively small (< 10). This opens up the possibility of providing a rational biophysical basis for the optimization of the solvents used for biotransformations. The widely used descriptor of solvent behavior, log P (the octanol:water partition coefficient), is a composite of more fundamental molecular descriptors; this explains why there are rarely good correlations between cytotoxicity and log P when a wide variety of solvents is studied. Although the intrinsic dimensionality of solvent space is relatively small, pure solvents still populate it rather sparsely. Thus, mixtures of solvents can and do provide the opportunity of obtaining a solvent optimal for a biotransformation of interest."
On harmonic generation in nonlinear biological systems.
The dogs that did not bark.
"Rapid and quantitative analysis of recombinant protein expression using pyrolysis mass spectrometry and artificial neural networks: application to mammalian cytochrome b5 in Escherichia coli.Recombinant Escherichia coli clones encoding between 0 and 6 copies of the mammalian cytochrome b5 gene were subjected to pyrolysis mass spectrometry (PyMS). To deconvolute the pyrolysis mass spectra so as to obtain quantitative information on the amount of cytochrome b5 produced fully-interconnected feedforward artificial neural networks (ANNs) were studied. It was found that the combination of PyMS and ANNs could be used to predict the amount of cytochrome b5 expressed in E. coli. PyMS is a novel, convenient and rapid method for the screening and analysis of microbial and other cultures producing recombinant proteins."
"Rapid identification using pyrolysis mass spectrometry and artificial neural networks of Propionibacterium acnes isolated from dogs.Curie-point pyrolysis mass spectra were obtained from reference Propionibacterium strains and canine isolates. Artificial neural networks (ANNs) were trained by supervised learning (with the back-propagation algorithm) to recognize these strains from their pyrolysis mass spectra; all the strains isolated from dogs were identified as human wild type P. acnes. This is an important nosological discovery, and demonstrates that the combination of pyrolysis mass spectrometry and ANNs provides an objective, rapid and accurate identification technique. Bacteria isolated from different biopsy specimens from the same dog were found to be separate strains of P. acnes, demonstrating a within-animal variation in microflora. The classification of the canine isolates by Kohonen artificial neural networks (KANNs) was compared with the classical multivariate techniques of canonical variates analysis and hierarchical cluster analysis, and found to give similar results. This is the first demonstration, within microbiology, of KANNs as an unsupervised clustering technique which has the potential to group pyrolysis mass spectra both automatically and relatively objectively."
"Dielectric properties of human blood and erythrocytes at radio frequencies (0.2-10 MHz); dependence on cell volume fraction and medium composition.The dielectric properties of human erythrocytes (red blood cells) suspended in whole blood and in isotonic media at various volume fractions (haematocrits) have been studied in the frequency range 0.2-10 MHz, in which the so-called beta-dispersion due to the Maxwell-Wagner effect is known to occur. The capacitance and conductance at 25 degrees C were measured by an instrument interfaced to a computer. The rectangular sample cavity (1 ml volume) contained four pure gold electrode pins, and the sample could be circulated by a roller pump. The frequency-dependence of the permittivity and conductivity were fitted by non-linear least squares regression. Corrections were applied for non-linearity in the dielectric increment at high haematocrit, and for electrode polarisation when diluting the blood in saline. Data were interpreted in terms of a simple equivalent resistor-capacitor circuit. From the measured haematological values the specific membrane capacitance (Cm) and the conductivities internal and external to the cells (sigma i' and sigma o' respectively) were estimated. The conductivities behaved in a predictable manner with a mean of 0.458 S.m-1 (s.d. +/- 0.044) for sigma i', whereas the value of Cm (and indeed the actual capacitance of the suspension) was dependent on the amount of plasma present. Hence, in stationary normal (anticoagulated) whole blood samples, Cm was as high as 2.98 mu F.cm-2 (s.d. +/- 0.40), in contrast to about 0.9 mu F.cm-2 in blood diluted more than two-fold (to less than 20% hct) in isotonic media. The high value remained when the diluent was plasma.(ABSTRACT TRUNCATED AT 250 WORDS)"
"On the role of enzyme kinetic parameters in determining the effectiveness with which channelling can decrease the size of a metabolite pool.Recently, it has been argued that the phenomenon of direct transfer of intermediate metabolites between adjacent enzymes, also known as metabolic channelling, would not decrease the concentration of those intermediates in the 'bulk' solution. However, this conclusion has been drawn by extrapolation from the results of simulations with a rather restricted set of parameters. We show that, for a number of kinetic cases, the existence of metabolic channelling can decrease the size of the soluble pool of intermediates. When the enzyme(s) 'downstream' of the channel have a catalytic capacity that is large relative to the enzymes 'upstream' of the channel, the decrease of concentration can be substantial (3 orders of magnitude)."
Dormancy in non-sporulating bacteria.
"New materials and technology for cell immobilization.The choice of the most effective manner in which to operate an immobilized cell system is both complicated and, to some extent, a matter of guesswork. There is increasing awareness of the factors affecting reactor choice, and present work is aimed at making reactor performance more predictable."
"Channelling can decrease pool size.It is widely considered that a possible advantage of metabolite channelling, in which a product of an enzyme is transferred to the next enzyme in a metabolic pathway without being released to the 'bulk' solution, is that channelling can decrease the steady-state concentrations of 'pool' intermediates. This then spares the limited solvent capacity of the cell, and reduces the loss of pathway flux due to leakage or instability of the free intermediate. Recently, however, based on simulations of a particular model of a 'dynamic' channel, Cornish-Bowden [""Failure of channelling to maintain low concentrations of metabolic intermediates"" (1991) Eur. J. Biochem. 195, 103-108] has argued that this is not in fact the case; his simulations indicated that the channel was rather ineffective at decreasing the concentration of the pool intermediate, and in some cases actually increased it. However, although his simulations were restricted to very specific thermodynamic and kinetic parameters, he generalised his conclusions, arguing that ""channelling has no effect on the free concentration of a channelled intermediate in a pathway"". By showing that, for a number of kinetic cases, the concentration of the pool intermediate did decrease substantially with increased channelling, we demonstrate here that the conclusion of Cornish-Bowden is not correct. In particular, if the reaction catalysed by the enzymes forming the channel has an equilibrium constant K higher than 1, and if the enzyme removing the product of the channel reaction is kinetically competent, channelling in the model system studied by Cornish-Bowden (1991) can decrease the steady-state concentration of the pool by a factor of 1000, independently of the mechanism of the terminal reaction and under conditions of essentially constant overall flux. If the channel is a 'static' channel, the decrease in the pool can be to arbitrarily low levels. This conclusion also holds for a system in which other reactions may consume the pool intermediate. Thus, channelling can maintain metabolite concentrations at low levels."
The protonmotive force as an intermediate in electron transport-linked phosphorylation: problems and prospects.
"Confirmation by using mutant strains that the membrane-bound H(+)-ATPase is the major source of non-linear dielectricity in Saccharomyces cerevisiae.Non-linear dielectric spectroscopy is a novel technique for determining the activity of (predominantly) membranous enzymes as their ability to generate harmonics when excited with a sinusoidal electrical field. In washed suspensions of yeast cells, the ability to generate harmonics is inhibited by low concentrations of sodium vanadate, suggesting that the vanadate-sensitive H(+)-ATPase is the major source of the non-linear dielectricity. This conclusion is greatly strengthened by the demonstration herein that the generation of harmonics by a strain containing a vandate-resistant H(+)-ATPase is also highly resistant to sodium metavanadate."
"Quantifying heterogeneity: flow cytometry of bacterial cultures.Flow cytometry is a technique which permits the characterisation of individual cells in populations, in terms of distributions in their properties such as DNA content, protein content, viability, enzyme activities and so on. We review the technique, and some of its recent applications to microbiological problems. It is concluded that cellular heterogeneity, in both batch and continuous axenic cultures, is far greater than is normally assumed. This has important implications for the quantitative analysis of microbial processes."
"Quantitative approaches to the analysis of the control and regulation of microbial metabolism.Recently, a number of novel ways of considering the control, regulation and thermodynamics of microbial physiology have been developed and applied. We here present an overview of the new concepts involved, of their limitations and of the most recent attempts to deal with those limitations. We conclude that there no longer exist reasons of principle for vagueness in discussions of the control of microbial physiology and energetics. Further, the novel conceptual methods serve to remove part of the discordance between holistic and reductionistic views of microbial physiology."
"On the physiological significance of metabolite channelling: if, how, and where, but not why."
"New materials and technology for cell immobilization.The choice of support materials for immobilizing cells is rapidly expanding. The literature that has appeared over the past year suggests that hydrogels will remain the first choice for the forseeable future, even though they are associated with many widely recognized problems. There is increasing interest in the use of tougher polymeric materials, and especially of inorganic ceramic supports. However, the most suitable cell support can be selected only after the process or form of reactor in which it is to be used has been assessed."
"Hydrodynamic deposition: a novel method of cell immobilization.A novel method of cell immobilization is described. The cell support consists of ceramic microspheres of approximately 50-75 microns diameter. The spheres are hollow, having a wall thickness of 10-15 microns and one entrance (ca. 20 microns diameter). The walls are porous with a mean pore size of approximately 90 nm. When a cell suspension (of S. cerevisiae) is passed through a column of such particles, cells are immobilized. Conditions are devised such that the overwhelming majority of cells are held in the central cavity of the support and not between the particles. Provided turbulence is avoided, the distribution of cells along the column length in the steady state is rather homogeneous. The facts that (a) essentially all particles, regardless of orientation, entrap cells, and (b) nonporous particles also entrap cells with high efficiency, indicate that filtration effects are irrelevant and that heretofore unrecognized hydrodynamic forces are alone responsible for the cell immobilization. Cells can be immobilized to high biomass densities, while the hydrodynamic properties of columns containing such immobilized cells are excellent. We describe an on-line electronic method for the real-time measurement of immobilized cellular biomass. Cell growth (so recorded) and metabolism continue to occur in such particles at high rates. Using the glycolytic production of ethanol by S. cerevisiae as a model reaction, volumetric productivities as great as any published are obtained. Thus the ""lobster-pot effect"" or ""hydrodynamic deposition"" represents a novel, promising, and generally applicable method of cell immobilization."
The inhibition by CO2 of the growth and metabolism of micro-organisms.
"The passive electrical properties of biological systems: their significance in physiology, biophysics and biotechnology."
"The roles of osmotic stress and water activity in the inhibition of the growth, glycolysis and glucose phosphotransferase system of Clostridium pasteurianum.Growth of Clostridium pasteurianum was inhibited in media of high solute content. At equal osmolarities, 'permeant' solutes (glycerol and acetamide) were much less growth-inhibitory than 'non-permeant' solutes (KC1 and xylitol). Glycolysis by washed cell suspensions was inhibited by these solutes in parallel with growth. However, in their inhibition of glucose 6-phosphate dissimilation by permeabilized cells the distinction between 'permeant' and 'impermeant' solutes was significantly less marked. The glucose phosphotransferase system (PTS) of intact cells was much more strongly inhibited by 'non-permeant' than by 'permeant' solutes. It was concluded that the predominant inhibitory effects on this organism of media of high solute content are due not to the low water activity of such media per se, but to the creation of an osmotic pressure across the bacterial cytoplasmic membrane, which acts to inhibit the glucose PTS by which the organism effects glucose uptake. Parallel measurements of the effects of xylitol on both glycolysis and the activity of the glucose PTS suggested that despite this correlation between the osmotic inhibition of growth, glycolysis and the PTS, the flux-control coefficient of the PTS on glycolysis did not exceed 0.2 under the conditions used."
"The physiology of Clostridium sporogenes NCIB 8053 growing in defined media.The physiology of Clostridium sporogenes was investigated in defined, minimal media. In batch culture, the major end products of glucose dissimilation were acetate, ethanol and formate. When L-proline was present as an electron acceptor, acetate production was strongly enhanced at the expense of ethanol. As judged by assay of the relevant enzymes, glucose was metabolized via the Embden-Meyerhof-Parnas pathway. The growth energetics of Cl. sporogenes were investigated in glucose- or L-valine-limited chemostat cultures. In the former case, the addition of L-proline to the medium caused a significant increase in the molar growth yield (as calculated by extrapolation to infinite dilution rate). This finding adds weight to the view that the reduction of L-proline by Cl. sporogenes is coupled to the conservation of free energy."
"The growth and nutrition of Clostridium sporogenes NCIB 8053 in defined media.Various defined and minimal media are described for the growth of Clostridium sporogenes NCIB 8053. The organism requires 10 amino acids and one vitamin for growth, whilst three other vitamins are growth stimulatory. L-alpha-hydroxy acid analogues can replace eight, and fatty acid analogues four, of these amino acids. The organism may generate free energy by a variety of Stickland reactions. Most Stickland acceptors, but not glycine, stimulate the growth of this organism on glucose. Nonetheless, cells grown in the presence of glycine will reductively deaminate it. The media described support the growth of several other strains of this species. The simplified growth media which we have developed permit quantitative studies of the physiology of this organism."
On the lateral mobility of proteins in prokaryotic membranes.
Uncoupler titrations in co-reconstituted systems do not discriminate between localized and delocalized mechanisms of photo-phosphorylation.
Localized protonic coupling: overview and critical evaluation of techniques.
"On the dielectrically observable consequences of the diffusional motions of lipids and proteins in membranes. 1. Theory and overview.A system consisting of any array of cylindrical, polytopic membrane proteins (or protein complexes) possessed of a permanent dipole moment and immersed in a closed, spherical phospholipid bilayer sheet is considered. It is assumed that rotation of the protein (complex) in a plane normal to the membrane, if occurring, is restricted by viscous drag alone. Lateral diffusion is assumed either to be free and random or to be partially constrained by barriers of an unspecified nature. The dielectric relaxation times calculated for membrane protein rotation in a suspension of vesicles of the above type are much longer than those observed with globular proteins in aqueous solution, and fall in the mid-to-high audio frequency range. If the long range lateral diffusion of (charged) membrane protein complexes is essentially unrestricted, as in the ""fluid mosaic"" membrane model, dielectric relaxation times for lateral motions will lie, except in the case of the very smallest vesicles, in the sub-audio (ELF) range. If, in contrast, the lateral diffusion of membrane protein complexes is partially restricted by ""barriers"" or ""long-range"" interactions (of unspecified nature), significant dielectric dispersions may be expected in both audio- and radio-frequency ranges, the critical (characteristic) frequencies depending upon the average distance moved before a barrier is encountered. Similar analyses are given for rotational and translational motions of phospholipids. At very low frequencies, a dispersion due to vesicle orientation might in principle also be observed; the dielectrically observable extent of this rotation will depend, inter alia, upon the charge mobility and disposition of the membrane protein complexes, as well as, of course, on the viscosity of the aqueous phase. The role of electroosmotic interactions between double layer ions (and water dipoles) and proteins raised above the membrane surface is considered. In some cases, it seems likely that such interactions serve to raise the dielectric increment, relative to that which might otherwise have been expected, of dispersions due to protein motions in membranes. Depending upon the tortuosity of the ion-relaxation pathways, such a relaxation mechanism might lead to almost any characteristic frequency, and, even in the absence of protein/lipid motions, would cause dielectric spectra to be much broader than one might expect from a simple, macroscopic treatment."
"On the dielectrically observable consequences of the diffusional motions of lipids and proteins in membranes. 2. Experiments with microbial cells, protoplasts and membrane vesicles.The dielectric properties of suspensions of intact cells of Methylophilus methylotrophus, Paracoccus denitrificans and Bacillus subtilis have been measured in the frequency range 1 kHz to 13 MHz. All possess a pronounced dispersion corresponding in magnitude and relaxation time to the ""beta-dispersion"" in a terminology defined by Schwan [Adv. Biol. Med. Phys. 5:147-209 (1957)]. The latter two strains, but not M. methylotrophus, also possess a substantial alpha-dispersion. The relaxation time of the beta-dispersion of B. subtilis is significantly lower than that of the other two strains, due to the higher internal K+ content of this Gram-positive organism. Treatment of P. denitrificans or B. subtilis with lysozyme greatly reduces the magnitude of the alpha-dispersion; in the latter case it is virtually abolished. The magnitude of both the alpha- and beta-dispersions of protoplasts of these organisms is significantly decreased by treatment with the cross-linking reagent glutaraldehyde, indicating that diffusional motions of the lipids and/or proteins in the protoplast membranes contribute to the dielectric relaxations observed in this frequency range. Such motions cannot be unrestricted, as in the ""fluid mosaic"" model, since the relaxation times of the lipids and proteins, if restricted by hydrodynamic forces alone, should then correspond, in protoplasts of this radius (0.4-0.5 micron), to approximately 10 Hz. Even after treatment of the (spherical) protoplasts with glutaraldehyde, the breadth of the remaining beta-dispersion is still significantly greater than (a) that of a pure Debye dispersion and (b) that to be expected solely from a classical Maxwell-Wagner-type mechanism. It is recognised that the surfaces of the protein complexes in such membranes extend significantly beyond the membrane surface as delineated by the phospholipid head-groups; such molecular granularity can in principle account for the broadened dielectric relaxations in the frequency range above 1 kHz, in terms of the impediment to genuinely tangential counterion relaxation caused by the protruding proteins themselves. The relaxation time of a previously observed, novel, low-frequency, glutaraldehyde-sensitive (mu-) dispersion in bacterial chromatophore suspensions, as well as that of their alpha-dispersion, is significantly increased by increasing the aqueous viscosity with glycerol. This finding is consistent with the view that, from a dielectric standpoint, the motions of charged proteins (and lipids) in biological membranes are rather tightly coupled to those of the adjacent ions and dipoles in the electric double layer.(ABSTRACT TRUNCATED AT 400 WORDS)"
"The estimation of microbial biomass.Methods that have been used to estimate the content, and in some cases the nature, of the microbial biomass in a sample are reviewed. The methods may be categorised in terms of their principle (physical, chemical, biological or mathematical/computational), their speed (real-time or otherwise) and the amount of automation/expense involved. For sparse populations, where the output signal is to be enhanced by growth of the organisms, physical, chemical and biological approaches may be of equal merit, whilst in systems, such as laboratory and industrial fermentations, in which the microbial biomass content is high, physical methods (alone) can permit the real-time estimation of microbial biomass."
"A minimal hypothesis for membrane-linked free-energy transduction. The role of independent, small coupling units.Experimental data are reviewed that are not in keeping with the scheme of 'delocalized' protonic coupling in membrane-linked free-energy transduction. It turns out that there are three main types of anomalies: (i) rates of electron transfer and of ATP synthesis do not solely depend on their own driving force and on delta mu H, (ii) the ('static head') ratio of delta Gp to delta mu H varies with delta mu H and (iii) inhibition of either some of the electron-transfer chains or some of the H+-ATPases, does not cause an overcapacity in the other, non-inhibited proton pumps. None of the earlier free-energy coupling schemes, alternative to delocalized protonic coupling, can account for these three anomalies. We propose to add a fifth postulate, namely that of the coupling unit, to the four existing postulates of 'delocalized protonic coupling' and show that, with this postulate, protonic coupling can again account for most experimental observations. We also discuss: (i) how experimental data that might seem to be at odds with the 'coupling unit' hypothesis can be accounted for and (ii) the problem of the spatial arrangement of the electrical field in the different free-energy coupling schemes."
"The antibacterial action of Tinopal AN.The bactericidal activity of Tinopal AN [1,1-bis(3,N-5-dimethyl-benzoxazol-2-yl)-methine p-toluene sulphonate] was shown to be due to a mechanism entirely independent of its inhibitory effects upon NADH dehydrogenase which were reported previously. Whereas the compound had no significant effect upon DNA synthesis in Escherichia coli D22, RNA and protein synthesis were immediately and markedly inhibited. In confirmation, Tinopal AN caused an immediate cessation in inducible beta-galactosidase synthesis in the same organism. An in vitro assay of the transcription of calf-thymus DNA by purified E. coli RNA polymerase showed that this process was inhibited by Tinopal AN."
"On the effects of thiocyanate and venturicidin on respiration-driven proton translocation in Paracoccus denitrificans.A fast-responding O2 electrode has been used to confirm and extend observations of a significant kinetic discrepancy between O2 reduction and consequent proton translocation in 'O2-pulse' experiments in intact cells of P. denitrificans. The permeant, chaotropic SCN- ion abolishes this discrepancy, and greatly increases the observable----H+/O ratio, to a value approaching its accepted, true, limiting stoichiometry. The observable H+ decay rates are very slow, particularly in the absence of SCN-. The submaximal----H+/O ratios observed in the absence of SCN- are essentially independent of the size of the O2 pulse, in a manner not easily explained by a delocalised chemiosmotic energy-coupling scheme. Osmotically active protoplasts of P. denitrificans do not show a significant kinetic discrepancy between O2 reduction and H+ translocation, even in the the absence of SCN-. However, the submaximal----H+/O ratios observed in the absence of SCN- are again essentially independent of the size of the O2 pulse. As in intact cells, the observable H+ decay rates are very slow. The energy-transfer inhibitor venturicidin causes a significant increase in the----H+/O ratio observed in protoplasts of P. denitrificans in the absence of SCN-; the decay kinetics of the H+ translocation process are also somewhat modified. Nevertheless, the----H+/O ratio observed in the presence of venturicidin is also independent of the size of the O2 pulse. This observation militates further against arguments in which (a) a non-ohmic leak of protons from the bulk aqueous phase might alone be the cause of the low----H+/O ratios observed in the absence of SCN-, and (b) in which there might be a delta p-dependent change ('redox slip') in the actual----H+/O ratio. It is concluded that the observable protonmotive activity of the respiratory chain of P. denitrificans in the absence of SCN- is directly influenced by the state of the H+-ATP synthetase in the cytoplasmic membrane of this organism. We are unable to explain the data in terms of a model in which the putative protonmotive force may be acting to affect the----H+/O ratio. The possibility is considered that the delocalised bulk-to-bulk phase membrane potential set up in response to protonmotive activity is energetically insignificant."
Proton-transfer pathways during bacterial electron-transport phosphorylation.
Mosaic protonic coupling hypothesis for free energy transduction.
"Uncouplers can shuttle between localized energy-coupling sites during photophosphorylation by chromatophores of Rhodopseudomonas capsulata N22.Two models of the action of uncoupler molecules in inhibiting photophosphorylation in bacterial chromatophores are considered: either uncoupler molecules shuttle rapidly between energy-coupling sites, or uncoupler molecules that are bound to particular sites in the chromatophores for a time that is comparable with the turnover time of the photophosphorylation apparatus may uncouple by a co-operative ""substoichiometric' mechanism. It is found that the titre of uncoupler necessary to cause complete uncoupling is lowered if the rate of photophosphorylation is initially decreased by partially restricting electron flow with an appropriate titre of antimycin A. This result indicates that uncoupler molecules shuttle rapidly between energy coupling in which the energized intermediate between electron transport and phosphorylation is delocalized over the entire chromatophore membrane and those in which it is not. If the rate of photophosphorylation is partially restricted with the covalent H+-translocating ATP synthase inhibitor dicyclohexylcarbodi-imide, the titre of uncoupler necessary to effect complete inhibition of photophosphorylation is also decreased relative to that in which the covalent H+-ATP synthase inhibitor is absent. This important result appears to be inconsistent with models of electron-transport phosphorylation in which the ""energized state' of the chromatophore membrane that is set up by electron transport and utilized in photophosphorylation is delocalized over the entire chromatophore membrane."
Coherent excitation in biology.
"Localized energy coupling during photophosphorylation by chromatophores of Rhodopseudomonas capsulata N22.The principle of the dual inhibitor titration method for testing models of electron-transport phosphorylation is outlined, and the method is applied to the study of photophosphorylation in bacterial chromatophores. It is concluded that energy coupling is strictly localized in nature in this system, in the sense that free energy released by a particular electron-transport chain may be used only by a particular H+-ATP synthase. Dual inhibitor titrations using the uncoupler SF 6847 and the H+-ATP synthase inhibitor oligomycin indicate that uncouplers act by shuttling rapidly between the localized energy-coupling sites."
Transmembrane respiration-driven H+ translocation is unimpaired in an eup mutant of Escherichia coli.
"On the mode of action of the bacteriocin butyricin 7423. Effects on membrane potential and potassium-ion accumulation in Clostridium pasteurianum.1. The apparent transmembrane bulk-phase electrical potential (delta psi) of Clostridium pasteurianum was determined from the distribution ratio of the membrane-permeable cation butyltriphenylphosphonium (BuPh3P+). In glycolysing cells the highest value of delta psi, calculated on the assumption that there was no energy-dependent binding of BuPh3P+ to the organisms, was recorded in media containing only 2-3 mM K+ ions and, even so, was only 100-110 mV. 2. Efrapeptin, a BF1-directed inhibitor of the membrane H+-ATPase of Cl. pasteurianum, abolished the membrane potential (delta psi) and caused complete efflux of actively-transported K+ ions. Thus protonmotive hydrolysis of ATP generated by substrate level phosphorylation is the sole means of membrane energisation in this anaerobe. 3. At low (sublethal) concentrations, butyricin 7423 stimulated K+ efflux from Cl. pasteurianum without measurably affecting its membrane potential. At lethal and supralethal concentrations of this bacteriocin, both delta psi and active K+ uptake were abolished. 4. Whilst the addition of valinomycin to cells of Cl. pasteurianum suspended in media of low K+ concentration generated a diffusion potential to which BuPh3P+ would respond, addition of butyricin 7423 in place of valinomycin caused no such effect. Also, unlike valinomycin, butyricin 7423 did not increase the rate of K+ efflux from non-glycolysing cells of Cl. pasteurianum. Valinomycin stimulated, but butyricin 7423 inhibited, the uptake of 86Rb+ ions by glycolysing cells of Cl. pasteurianum. 5. A mutant strain of Cl. pasteurianum (viz. strain DC3) which possessed a H+-ATPase with diminished sensitivity both to N,N'-dicyclohexylcarbodiimide and to butyricin 7423, exhibited a negligible decrease in delta psi and in K+ accumulation ratio in response to concentrations of butyricin 7423 that were bactericidal to the wild-type, parent organism. Even so, the bactericidal action of butyricin 7423 on Cl. pasteurianum is not adequately explained by its ability in vitro to inhibit the membrane H+-ATPase of this organism. 6. Bactericidal concentrations of butyricin 7423 neither provoked efflux of Na+ ions from Cl. pasteurianum nor exhibited any protonophorous activity. However, at artificially high concentration, butyricin 7423 catalysed the passage of Na+ ions as well as of K+ ions through multilayer lipid membranes. 7. As a non-protonophorous uncoupler, butyricin 7423 appears to act in a similar manner to that of the membrane-active colicins. Yet no evidence was obtained that butyricin 7423 at its minimum lethal concentration might form a gated ion channel in the cytoplasmic membrane of the target cell, or act as a classic ionophore."
"On the extent of localization of the energized membrane state in chromatophores from Rhodopseudomonas capsulata N22.1. The principle of the double-inhibitor titration method for assessing competing models of electron transport phosphorylation is expounded. 2. This principle is applied to photophosphorylation by chromatophores from Rhodopseudomonas capsulata N22. 3. It is found that, in contrast to the predictions of the chemiosmotic coupling model, free energy transfer is confined to individual electron transport chain and ATP synthase complexes. 4. This conclusion is not weakened by arguments concerning, the degree of uncoupling in the native chromatophore preparation or the relative number of electron transport chain and ATP synthase complexes present. 5. Photophosphorylation is completely inhibited by the uncoupler SF 6847 at a concentration corresponding to 0.31 molecules per electron transport chain. 6. The apparent paradox is solved by the proposal, consistent with the available evidence on the mode of action of uncouplers, that uncoupler binding causes a co-operative conformation transition in the chromatophore membrane, which leads to uncoupling and which is not present in the absence of uncoupler."
A novel inhibitor of NADH dehydrogenase in Paracoccus denitrificans.
"Butyricin 7423 and the membrane H+ -ATPase of Clostridium pasteurianum.The bacteriocin butyricin 7423 inhibited the activity of the membrane H+ -ATPase (BFoF1) of vegetative cells of Clostridium pasteurianum but not that of its soluble BF1 component. In vitro studies with the H+-ATPases of mutant strains selected for diminished sensitivity sensitivity (a) to butyricin 7423 and (b) to dicyclohexylcarbodi-imide, confirmed that butyricin 7423 interacts with the BFo component of this enzyme complex. Even so, certain other mutant strains displaying decreased sensitivity to butyricin 7423 possessed H+-ATPases which in vitro showed undiminished sensitivity to inhibition by the bacteriocin. Furthermore, from the changes in intracellular ATP concentration and in the rates and net extent of efflux of intracellular 86Rb+ ions that were provoked by exposure of the parent and several of the mutant strains to butyricin 7423, it was concluded that its primary bactericidal action was not attributable to stoichiometric inhibition of the membrane H+-ATPase. High extracellular concentrations of K+ ions enabled Cl. pasteurianum to survive exposure to low concentration of this membrane active bacteriocin."
"Proton-coupled energy transduction by biological membranes. Principles, pathways and praxis."
"Estimation with an ion-selective electrode of the membrane potential in cells of Paracoccus denitrificans from the uptake of the butyltriphenylphosphonium cation during aerobic and anaerobic respiration.1. Aerobic respiration by cells of Paracoccus dentrificans drives the uptake of the lipophilic cation butyltriphenylphosphonium. Anaerobiosis or addition of an uncoupler of oxidative phosphorylation (carbonyl cyanide p-trifluoromethoxyphenylhydrazone) results in efflux of the cation. Changes in the concentration of butyltriphenylphosphonium in the suspension medium were measured by using an ion-selective electrode, the construction of which is described. 2. If the uptake of butyltriphenylphosphonium is used as an indicator of membrane potential, then at pH 7.3 an estimate of about 160 mV is obtained for cells of P. dentrificans respiring aerobically in 100 mM-Hepes [4-(2-hydroxyethyl)-1-piperazine-ethanesulphonic acid/NaOH or 100mM-NaH2PO4/NaOH. This potential, however, is decreased by more than 20 mV in reaction media containing a high concentration of phosphate (100 mM) together with at least 1 mM-K+. 3. Anaerobic electron transport with NO3-, NO2- or N2O as terminal electron acceptor generates a membrane potential of about 150mV in described suspension media. The presence of these species under aerobic conditions, moreover, has negligible effect upon the extent of uptake of butyltriphenylphosphonium normally driven by aerobic respiration. These data indicate that none of these molecules exert a significant uncoupling effect on the protonmotive force. 4. No 204Tl+ uptake into respiring cells was detected. This adds to the evidence that 204Tl+ is not a freely permeable cation in bacterial cells and therefore not an indicator of membrane potential as has been proposed. The absence of respiration-driven 204Tl+ uptake indicates that P. denitrificans cells grown under the conditions specified in the present work do not possess K+-transport systems of either the Kdp or TrkA types that have been described in Escherichia coli."
On the permeability to weak acids and bases of the cytoplasmic membrane of Clostridium pasteurianum.
"Formulation and some biological uses of a buffer mixture whose buffering capacity is relatively independent of pH in the range pH 4-9.A mixture is described which has a buffering capacity which is essentially independent of pH in the range pH 4.0-9.0. It is shown how this buffer mixture may be used to determine the force-flux relationship of proton transfer between two aqueous phases separated by a phospholipid bilayer in vesicular systems and so demonstrate that this relationship is linear over a wide range of delta mu approximately H+. The buffer mixture can, furthermore, be employed to determine the volume enclosed within a vesicular preparation."
An adenine nucleotide translocase in the procaryote Methanobacterium thermoautotrophicum.
Oxidation-reduction properties of coenzyme M (2-mercaptoethane sulphonate) at the mercury electrode.
The generation of a membrane potential by a fermentative bacterium [proceedings]
Comparative aspects of the energetics of oxidative phosphorylation in bacteria and mitochondria.
On the functional proton current pathway of electron transport phosphorylation. An electrodic view.
"Comparison of permeant ion uptake and carotenoid band shift as methods for determining the membrane potential in chromatophores from Rhodopseudomonas sphaeroides Ga.1. A comparison was made of two methods for estimating the membrane potential in chromatophores from Rhodopseudomonas sphaeroides Ga. Illuminated chromatophores generated a potential that is apparently much larger when estimated on the basis of the red-band shift of carotenoids rather than from the extent of uptake of the permeant SCN- ion. 2. In contrast, when the chromatophores were oxidizing NADH or succinate the uptake of SCN- indicated a larger membrane potential than was estimated from the carotenoid band shift. 3. The extent of SCN- uptake and the carotenoid-band shift respond differently to changes in the ionic composition of the reaction medium. 4. The effects of antimycin on the carotenoid band shift and SCN- uptake are reported. 5. It is concluded that the carotenoid band shift and the uptake of SCN- are responding to different aspects of the energized state."
Evidence from 31P nuclear magnetic resonance that polyphosphate synthesis is a slip reaction in Paracoccus denitrificans [proceedings]
"The protonmotive force in phosphorylating membrane vesicles from Paracoccus denitrificans. Magnitude, sites of generation and comparison with the phosphorylation potential."
"The protonmotive force in bovine heart submitochondrial particles. Magnitude, sites of generation and comparison with the phosphorylation potential.1. The magnitude of the protonmotive force in respiring bovine heart submitochondrial particles was estimated. The membrane-potential component was determined from the uptake of S14CN-ions, and the pH-gradient component from the uptake of [14C]methylamine. In each case a flow-dialysis technique was used to monitor uptake. 2. With NADH as substrate the membrane potential was approx. 145mV and the pH gradient was between 0 and 0.5 unit when the particles were suspended in a Pi/Tris reaction medium. The addition of the permeant NO3-ion decreased the membrane potential with a corresponding increase in the pH gradient. In a medium containing 200mM-sucrose, 50mM-KCl and Hepes as buffer, the total protonmotive force was 185mV, comprising a membrane potential of 90mV and a pH gradient of 1.6 units. Thus the protonmotive force was slightly larger in the high-osmolarity medium. 3. The phosphorylation potential (= deltaG0' + RT ln[ATP]/[ADP][Pi]) was approx. 43.1 kJ/mol (10.3kcal/mol) in all the reaction media tested. Comparison of this value with the protonmotive force indicates that more than 2 and up to 3 protons must be moved across the membrane for each molecule of ATP synthesized by a chemiosmotic mechanism. 4. Succinate generated both a protonmotive force and a phosphorylation potential that were of similar magnitude to those observed with NADH as substrate. 5. Although oxidation of NADH supports a rate of ATP synthesis that is approximately twice that observed with succinate, respiration with either of these substrates generated a very similar protonmotive force. Thus there seemed to be no strict relation between the size of the protonmotive force and the phosphorylation rate. 6. In the presence of antimycin and/or 2-n-heptyl-4-hydroxyquinoline N-oxide, ascorbate oxidation with either NNN'N'-tetramethyl-p-phenylenediamine or 2,3,5,6-tetramethyl-p-phenylenediamine as electron mediator generated a membrane potential of approx. 90mV, but no pH gradient was detected, even in the presence of NO3-. These data are discussed with reference to the proposal that cytochrome oxidase contains a proton pump."
"Measurement by a flow dialysis technique of the steady-state proton-motive force in chromatophores from Rhodospirillum rubrum. Comparison with phosphorylation potential.1. In the light a transmembrane electrical potential of 100 mV has been estimated to occur in chromatophores from Rhodospirillum rubrum. The potential was determined by measuring the steady-state distribution of the permeant SCN- across the chromatophore membrane using a flow dialysis technique. The potential was not observed in the dark, nor in the presence of antimycin. It was dissipated on the addition of carbonyl cyanide p-trifluoromethoxyphenylhydrazone. The potential was reduced by between 15 and 20 mV when ADP and Pi were added. Hydrolysis of ATP by the chromatophores generated a membrane potential of about 80 mV. 2. Using a flow dialysis technique light-dependent uptake of methylamine was observed only in the presence of concentrations of SCN- that were 500-fold higher than were used to measure the membrane potential. It is concluded that the pH gradient across the illuminated chromatophore membrane is insignificant except in the presence of relatively high concentrations of a permeant anion like thiocyanate. Further evidence that a negligible pH gradient was generated by the chromatophores is that addition of K+ and nigericin to illuminated chromatophores did not stimulate uptake of SCN-. 3. In the light of chromatophores established and maintained a phosphorylation potential of up to 14 kcal/mol. If a phosphorylation potential of this magnitude is to be poised against a proton-motive force that comprises solely a membrane potential of approx. 100 mV, then at least five protons must be translocated for each ATP synthesised via a chemiosmotic mechanism."
Continuous monitoring of the electrical potential across energy-transducing membranes using ion-selective electrodes. Application to submitochondrial particles and chromatophores.
On the current-voltage relationships of energy-transducing membranes: submitochondrial particles [proceedings]
On the current-voltage relationships of energy-transducing membranes: phosphorylating membrane vesicles from Paracoccus denitrificans [proceedings]
"A knowledgebase system to enhance scientific discovery: Telemakus.BACKGROUND: With the rapid expansion of scientific research, the ability to effectively find or integrate new domain knowledge in the sciences is proving increasingly difficult. Efforts to improve and speed up scientific discovery are being explored on a number of fronts. However, much of this work is based on traditional search and retrieval approaches and the bibliographic citation presentation format remains unchanged. METHODS: Case study. RESULTS: The Telemakus KnowledgeBase System provides flexible new tools for creating knowledgebases to facilitate retrieval and review of scientific research reports. In formalizing the representation of the research methods and results of scientific reports, Telemakus offers a potential strategy to enhance the scientific discovery process. While other research has demonstrated that aggregating and analyzing research findings across domains augments knowledge discovery, the Telemakus system is unique in combining document surrogates with interactive concept maps of linked relationships across groups of research reports. CONCLUSION: Based on how scientists conduct research and read the literature, the Telemakus KnowledgeBase System brings together three innovations in analyzing, displaying and summarizing research reports across a domain: (1) research report schema, a document surrogate of extracted research methods and findings presented in a consistent and structured schema format which mimics the research process itself and provides a high-level surrogate to facilitate searching and rapid review of retrieved documents; (2) research findings, used to index the documents, allowing searchers to request, for example, research studies which have studied the relationship between neoplasms and vitamin E; and (3) visual exploration interface of linked relationships for interactive querying of research findings across the knowledgebase and graphical displays of what is known as well as, through gaps in the map, what is yet to be tested. The rationale and system architecture are described and plans for the future are discussed."
"An information extraction and representation system for rapid review of the biomedical literature.With the rapid expansion of scientific research, the ability to effectively find or integrate new domain knowledge in the sci-ences is proving increasingly difficult. The development of methods and tools for assisting researchers to effectively ex-tract problem-oriented knowledge from heterogeneous and massive information sources, and for using this knowledge in problem-solving is one of the most fundamental research di-rections for the information and computer sciences today. There is a need for new tools to support more precise identifi-cation of relevant research articles and provide visual clues regarding relationships among the document sets. We present the Telemakus system in which aggregated citation informa-tion and extracted research findings are displayed in a schema-based document surrogate and an interactive map-ping tool provides graphical displays of research inter-relationships from documents across a domain. This system is an innovative approach to creating useful and precise docu-ment surrogates and may re-conceptualize the way we cur-rently represent, retrieve, and assimilate research findings from the published literature."
"Tribal connections health information outreach: results, evaluation, and challenges.In 1997, the National Library of Medicine (NLM), a component of the National Institutes of Health (NIH), initiated a program of intensified outreach to Native Americans, initially focusing on the Pacific Northwest in collaboration with the Pacific Northwest Regional Medical Library (PNRML). This initiative, known as the Tribal Connections Project, emphasized the establishment or strengthening of Internet connections at select Indian reservations and Alaska Native villages and related needs assessment and training. The hope was that these efforts would improve tribal access to health information available via the Internet and the Web. Phase I included sixteen tribal sites--eight in Washington, four in Alaska, two in Montana, and one each in Oregon and Idaho. Phase I results indicate that the project was successful in assessing local needs and building awareness of the Internet, forging new partnerships with and between the participating Indian reservations and Alaska Native villages and other organizations, making real improvements in the information technology (IT) infrastructure and Internet connectivity at fifteen of sixteen sites, and conducting training sessions with several hundred tribal participants across thirteen sites. Most importantly, the project demonstrated the key role of tribal community involvement and empowerment and contributed to development of an outreach evaluation field manual and the evolving concept of community-based outreach. The knowledge gained from Tribal Connections Project Phase I is helping refine and enhance subsequent NLM-sponsored tribal connections and similar community outreach efforts."
"An objective function for radiation treatment optimization based on local biological measures.The implementation of biological optimization of radiation treatment plans is impeded by both computational and modelling problems. We derive an objective function from basic model assumptions which includes the normal tissue constraints as interior penalty functions. For organs that are composed of parallel subunits, a mean response model is proposed which leads to constraints similar to dose-volume constraints. This objective function is convex in the case when no parallel organs lie in the treatment volume. Otherwise, an argument is given to show that a number of local minima may exist which are near degenerate to the global minimum. Thus, together with the measure quality of the objective function, highly efficient gradient algorithms can be used. The number of essential biological model parameters could be reduced to a minimum. However, if the optimization constraints are given as TCP/NTCP values, Lagrange multiplier updates have to be performed by invoking comprehensive biological models."
"A non-EST-based method for exon-skipping prediction.It is estimated that between 35% and 74% of all human genes can undergo alternative splicing. Currently, the most efficient methods for large-scale detection of alternative splicing use expressed sequence tags (ESTs) or microarray analysis. As these methods merely sample the transcriptome, splice variants that do not appear in deeply sampled tissues have a low probability of being detected. We present a new method by which we can predict that an internal exon is skipped (namely whether it is a cassette-exon) merely based on its naked genomic sequence and on the sequence of its mouse ortholog. No other data, such as ESTs, are required for the prediction. Using our method, which was experimentally validated, we detected hundreds of novel splice variants that were not detectable using ESTs. We show that a substantial fraction of the splice variants in the human genome could not be identified through current human EST or cDNA data."
Document co-organization in an online knowledge community
"Autophosphorylation of ataxia-telangiectasia mutated is regulated by protein phosphatase 2AIonizing radiation induces autophosphorylation of the ataxia-telangiectasia mutated (ATM) protein kinase on serine 1981; however, the precise mechanisms that regulate ATM activation are not fully understood. Here, we show that the protein phosphatase inhibitor okadaic acid (OA) induces autophosphorylation of ATM on serine 1981 in unirradiated cells at concentrations that inhibit protein phosphatase 2A-like activity in vitro. OA did not induce -H2AX foci, suggesting that it induces ATM autophosphorylation by inactivation of a protein phosphatase rather than by inducing DNA double-strand breaks. In support of this, we show that ATM interacts with the scaffolding (A) subunit of protein phosphatase 2A (PP2A), that the scaffolding and catalytic (C) subunits of PP2A interact with ATM in undamaged cells and that immunoprecipitates of ATM from undamaged cells contain PP2A-like protein phosphatase activity. Moreover, we show that IR induces phosphorylation-dependent dissociation of PP2A from ATM and loss of the associated protein phosphatase activity. We propose that PP2A plays an important role in the regulation of ATM autophosphorylation and activity in vivo."
Ethnomedical interactions: health and identity on Nicaragua's atlantic coast
"Pre-eclampsia and cardiovascular disease: metabolic syndrome of pregnancy?Complications of pregnancy, particularly pre-eclampsia (PET) and intra-uterine growth restriction (IUGR) have been associated with future maternal cardiovascular disease (CVD). Pre-eclampsia, characterised by insulin resistance, widespread endothelial damage and dysfunction, coagulation defects and increased systemic inflammatory response, shares many risk factors with CVD. This review describes the pathology of PET and the maternal metabolic response and discusses the possible underlying mechanisms common to CVD and PET. The contributions of pre-existing risk factors and of the exaggerated atherogenic-like response seen in PET persisting post-partum to future CVD are considered. The potential for interventions based on early assessment of cardiovascular risk is addressed. We conclude that despite the low immediate cardiovascular risk in a population of young women, a pregnancy with multiple complications including PET, premature delivery and IUGR, carries a seven-fold additive risk of future disease. These women may be an appropriate cohort for CVD risk screening and for possible intervention."
"Checking on DNA damage in S phase.The precise replication of the genome and the continuous surveillance of its integrity are essential for survival and the avoidance of various diseases. Cells respond to DNA damage by activating a complex network of the so-called checkpoint pathways to delay their cell-cycle progression and repair the defects. In this review we integrate findings on the emerging mechanisms of activation, the signalling pathways and the spatio-temporal organization of the intra-S-phase DNA-damage checkpoint and its impact on the cell-cycle machinery, and discuss its biological significance."
AlgoVista
The dream of a common language
CS educational research
Rethinking computer science education from a test-first perspective
Inferring Web Communities from Link Topology
Information foraging
Exploiting generative models in discriminative classifiers
Using the Fisher kernel method to detect remote protein homologies.
"Deletion of the ecdysis-triggering hormone gene leads to lethal ecdysis deficiency.At the end of each developmental stage, insects perform a stereotypic behavioral sequence leading to ecdysis of the old cuticle. While ecdysis-triggering hormone (ETH) is sufficient to trigger this sequence, it has remained unclear whether it is required. We show that deletion of eth, the gene encoding ETH in Drosophila, leads to lethal behavioral and physiological deficits. Null mutants (eth(-)) fail to inflate the new respiratory system on schedule, do not perform the ecdysis behavioral sequence, and exhibit the phenotype buttoned-up, which is characterized by incomplete ecdysis and 98% mortality at the transition from first to second larval instar. Precisely timed injection of synthetic DmETH1 restores all deficits and allows normal ecdysis to occur. These findings establish obligatory roles for eth and its gene products in initiation and regulation of the ecdysis sequence. The ETH signaling system provides an opportunity for genetic analysis of a chemically coded physiological and behavioral sequence."
"Neuroendocrine control of larval ecdysis behavior in Drosophila: complex regulation by partially redundant neuropeptides.To complete each molting cycle, insects display a stereotyped sequence of behaviors to shed the remains of the old cuticle. These behavioral routines, as well as other related physiological events, are critical for proper development and are under the control of several neuropeptides. Their correct deployment and concatenation depends on the complex actions and interactions among several peptide hormones: ecdysis triggering hormone (ETH), eclosion hormone (EH), and crustacean cardioactive peptide (CCAP). Numerous theories, some in conflict, have been proposed to define the functional hierarchies by which these regulatory factors operate. Here we use wild-type Drosophila and transgenic flies bearing targeted ablations of either EH or CCAP neurons, or ablations of both together, to reevaluate their roles. Consistent with findings in moths, our results suggest that EH and ETH affect the release of each other via a positive feedback, although ETH can also be released in the absence of EH. We show that EH and ETH both contribute to the air filling of the air ducts (trachea) of the next stage but that EH may play a primary role in this process. We present evidence that EH, whose actions have always been placed upstream of CCAP, may also regulate ecdysis independently of CCAP. Finally, we confirm that flies lacking EH neurons do not ecdyse prematurely when injected with ETH peptides. These findings are surprising and not easily explained by currently available hypotheses. We propose that important additional neuropeptides, and additional interactions between known regulators, contribute to the mechanisms underlying insect ecdysis behaviors."
"Endocrine insights into the evolution of metamorphosis in insects.This review explores the roles of ecdysone and juvenile hormone (JH) in the evolution of complete metamorphosis and how metamorphosis, in turn, has impacted endocrine signaling. JH is a key player in the evolution of metamorphosis because it can act on embryos from more basal insect groups to suppress morphogenesis and cause premature differentiation, functions needed for transforming the transitional pronymphal stage of hemimetabolous insects into a functional larval stage. In the ancestral condition, imaginal-related growth is then delayed until JH finally disappears during the last larval instar. In the more derived groups of the Holometabola, selective tissues have escaped this JH suppression to form early-growing imaginal discs. We discuss how complete metamorphosis may have influenced the molecular aspects of both ecdysone and JH signaling."
Approximating the Nondominated Front Using the Pareto Archived Evolution Strategy
Attack-resistant trust metrics for public key certification
Spreading Activation Models for Trust Propagation
Centro Per La Ricerca
"Design and implementation of microarray gene expression markup language (MAGE-ML).BACKGROUND: Meaningful exchange of microarray data is currently difficult because it is rare that published data provide sufficient information depth or are even in the same format from one publication to another. Only when data can be easily exchanged will the entire biological community be able to derive the full benefit from such microarray studies. RESULTS: To this end we have developed three key ingredients towards standardizing the storage and exchange of microarray data. First, we have created a minimal information for the annotation of a microarray experiment (MIAME)-compliant conceptualization of microarray experiments modeled using the unified modeling language (UML) named MAGE-OM (microarray gene expression object model). Second, we have translated MAGE-OM into an XML-based data format, MAGE-ML, to facilitate the exchange of data. Third, some of us are now using MAGE (or its progenitors) in data production settings. Finally, we have developed a freely available software tool kit (MAGE-STK) that eases the integration of MAGE-ML into end users' systems. CONCLUSIONS: MAGE will help microarray data producers and users to exchange information by providing a common platform for data exchange, and MAGE-STK will make the adoption of MAGE easier."
Studies of beam blow up due to beam-beam interactions at a warm linear colliderAt a warm linear collider the short time interval at which bunches will pass near each other in the interaction region may lead to significant alteration of the bunches positions. In this paper we quantify the intensity of this effect and show that it can be addressed by a fast intra-pulse feedback system.
"An XML standard for the dissemination of annotated 2D gel electrophoresis data complemented with mass spectrometry results.BACKGROUND: Many proteomics initiatives require a seamless bioinformatics integration of a range of analytical steps between sample collection and systems modeling immediately assessable to the participants involved in the process. Proteomics profiling by 2D gel electrophoresis to the putative identification of differentially expressed proteins by comparison of mass spectrometry results with reference databases, includes many components of sample processing, not just analysis and interpretation, are regularly revisited and updated. In order for such updates and dissemination of data, a suitable data structure is needed. However, there are no such data structures currently available for the storing of data for multiple gels generated through a single proteomic experiments in a single XML file. This paper proposes a data structure based on XML standards to fill the void that exists between data generated by proteomics experiments and storing of data. RESULTS: In order to address the resulting procedural fluidity we have adopted and implemented a data model centered on the concept of annotated gel (AG) as the format for delivery and management of 2D Gel electrophoresis results. An eXtensible Markup Language (XML) schema is proposed to manage, analyze and disseminate annotated 2D Gel electrophoresis results. The structure of AG objects is formally represented using XML, resulting in the definition of the AGML syntax presented here. CONCLUSION: The proposed schema accommodates data on the electrophoresis results as well as the mass-spectrometry analysis of selected gel spots. A web-based software library is being developed to handle data storage, analysis and graphic representation. Computational tools described will be made available at http://bioinformatics.musc.edu/agml. Our development of AGML provides a simple data structure for storing 2D gel electrophoresis data."
"CEBS object model for systems biology data, SysBio-OM.MOTIVATION: To promote a systems biology approach to understanding the biological effects of environmental stressors, the Chemical Effects in Biological Systems (CEBS) knowledge base is being developed to house data from multiple complex data streams in a systems friendly manner that will accommodate extensive querying from users. Unified data representation via a single object model will greatly aid in integrating data storage and management, and facilitate reuse of software to analyze and display data resulting from diverse differential expression or differential profile technologies. Data streams include, but are not limited to, gene expression analysis (transcriptomics), protein expression and protein-protein interaction analysis (proteomics) and changes in low molecular weight metabolite levels (metabolomics). RESULTS: To enable the integration of microarray gene expression, proteomics and metabolomics data in the CEBS system, we designed an object model, Systems Biology Object Model (SysBio-OM). The model is comprehensive and leverages other open source efforts, namely the MicroArray Gene Expression Object Model (MAGE-OM) and the Proteomics Experiment Data Repository (PEDRo) object model. SysBio-OM is designed by extending MAGE-OM to represent protein expression data elements (including those from PEDRo), protein-protein interaction and metabolomics data. SysBio-OM promotes the standardization of data representation and data quality by facilitating the capture of the minimum annotation required for an experiment. Such standardization refines the accuracy of data mining and interpretation. The open source SysBio-OM model, which can be implemented on varied computing platforms is presented here. AVAILABILITY: A universal modeling language depiction of the entire SysBio-OM is available at http://cebs.niehs.nih.gov/SysBioOM/. The Rational Rose object model package is distributed under an open source license that permits unrestricted academic and commercial use and is available at http://cebs.niehs.nih.gov/cebsdownloads. The database and interface are being built to implement the model and will be available for public use at http://cebs.niehs.nih.gov."
Beyond the Great Divide: Collaborative Networks and the Challenge to Dominant Conceptions of Creative Industries
"Patch establishment and development of a clonal plant, Polygonum cuspidatum, on Mount Fuji.Microsatellite analysis was used to investigate the patch establishment and development of Polygonum cuspidatum Sieb. et Zucc, a clonal herbaceous plant that dominates the primary succession on the southeast slope of Mount Fuji. Genotypes of P. cuspidatum in 155 patches at the study site differed from each other. This indicates that P. cuspidatum patches are initially established by seed dispersed on the bare scoria field, and not by clonal rhizome extension. Genetic differentiation was estimated using the FST values between subpopulations at the study site. There was almost no genetic differentiation between subpopulations, indicating the presence of massive gene flow. The pollen fathers of seeds and maternal genets of current-year seedlings were inferred from the microsatellite allele composition by a simple exclusion method. The wide, random distribution of pollen fathers suggests that pollen dispersal occurs over a broad area. Maternal analysis showed a tendency for seed dispersal to be biased to the area nearby and down slope from the mother plants. Patch establishment under massive gene flow may result from such pollen and seed dispersal. To understand the process of patch development, aerial photographs taken from 1962 to 1999 were compared, and then genets in each of 36 patches were identified from the microsatellite genotypes of P. cuspidatum shoots. The comparison of aerial photographs showed that most of the patches enlarged each year and that some neighbouring patches combined during growth. Genet analysis demonstrated a high correlation between patch area and the area of the largest genet within it, and that new genets were recruited at the patch periphery. These findings indicate that both vegetative and sexual reproduction, i.e. rhizome extension and the establishment of new seedlings, contribute to the development of P. cuspidatum patches."
Dwellings and Devils in Early Bulgakov
"The Impact of Temperature on the Northern Distribution Limits of the Introduced Species Fallopia japonica and Impatiens glandulifera in North-West EuropeThis paper tests the predictions of sensitivity analysis performed on two matrix population growth models, for annual and perennial vegetation (Woodward, 1988). Climatic correlations have been established for two introduced invasive plant species Fallopia japonica (Japanese knotweed) and Impatiens glandulifera (Himalayan balsam) in north west Europe. These two species represent examples of perennial and annual vegetation respectively. In accordance with the model predictions, the northern distribution limit of F. japonica was found to be controlled by two climatic variables-the length of the growing season, measured in day-degrees, and the minimum temperature-while for I. glandulifera only the length of the growing season was critical. Experimental verification of the results is crucial for understanding the mechanisms operating to limit plant distributions. By use of the predictions established by the climatic correlations for I. glandulifera and F. japonica, maps have been produced forecasting the potential northward spread of both species on the basis of a 1.5<sup>⚬</sup> C and a 4.5<sup>⚬</sup> C rise in global mean surface air-temperature. These temperatures represent the minimum and maximum increases predicted to occur by general circulation models for a doubling of CO<sub>2</sub> concentration in the atmosphere. For a global temperature increase of 1.5<sup>⚬</sup> C the maps demonstrate a maximum northward spread of F. japonica from a latitude of 63<sup>⚬</sup> to 68<sup>⚬</sup> N and for I. glandulifera from 64<sup>⚬</sup> up to 69<sup>⚬</sup> N. The greater temperature increase fo 4.5<sup>⚬</sup> C indicates a considerable potential for expansion in the range of F. japonica in Norway and Sweden but a distribution which was restricted along the eastern coast of Sweden and southern Finland. In contrast, I. glandulifera could colonize the whole of the Fennoscandinavian area. The predictions are made assuming no migrational lag and no soil 'incompatibility'. Geographical differences in the patterns of spread between the species were explained with reference to the different factors affecting perennial and annual vegetation."
"Core Concepts and Common Ground: The Relational Basis of Our DisciplineThe core of sociology is the key thing that we share as sociologists - the basic way of viewing social life that makes us distinctive as a discipline. This core is the content that we have to communicate to a larger public. I argue that the disciplinary form that best develops a core is a structure in which there are a high density of positive network ties within the discipline, relatively weak subdivisions within the discipline, and a lower density of ties linking us to outside institutions. I use structural and social psychological theory to talk about the interactional dynamics that weaken this optimal disciplinary structure. The hope is that these theoretical insights will help us deal productively with some of the major social changes that are occurring within our field. I end with eight theoretically derived propositions to guide our behavior toward these ends."
"Plant Invasions and the Role of Riparian Habitats: A Comparison of Four Species Alien to Central EuropeWe compared the rate of invasion of four plant species which are alien to central Europe and the highest-growing representative of different life-forms: Impatients glandulifera (annaul), Heracleum mantegazzianum (monocarpic perennial), Reynoutria japonica and R. sachalinensis (polycarpic perennials). The spread of these species in the Czech Republic was reconstructed on the basis of floristic data. Cumulative numbers of localities reported from the time of introduction to the present were used for comparison. Exponential regression models were found to best fit the increase in thecumulative number of localities over time and the slope b was considered a convenient measure of the invasion rate. The ranking of species according to the decreasing rate of invasion was: I. glandulifera, Reynoutria japonica, Heracleum mantegazzianum, R. sachalinensis. The rate of invasion in riparian habitats, if these were treated separately, decreased in the following order: I. glandulifer, R. sachalinensis, R. japonica, H. mantegazzianum. The lag and exponential phases of spread were distinguished and the timing of the beginning of invasion was estimated at 1936 in I. glandulifera, 1938 in R. japonica, 1943 in H. mantegazzianum and 1952 in R. sachalinensis. H. mantegazzianum and I. glandulifera began to spread exponentially after having reached only a few localities in the area studied and their invasion rates during the exponential phase were higher than those of both Reynoutria species, whose imvasion proceeded at a more even rate. Habitat preferences differed between species in both law and exponential phases of spread. Different patterns of affinity to riparian habitats were found among the species studied. The role of river corridors in encouraging plant invasions is discussed on the regional scale with respect to the autecology of the species and frequency of suitable habitats."
"Sociology's Asociological ""Core"": An Examination of Textbook Sociology in Light of the Sociology of Scientific KnowledgeThe sociology of scientific knowledge (SSK) has challenged many of the ""core"" conceptions of theory and method that remain entrenched in sociology textbooks. In conjunction with recent developments in history and philosophy of science, sociologists of science speak of the disunity of science and describe the local-historical origins of particular scientific facts and laws. ""Core"" sociology textbooks devote no attention to the methodological implications of recent sociology of science. Elementary textbooks present upbeat versions of the discipline that emphasize sociology's scientific methodology; they describe sociological methods as implementations of a general research process designed along hypothetico-deductive lines. Viewed from the vantage point of SSK, such widely disseminated elementary versions of sociology promote an asociological conception of science. In this paper we suggest that the ""epistemic flattening"" accomplished by SSK's research on the natural sciences provides a valuable antidote to current anxieties about the coherence and scientific status of sociology."
"Core Intervention and Periphery Revolution, 1821-1985The association between periphery revolution and core intervention, 1821-1985, is examined in light of the world-system perspective. Two hypotheses are tested. First, a positive relationship between revolution and intervention can be found overt the longue duree of the two centuries. Second, however, the relationship is conditional on changing structural processes of the world system: the Kondratieff wave and the long wave of world leadership. Both hypotheses receive support from longitudinal data. Revolution is associated with intervention, but more so when the world system undergoes restructuring during Kondratieff expansions and hegemonic decline."
A Dual-Core Model of Organizational InnovationThis paper examines the role of administrators and technical employees in the process leading to innovation adoption. A marked division of labor is found. The evidence indicates that two distinct innovation processes--bottom-up and top-down--can exist in organizations. The findings are used to propose a dual-core model of organizational innovation.
Theory in Anthropology: Center and Periphery
"Agency and Social Networks: Strategies of Action in a Social Structure of Position, Opposition, and OpportunityThis study uses social movement concepts to explain the success and failure of actors in a network of relationships trying to influence policies on environmental issues in a small city. Results show that strategies to take action and mobilize others in a network of interorganizational relationships can vary depending on the social context, which consists of the political opportunity structure defined by government regulators, whether the actor faces opposition, and the actor's position in the network. Decisions to engage in strategies to try to influence government regulators directly, to use a broker to reach agreements with the opposition, or to form a coalition with actors in other organizations to influence government decision makers are affected by this social context. Results also show that even peripheral actors, usually assumed to be powerless in network studies, can influence policy if they use a direct-contact strategy and the political opportunity structure is favorable."
"Socialization to Heroism: Individualism and Collectivism in a Voluntary Search and Rescue GroupIn this paper I examine the tension between self-interested individualism and norms of self-sacrifice in a volunteer search and rescue group in the western United States. I draw on 3 1/2 years of ethnographic fieldwork to highlight how individuals were socialized to membership by conforming to the group norms along three general dimensions: the consciousness they displayed, the resources they provided, and the commitment they developed. Within each of these dimensions, I identify stages denoting members' change in status from new member to peripheral member to core member, and I show how those who achieved core membership were granted heroic status. I conclude by examining how the meanings of this symbolic reward, heroic status, guided members' behavior, producing a layered stage model of organizational socialization that helped them to reconcile their own interests with those of the group."
"Management FashionManagement fashion setters disseminate management fashions, transitory collective beliefs that certain management techniques are at the forefront of management progress. These fashion setters-consulting firms, management gurus, business mass-media publications, and business schools-do not simply force fashions onto gullible managers. To sustain their images as fashion setters, they must lead in a race (a) to sense the emergent collective preferences of managers for new management techniques, (b) to develop rhetorics that describe these techniques as the forefront of management progress, and (c) to disseminate these rhetorics back to managers and organizational stakeholders before other fashion setters. Fashion setters who fall behind in this race (e.g., business schools or certain scholarly professional societies) are condemned to be perceived as lagging rather than leading management progress, as peripheral to the business community, and as undeserving of societal support. This article is not a plea for business school scholars to become slaves to management fashion. Rather, it urges these scholars not only to study the management-fashion-setting process and to explain when and how it fails to serve shareholders, employees, managers, students, and other stakeholders, but also to intervene in this process in order to render it a more technically useful, collective learning process for these stakeholders."
"Front-Line Organization of the State Mental HospitalThe power of attendants at state mental hospitals to influence policy has often been noted. This paper suggests that the distribution of power in the state mental hospital fails to conform to Michels's ""iron law of oligarchy."" From an analysis of the ward system, three main characteristics are derived. These are then stated as the formal characteristics of a front-line type of organization in which power tends to be distributed to peripheral units rather than to centralized positions of leadership. It is suggested finally that a front-line type of organization presents special problems of control and hence will tend to develop characteristic structures and processes of control as solutions."
"Community as Gift-Giving: Collectivistic Roots of VolunteerismWho in America volunteers what and why? And what impact does volunteering have? It is widely believed that the typical volunteer is middle-aged and middle-class and that volunteerism is rooted in American cultural individualism. Undocumented and unexplored are collectivistic roots of giving, which may have a different social base than individualistc-grounded volunteerism. Characteristics of collectivistic-rooted volunteerism, conditions under which it transpires, and group and community effects of such giving are explored here. The analysis is based on ethnographic research in a predominantly ""old immigrant"" working-class inner-ring suburb. Collectivistic-rooted volunteerism is shown to be community-embedded and to have group, community, and class stratifying effects."
"Gemeinschaft Revisited: A Critique and Reconstruction of the Community ConceptCommunity remains a potent symbol and aspiration in political and intellectual life. However, it has largely passed out of sociological analysis. The paper shows why this has occurred, and it develops a new typology that can make the concept useful again in sociology. The new typology is based on identifying structurally distinct subtypes of community using a small number of partitioning variables. The first partition is defined by the ultimate context of interaction; the second by the primary motivation for interaction; the third by rates of interaction and location of members; and the fourth by the amount of face-to-face as opposed to computer-mediated interaction. This small number of partitioning variables yields eight major subtypes of community. The paper shows how and why these major subtypes are related to important variations in the behavioral and organizational outcomes of community. The paper also seeks to resolve some disagreements between classical liberalism and communitarians. It shows that only a few of the major subtypes of community are likely to be as illiberal and intolerant as the selective imagery of classical liberals asserts, while at the same time only a few are prone to generate as much fraternalism and equity as the selective imagery of communitarians suggests. The paper concludes by discussing the forms of community that are best suited to the modern world."
From regular lattice to scale free network - yet another algorithmThe Watts-Strogatz algorithm transferring a regular lattice to the small world network is modified by introducing preferential rewiring constrained by connectivity demand. The probability to link to/ unlink form a node is dependent on a vertex degree and adjusted by some threshold. For each threshold value there exists a probability at which the resulting stationary network has degree distribution with power-law decay in large interval of degrees.
"Multidimensional Consensus model on a Barabasi-Albert networkA Consensus Model according to Deffuant on a directed Barabasi-Albert network was simulated. Agents have opinions on different subjects. A multi-component subject vector was used. The opinions are discrete. The analysis regards distribution and clusters of agents which are on agreement in the opinions of the subjects. Remarkable results are on the one hand, that there mostly exists no absolute consens. It determines depending on the ratio of number of agents to the number of subjects, whether the communication ends in a consens or a pluralism. Mostly a second robust cluster remains, in its size depending on the number of subjects. Two agents agree either in (nearly) all or (nearly) no subject.\\ The operative parameter of the consens-formating-process is the tolerance in change of views of the group-members."
"Network reachability of real-world contact sequencesWe use real-world contact sequences, time-ordered lists of contacts from one person to another, to study how fast information or disease can spread across network of contacts. Specifically we measure the reachability time—the average shortest time for a series of contacts to spread information between a reachable pair of vertices (a pair where a chain of contacts exists leading from one person to the other)—and the reachability ratio—the fraction of reachable vertex pairs. These measures are studied using conditional uniform graph tests. We conclude, among other things, that the network reachability depends much on a core where the path lengths are short and communication frequent, that clustering of the contacts of an edge in time tends to decrease the reachability, and that the order of the contacts really does make sense for dynamical spreading processes."
"Surviving Closure: Post-Rejection Adaptation and Plurality in ScienceCan the procedures and institutions of modern science support more than one version of reality? The early science of gravitational wave detection adapted and survived for a quarter of a century after its findings ceased to be accepted by the majority of the scientific community. Two mutually exclusive approaches to the same physical phenomenon, spawned by the same community, were initially supported by the same institutions and later by only marginally different institutions. The case reveals, then, a surprising plurality within physics, that stretches from publication policies to funding sources. The survival history of what will be called ""high visibility gravitational radiation"" (HighVGR) research is compared with that of other ""rejected sciences"" that experienced what might be called ""life after death."" It is suggested that ""core-groups"" in physics allow a large degree of license within the formal institutions because their informal controls make sure that rejected science does no harm to progress in the mainstream. When informal controls break down, however, formal controls take over. Analysis of the formal, readily visible face of science reveals little of what is happening in the, often crucial, informal networks."
"Putting the Community into Organizational Science: Exploring the Construction of Knowledge ClaimsLike Weiss, I too dislike some of the postmodern writings on organizations. I too worry that shallow works given even more shallow and opportunistic readings can have negative social consequences. But I also recognize that most of Weiss's concerns are not unique to postmodern writings. Many of the problems he discusses could also be descriptive of work from different conceptual and methodological stances. Statistics are often contrived and misleading. Ethnography has at times aided colonization. Both social and physical sciences have at times produced bad theories and been put to very negative uses. Some early postmodernist theorists, Christians, and scientists, were Nazis, and elements of each of their fundamental conceptions could be co-opted to support this particular form of barbarism. This potential utilization, however, does not lead for me to a blanket condemnation of postmodernism, science, ethnography, religion, or statistics. Devotees of each have used their special understandings to fight tyranny. Both postmodernism and science also draw on fundamental conceptions that are productive, enable open choices, and help us see through the masters and ideologies of a particular time and place. I am less interested in blame than in finding what each can contribute. I look to an ongoing community discussion that helps us to do the best we can to sort out the good from the bad, and I hope that the current set of essays helps stimulate a positive dialogue."
"The Yeast Proteome Database (YPD): a model for the organization and presentation of genome-wide functional data.The Yeast Proteome Database (YPD) is a model for the organization and presentation of comprehensive protein information. Based on the detailed curation of the scientific literature for the yeast Saccharomyces cerevisiae, YPD contains more than 50 000 annotations lines derived from the review of 8500 research publications. The information concerning each of the approximately 6100 yeast proteins is structured around a convenient one-page format, the Yeast Protein Report, with additional information provided as pop-up windows. Protein classification schema have been revised this year, defining each protein's cellular role, function and pathway, and adding a Functional to the Yeast Protein Report. These changes provide the user with a succinct summary of the protein's function and its place in the biology of the cell, and they enhance the power of YPD Search functions. Precalculated sequence alignments have been added, to provide a crossover point for comparative genomics. The first transcript profiling data has been integrated into the YPD Protein Reports, providing the framework for the presentation of genome-wide functional data. The Yeast Proteome Database can be accessed on the Web at http://www.proteome.com/YPDhome.html"
"YPD-A database for the proteins of Saccharomyces cerevisiae.YPD is a database for the proteins of the budding yeast, Saccharomyces cerevisiae. YPD has two formats: (i) a spreadsheet which tabulates many of the physical and functional properties of yeast proteins, and (ii) the YPD Protein Reports which are formatted pages containing the protein properties, annotations gathered from the literature, and references with titles. YPD is available through the World-Wide Web, through an Email server, and by anonymous FTP. New releases of the YPD spreadsheet are produced every two to four months, and the on-line information is updated daily."
"A Theory of Problem-Solving BehaviorIn this paper we develop a formal, testable theory of problem-solving behavior with special relevance to individuals and small groups. The theory is consistent with principles drawn from operant behavior and social exchange theories but also incorporates elements of cognitive psychology. Problem solving is defined as a nonroutine activity oriented toward changing an undesirable state of affairs. The focus on change differentiates problem solving from coping, which is oriented toward relieving feelings of stress. A decision-making model is presented, which takes the problem-solving process through its latter stages. The theory is based on two axioms and three theorems pertaining to the process of decision making. These axioms and theorems serve as the foundation for deriving 14 theorems that establish the antecedent conditions affecting decisions relevnat to each of four stages in the problem-solving process. This theory is distinguished from other problem-solving theories in its effort to account for conditions leading to awareness of problems and in its emphasis on generic problem-solving processes rather than on the effectiveness of problem-solving outcomes."
"A Holistic View of Problem SolvingThe limited view of the problem-solving space that is held by the world of science is criticized. A problem solution is considered to be achieved when a perceived present situation and a perceived desired situation become the same. The problem-solving space is three dimensional, and its three vectors are concerned with problem taxonomy, problem-solving modes, and problem-solving process. The space takes on greater meaning when it is related to the fourth dimension called the chronology of problem solving. This chronology includes four primary phases: personalization, collaboration, institutionalization, and socialization. A case is made that the scientific or rationalistic view of problem solving is limited in the collaboration phase and has no relevance in the institutionalization and socialization phases. A holistic view of problem solving is concerned with the relationship between the problem-solving chronology and the ultimate implementation of solutions."
"""Sticky Information"" and the Locus of Problem Solving: Implications for InnovationTo solve a problem, needed information and problem-solving capabilities must be brought together. Often the information used in technical problem solving is costly to acquire, transfer, and use in a new location-is, in our terms, ""sticky."" In this paper we explore the impact of information stickiness on the locus of innovation-related problem solving. We find, first, that when sticky information needed by problem solvers is held at one site only, problem solving will be carried out at that locus, other things being equal. Second, when more than one locus of sticky information is called upon by problem solvers, the locus of problem solving may iterate among these sites as problem solving proceeds. When the costs of such iteration are high, then, third, problems that draw upon multiple sites of sticky information will sometimes be ""task partitioned"" into subproblems that each draw on only one such locus, and/or, fourth, investments will be made to reduce the stickiness of information at some locations. Information stickiness appears to affect a number of issues of importance to researchers and practitioners. Among these are patterns in the diffusion of information, the specialization of firms, the locus of innovation, and the nature of problems selected by problem solvers."
"Herd Behaviors in Financial Markets We investigate the herd behavior of returns for the yen-dollar exchange rate in the Japanese financial market. It is obtained that the probability distribution $P(R)$ of returns $R$ satisfies the power-law behavior $P(R) ∼eq R^-β$ with the exponents $ β=3.11$(the time interval $τ=$ one minute) and 3.36($τ=$ one day). The informational cascade regime appears in the herding parameter $H≥ 2.33$ at $τ=$ one minute, while it occurs no herding at $τ=$ one day. Especially, we find that the distribution of normalized returns shows a crossover to a Gaussian distribution at one time step $Δ t=1$ day."
"Information diffusion through blogspaceWe study the dynamics of information propagation in environments of low-overhead personal publishing, using a large collection of weblogs over time as our example domain. We characterize and model this collection at two levels. First, we present a macroscopic characterization of topic propagation through our corpus, formalizing the notion of long-running ""chatter"" topics consisting recursively of ""spike"" topics generated by outside world events, or more rarely, by resonances within the community. Second, we present a microscopic characterization of propagation from individual to individual, drawing on the theory of infectious diseases to model the flow. We propose, validate, and employ an algorithm to induce the underlying propagation network from a sequence of posts, and report on the results."
"The Role of Team and Task Characteristics in R & D Team Collaborative Problem Solving and ProductivityAntecedents of collaborative problem solving in R & D teams have received little attention. Furthermore, the relationship between this form of problem solving and R & D team productivity remains unarticulated. This lacuna is addressed in the present study be analyzing the relationships between task and team properties, collaborative problem solving and team productivity. Multiple regression was used to study the relationships among these variables. Results indicated that team cohesiveness and task certainty were robust predictors of collaborative problem solving and productivity for 45 R & D project groups. It was found that collaborative problem solving did not have a linear relationship with team productivity. The collaborative problem solving-productivity relationship was further examined and it was shown that the relationship was sensitive to high and low levels for each of four predictors used in the research design (task certainty, task interdependence, team size, and team cohesiveness). These empirical findings were then translated into implications for R & D managers."
"Problems with Fitting to the Power-Law DistributionThis short communication uses a simple experiment to show that fitting to a power law distribution by using graphical methods based on linear fit on the log-log scale is biased and inaccurate. It shows that using maximum likelihood estimation (MLE) is far more robust. Finally, it presents a new table for performing the Kolmogorov-Smirnof test for goodness-of-fit tailored to power-law distributions in which the power-law exponent is estimated using MLE. The techniques presented here will advance the application of complex network theory by allowing reliable estimation of power-law models from data and further allowing quantitative assessment of goodness-of-fit of proposed power-law models to empirical data."
The shortest path to complex networks1. The birth of network science. 2. What are random networks? 3. Adjacency matrix. 4. Degree distribution. 5. What are simple networks? Classical random graphs. 6. Birth of the giant component. 7. Topology of the Web. 8.Uncorrelated networks. 9. What are small worlds? 10. Real networks are mesoscopic objects. 11. What are complex networks? 12. The configuration model. 13. The absence of degree--degree correlations. 14.Networks with correlated degrees.15.Clustering. 16. What are small-world networks? 17. `Small worlds' is not the same as `small-world networks'. 18. Fat-tailed degree distributions. 19.Reasons for the fat-tailed degree distributions. 20. Preferential linking. 21. Condensation of edges. 22. Cut-offs of degree distributions. 23. Reasons for correlations in networks. 24. Classical random graphs cannot be used for comparison with real networks. 25. How to measure degree--degree correlations. 26. Assortative and disassortative mixing. 27. Disassortative mixing does not mean that vertices of high degrees rarely connect to each other. 28. Reciprocal links in directed nets. 29. Ultra-small-world effect. 30. Tree ansatz. 31.Ultraresilience against random failures. 32. When correlated nets are ultraresilient. 33. Vulnerability of complex networks. 34. The absence of an epidemic threshold. 35. Search based on local information. 36.Ultraresilience disappears in finite nets. 37.Critical behavior of cooperative models on networks. 38. Berezinskii-Kosterlitz-Thouless phase transitions in networks. 39.Cascading failures. 40.Cliques & communities. 41. Betweenness. 42.Extracting communities. 43. Optimal paths. 44.Distributions of the shortest-path length & of the loop's length are narrow. 45. Diffusion on networks. 46. What is modularity? 47.Hierarchical organization of networks. 48. Convincing modelling of real-world networks:Is it possible? 49. The small Web..
"Individual strategies in complementarity games and population dynamicsWe introduce and study an evolutionary complementarity game where in each round a player of population 1 is paired with a member of population 2. The game is symmetric, and each player tries to obtain an advantageous deal, but when one of them pushes too hard, no deal at all can be concluded, and they both loose. The game has many equilibria, and which of them is reached depends on the history of the interactions as the players evolve according to a fitness function that measures their gains across the interactions. We can then break the symmetry by assigning different strategy spaces to the populations, varying in particular with respect to the information available to the agents. The agents can, for example, adapt to the behavior of their opponents met in previous rounds, or they can try to copy the strategies of their successful friends. It turns out that, in general, the more restricted strategy spaces, that is, those that utilize less information, are more advantageous for a population as a whole as their adoption drives the equilibrium in a direction advantageous to that population. One reason is that a simpler strategy can be learned faster in an evolutionary setting, another is that it is good for a population to have some individuals that are unfit in the sense that they make offers that are individually unsuccessful, but have a systematic effect on the strategies of their opponents. All these effects are demonstrated through systematic simulations."
"Coevolution of dynamical states and interactions in dynamic networksWe explore the coupled dynamics of the internal states of a set of interacting elements and the network of interactions among them. Interactions are modeled by a spatial game and the network of interaction links evolves adapting to the outcome of the game. As an example we consider a model of cooperation, where the adaptation is shown to facilitate the formation of a hierarchical interaction network that sustains a highly cooperative stationary state. The resulting network has the characteristics of a small world network when a mechanism of local neighbor selection is introduced in the adaptive network dynamics. The highly connected nodes in the hierarchical structure of the network play a leading role in the stability of the network. Perturbations acting on the state of these special nodes trigger global avalanches leading to complete network reorganization."
"Maximum path information and the principle of least action for chaotic systemA path information is defined in connection with the different possible paths of chaotic system moving in its phase space between two cells. On the basis of the assumption that the paths are differentiated by their actions, we show that the maximum path information leads to a path probability distribution as a function of action from which the well known transition probability of Brownian motion can be easily derived. An interesting result is that the most probable paths are just the paths of least action. This suggests that the principle of least action, in a probabilistic situation, is equivalent to the principle of maximization of information or uncertainty associated with the probability distribution."
"[Management of TB suspected cases of drug resistant tuberculosis requiring a second treatment]The management of patients with resistance to anti tuberculous drugs is complex and therefore must be managed by physician specialists. The most difficult patients are the cases in retreatment, where some very different possibilities are possible, as abandonment, failures and relapses. Patients with multi-drug resistant (MDR) tuberculosis are the most difficult to treat; MDR appears in all the failures or non-adherences to the treatment regime. To elaborate a scheme of retreatment for these patients, two guidelines must be followed: (1) do not rely on outcomes of drug susceptibility tests and (2) a detailed history of drug treatment must be considered of paramount importance. With this information, a retreatment scheme can be formulated that involves the use of at least three drugs not previously taken by the patient. For a successful control of tuberculosis, the national tuberculosis programs in Latin American countries must assure careful management of newly diagnosed patients. Secondly, if resources are available, a bank of second-line drugs must be ready for managing retreatment situations (e.g., 3 Z-Kn-Eth-Of/15 Z-Eth-Of) if first line drug treatments fail. Using individualized retreatment with second line drugs is recommended only in industrialized countries, and for a few middle income countries as a last resort."
"No Innate Phases in Group Problem SolvingA widely accepted empirical study (Bales & Strodtbeck, 1951)) concludes that ""many staff conferences, committees, and similar groups"" progress through predictable sequential phases in problem solving. Reexamination suggests that the conclusion is wrong. Only those subject groups that had never before met showed phased movement. The 1951 research may have measured the process of group formation, not problem solving. Well-acquainted small groups-for example, most management teams, task forces, and committees-do not naturally follow sequential phases in problem solving."
"Coarse-Graining and Self-Dissimilarity of Complex NetworksCan complex engineered and biological networks be coarse-grained into smaller and more understandable versions in which each node represents an entire pattern in the original network? To address this, we define coarse-graining units (CGU) as connectivity patterns which can serve as the nodes of a coarse-grained network, and present algorithms to detect them. We use this approach to systematically reverse-engineer electronic circuits, forming understandable high-level maps from incomprehensible transistor wiring: first, a coarse-grained version in which each node is a gate made of several transistors is established. Then, the coarse-grained network is itself coarse-grained, resulting in a high-level blueprint in which each node is a circuit-module made of multiple gates. We apply our approach also to a mammalian protein-signaling network, to find a simplified coarse-grained network with three main signaling channels that correspond to cross-interacting MAP-kinase cascades. We find that both biological and electronic networks are 'self-dissimilar', with different network motifs found at each level. The present approach can be used to simplify a wide variety of directed and nondirected, natural and designed networks."
"MIPS: a database for genomes and protein sequencesThe Munich Information Center for Protein Sequences (MIPS-GSF), Martinsried near Munich, Germany, develops and maintains genome oriented databases. It is commonplace that the amount of sequence data available increases rapidly, but not the capacity of qualified manual annotation at the sequence databases. Therefore, our strategy aims to cope with the data stream by the comprehensive application of analysis tools to sequences of complete genomes, the systematic classification of protein sequences and the active support of sequence analysis and functional genomics projects. This report describes the systematic and up-to-date analysis of genomes (PEDANT), a comprehensive database of the yeast genome (MYGD), a database reflecting the progress in sequencing the Arabidopsis thaliana genome (MATD), the database of assembled, annotated human EST clusters (MEST), and the collection of protein sequence data within the framework of the PIR-International Protein Sequence Database (described elsewhere in this volume). MIPS provides access through its WWW server (http://www.mips.biochem.mpg.de) to a spectrum of generic databases, including the above mentioned as well as a database of protein families (PROTFAM), the MITOP database, and the all-against-all FASTA database."
Social Balance TheoryWe construct a model based on social balance theory proposed by Fritz Heider to analyze the interpersonal network among social agents. The model of social balance theory provides us an interesting tool to see how a social group evolves to the possible balance state. We introduce the balance index that can be used to measure social balance in macro structure level (global balance index) or in micro structure (local balance index) to see how the local balance index influences the global balance structure. Several experiments are done and we discover how the social group can form separation of subgroups in a group or strengthening a social group while emphasizing the structure theorem and social mitosis previously introduced.
"Problem-Solving, Research Traditions, and the Development of Scientific FieldsThe general thesis that science is essentially a problem-solving activity is extended to the development of new fields. Their development represents a research strategy for generating and solving new unsolved problems and solving existing ones in related fields. The pattern of growth of new fields is guided by the central problems within the field and applicable problems in other fields. Proponents of existing research traditions welcome work in new fields, if they believe it will increase the problem-solving effectiveness of their tradition. Correspondingly, researchers in new fields will graft their work onto established traditions, if they believe it will augment the problem-solving effectiveness of their work. The above claims are defended through using the development of paleomagnetism as a case study."
"Near Rationality and Competitive Equilibria in Networked SystemsA growing body of literature in networked systems research relies on game theory and mechanism design to model and address the potential lack of cooperation between self-interested users. Most game-theoretic models applied to system research only describe competitive equilibria in terms of pure Nash equilibria, that is, a situation where the strategy of each user is deterministic, and is her best response to the strategies of all the other users. However, the assumptions necessary for a pure Nash equilibrium to hold may be too stringent for practical systems. Using three case studies on computer security, TCP congestion control, and network formation, we outline the limits of game-theoretic models relying on Nash equilibria, and we argue that considering competitive equilibria of a more general form may help reconcile predictions from game-theoretic models with empirically observed behavior."
"Dealing With Curious Players in Secure NetworksIn secure communications networks there are a great number of user behavioural problems, which need to be dealt with. Curious players pose a very real and serious threat to the integrity of such a network. By traversing a network a Curious player could uncover secret information, which that user has no need to know, by simply posing as a loyalty check. Loyalty checks are done simply to gauge the integrity of the network with respect to players who act in a malicious manner. We wish to propose a method, which can deal with Curious players trying to obtain ""Need to Know"" information using a combined Fault-tolerant, Cryptographic and Game Theoretic Approach."
Extraction of topological features from communication network topological patterns using self-organizing feature mapsDifferent classes of communication network topologies and their representation in the form of adjacency matrix and its eigenvalues are presented. A self-organizing feature map neural network is used to map different classes of communication network topological patterns. The neural network simulation results are reported.
"MIPS: a database for protein sequences, homology data and yeast genome information.The MIPS group (Martinsried Institute for Protein Sequences) at the Max-Planck-Institute for Biochemistry, Martinsried near Munich, Germany, collects, processes and distributes protein sequence data within the framework of the tripartite association of the PIR-International Protein Sequence Database (,). MIPS contributes nearly 50% of the data input to the PIR-International Protein Sequence Database. The database is distributed on CD-ROM together with PATCHX, an exhaustive supplement of unique, unverified protein sequences from external sources compiled by MIPS. Through its WWW server (http://www.mips.biochem.mpg.de/ ) MIPS permits internet access to sequence databases, homology data and to yeast genome information. (i) Sequence similarity results from the FASTA program () are stored in the FASTA database for all proteins from PIR-International and PATCHX. The database is dynamically maintained and permits instant access to FASTA results. (ii) Starting with FASTA database queries, proteins have been classified into families and superfamilies (PROT-FAM). (iii) The HPT (hashed position tree) data structure () developed at MIPS is a new approach for rapid sequence and pattern searching. (iv) MIPS provides access to the sequence and annotation of the complete yeast genome (), the functional classification of yeast genes (FunCat) and its graphical display, the 'Genome Browser' (). A CD-ROM based on the JAVA programming language providing dynamic interactive access to the yeast genome and the related protein sequences has been compiled and is available on request."
"Organizational Joint Problem-SolvingTo carry out its day-to-day activities an organization will establish an organizational servomechanism. On the other hand, planning and problem-solving must be dealt with differently. Traditional methods, characterized here as the authority approach and the group incremental approach, have significant limitations. On the other hand organizations can and do effectively solve novel and complex tasks by organizational joint problem-solving. This approach is characterized in this paper by a set of propositions formulated to describe how authority and responsibility are distributed and how search and coordination are facilitated. This is done through: the linkage of a set of organizational centers around a mission assignment, the initial search at the overall task level, the search within task components, the broadcast of actions and task laws to all or many centers, the identification and resolution of inconsistencies between components and the conduct of joint search, and the iteration on these steps until an overall consistent set of actions has been established. Where the conditions (goal orientation, participant skill, communication facilities) for organizational joint problem-solving are not initially met, steps can be taken to aid and encourage the participants to use the procedures."
"MIPS: analysis and annotation of proteins from whole genomesThe Munich Information Center for Protein Sequences (MIPSâGSF), Neuherberg, Germany, provides protein sequenceârelated information based on wholeâgenome analysis. The main focus of the work is directed toward the systematic organization of sequenceârelated attributes as gathered by a variety of algorithms, primary information from experimental data together with information compiled from the scientific literature. MIPS maintains automatically generated and manually annotated genomeâspecific databases, develops systematic classification schemes for the functional annotation of protein sequences and provides tools for the comprehensive analysis of protein sequences. This report updates the information on the yeast genome (CYGD), the Neurospora crassa genome (MNCDB), the database of complete cDNAs (German Human Genome Project, NGFN), the database of mammalian proteinâprotein interactions (MPPI), the database of FASTA homologies (SIMAP), and the interface for the fast retrieval of proteinâassociated information (QUIPOS). The Arabidopsis thaliana database, the rice database, the plant EST databases (MATDB, MOsDB, SPUTNIK), as well as the databases for the comprehensive set of genomes (PEDANT genomes) are described elsewhere in the 2003 and 2004 NAR database issues, respectively. All databases described, and the detailed descriptions of our projects can be accessed through the MIPS web server (http://mips.gsf.de)."
"Optimizing genetic algorithm strategies for evolving networksThis paper explores the use of genetic algorithms for the design of networks, where the demands on the network fluctuate in time. For varying network constraints, we find the best network using the standard genetic algorithm operators such as inversion, mutation and crossover. We also examine how the choice of genetic algorithm operators affects the quality of the best network found. Such networks typically contain redundancy in servers, where several servers perform the same task and pleiotropy, where servers perform multiple tasks. We explore this trade-off between pleiotropy versus redundancy on the cost versus reliability as a measure of the quality of the network."
"Neighborhood-Based Topology Recognition in Sensor NetworksWe consider a crucial aspect of self-organization of a sensor network consisting of a large set of simple sensor nodes with no location hardware and only very limited communication range. After having been distributed randomly in a given two-dimensional region, the nodes are required to develop a sense for the environment, based on a limited amount of local communication. We describe algorithmic approaches for determining the structure of boundary nodes of the region, and the topology of the region. We also develop methods for determining the outside boundary, the distance to the closest boundary for each point, the Voronoi diagram of the different boundaries, and the geometric thickness of the network. Our methods rely on a number of natural assumptions that are present in densely distributed sets of nodes, and make use of a combination of stochastics, topology, and geometry. Evaluation requires only a limited number of simple local computations."
"MIPS: a database for genomes and protein sequences. The Munich Information Center for Protein Sequences (MIPS-GSF, Neuherberg, Germany) continues to provide genome-related information in a systematic way. MIPS supports both national and European sequencing and functional analysis projects, develops and maintains automatically generated and manually annotated genome-specific databases, develops systematic classification schemes for the functional annotation of protein sequences, and provides tools for the comprehensive analysis of protein sequences. This report updates the information on the yeast genome (CYGD), the Neurospora crassa genome (MNCDB), the databases for the comprehensive set of genomes (PEDANT genomes), the database of annotated human EST clusters (HIB), the database of complete cDNAs from the DHGP (German Human Genome Project), as well as the project specific databases for the GABI (Genome Analysis in Plants) and HNB (Helmholtz-Netzwerk Bioinformatik) networks. The Arabidospsis thaliana database (MATDB), the database of mitochondrial proteins (MITOP) and our contribution to the PIR International Protein Sequence Database have been described elsewhere [Schoof et al. (2002) Nucleic Acids Res., 30, 91-93; Scharfe et al. (2000) Nucleic Acids Res., 28, 155-158; Barker et al. (2001) Nucleic Acids Res., 29, 29-32]. All databases described, the protein analysis tools provided and the detailed descriptions of our projects can be accessed through the MIPS World Wide Web server (http://mips.gsf.de). "
"MIPS: a database for genomes and protein sequences.The Munich Information Center for Protein Sequences (MIPS-GSF), Martinsried, near Munich, Germany, continues its longstanding tradition to develop and maintain high quality curated genome databases. In addition, efforts have been intensified to cover the wealth of complete genome sequences in a systematic, comprehensive form. Bioinformatics, supporting national as well as European sequencing and functional analysis projects, has resulted in several up-to-date genome-oriented databases. This report describes growing databases reflecting the progress of sequencing the Arabidopsis thaliana (MATDB) and Neurospora crassa genomes (MNCDB), the yeast genome database (MYGD) extended by functional analysis data, the database of annotated human EST-clusters (HIB) and the database of the complete cDNA sequences from the DHGP (German Human Genome Project). It also contains information on the up-to-date database of complete genomes (PEDANT), the classification of protein sequences (ProtFam) and the collection of protein sequence data within the framework of the PIR-International Protein Sequence Database. These databases can be accessed through the MIPS WWW server (http://www. mips.biochem.mpg.de)."
"Evolving a Stigmergic Self-Organized Data-MiningSelf-organizing complex systems typically are comprised of a large number of frequently similar components or events. Through their process, a pattern at the global-level of a system emerges solely from numerous interactions among the lower-level components of the system. Moreover, the rules specifying interactions among the system's components are executed using only local information, without reference to the global pattern, which, as in many real-world problems is not easily accessible or possible to be found. Stigmergy, a kind of indirect communication and learning by the environment found in social insects is a well know example of self-organization, providing not only vital clues in order to understand how the components can interact to produce a complex pattern, as can pinpoint simple biological non-linear rules and methods to achieve improved artificial intelligent adaptive categorization systems, critical for Data-Mining. On the present work it is our intention to show that a new type of Data-Mining can be designed based on Stigmergic paradigms, taking profit of several natural features of this phenomenon. By hybridizing bio-inspired Swarm Intelligence with Evolutionary Computation we seek for an entire distributed, adaptive, collective and cooperative self-organized Data-Mining. As a real-world, real-time test bed for our proposal, World-Wide-Web Mining will be used. Having that purpose in mind, Web usage Data was collected from the Monash University's Web site (Australia), with over 7 million hits every week. Results are compared to other recent systems, showing that the system presented is by far promising."
"Data Compression approach to Information Extraction and ClassificationIn this paper we present a class of general methods for information extraction and automatic categorization. These methods exploit the features of data compression techniques in order to define a measure of syntactic remoteness between pairs of sequences of characters (e.g. texts) based on their relative informatic content. Using this elementary tool it is possible to implement several algorithms to address problems of information retrieval in very different domains. We address in particular several linguistic motivated problems and we present results for automatic language recognition, authorship attribution, context-based classification as well as automatic universal classification. We also discuss in detail how specific features of data compression techniques could be used to introduce the notion of “dictionary” of a given sequence and of “Artificial Text” and we show how these new tools can be used for information retrieval purposes. We finally discuss the relevance of our results in non-linguistic fields, i.e. whenever the information is codified in generic sequences of characters."
"Random Networks with Tunable Degree Distribution and ClusteringWe present an algorithm for generating random networks with arbitrary degree distribution and Clustering (frequency of triadic closure). We use this algorithm to generate networks with exponential, power law, and poisson degree distributions with variable levels of clustering. Such networks may be used as models of social networks and as a testable null hypothesis about network structure. Finally, we explore the effects of clustering on the point of the phase transition where a giant component forms in a random network, and on the size of the giant component. Some analysis of these effects is presented."
"Nominal versus Interacting Group Processes for Committee Decision-Making EffectivenessThe article reviews literature dealing with the relative effectiveness of interacting (spontaneous group discussion) versus nominal (individual silent effort in a group setting) group processes for problem-solving committees. The authors conclude that the optimal combination of group processes for a problem-solving committee is: (1) the use of nominal group processes for fact-finding, idea generation, or initial subjective probability estimation in the first phase of a committee's work; (2) the use of structured feedback and interacting discussion in the second phase; and (3) nominal group voting for final independent individual judgments in the final phase."
"Voting in the European Union: The square root system of Penrose and a critical pointThe notion of the voting power is illustrated by examples of the systems of voting in the European Council according to the Treaty of Nice and the more recent proposition of the European Convent. We show that both systems are not representative, in a sense that citizens of different countries have not the same influence for the decision taken by the Council. We present a compromise solution based on the law of Penrose, which states that the weights for each country should be proportional to the square root of its population. Analysing the behaviour of the voting power as a function of the quota we discover a critical point, which allows us to propose the value of the quota to be 62%. The system proposed is simple (only one criterion), representative, transparent, effective and objective: it is based on a statistical approach and does not favour nor handicap any European country."
"Reverse engineering of linking preferences from network restructuringWe provide a method to deduce the preferences governing the restructuring dynamics of a network from the observed rewiring of the edges. Our approach is applicable for systems in which the preferences can be formulated in terms of a single-vertex energy function with f(k) being the contribution of a node of degree k to the total energy, and the dynamics obeys the detailed balance. The method is first tested by Monte-Carlo simulations of restructuring graphs with known energies, then it is used to study variations of real network systems ranging from the co-authorship network of scientific publications to the asset graphs of the New York Stock Exchange. The empirical energies obtained from the restructuring can be described by a universal function f(k) -k ln(k), which is consistent with and justifies the validity of the preferential attachment rule proposed for growing networks."
"Mining Frequent Itemsets from Secondary MemoryMining frequent itemsets is at the core of mining association rules, and is by now quite well understood algorithmically. However, most algorithms for mining frequent itemsets assume that the main memory is large enough for the data structures used in the mining, and very few efficient algorithms deal with the case when the database is very large or the minimum support is very low. Mining frequent itemsets from a very large database poses new challenges, as astronomical amounts of raw data is ubiquitously being recorded in commerce, science and government. In this paper, we discuss approaches to mining frequent itemsets when data structures are too large to fit in main memory. Several divide-and-conquer algorithms are given for mining from disks. Many novel techniques are introduced. Experimental results show that the techniques reduce the required disk accesses by orders of magnitude, and enable truly scalable data mining."
"Traffic-driven model of the World Wide Web graphWe propose a model for the World Wide Web graph that couples the topological growth with the traffic's dynamical evolution. The model is based on a simple traffic-driven dynamics and generates weighted directed graphs exhibiting the statistical properties observed in the Web. In particular, the model yields a non-trivial time evolution of vertices and heavy-tail distributions for the topological and traffic properties. The generated graphs exhibit a complex architecture with a hierarchy of cohesiveness levels similar to those observed in the analysis of real data."
"Organization Structure and Complex Problem SolvingBased on an analysis of task characteristics and group problem-solving behavior, a division-of-labor form of organization was hypothesized to be superior in performance to committee or hierarchical forms in a business-game simulation. The experimental results strongly support the hypothesis. In addition, an interaction between organization structure and rates of improvement in performance was found and was greatest among groups showing a low level of initial performance. The problem-solving efficiency of different organization structures is discussed in relation to task requirements and the appropriate organizational behavior, to group adaptation to a task over time, and to various group characteristics."
Analyzing Stability of Equilibrium Points in Neural Networks: A General ApproachNetworks of coupled neural systems represent an important class of models in computational neuroscience. In some applications it is required that equilibrium points in these networks remain stable under parameter variations. Here we present a general methodology to yield explicit constraints on the coupling strengths to ensure the stability of the equilibrium point. Two models of coupled excitatory-inhibitory oscillators are used to illustrate the approach.
"How Crucial is Small World Connectivity for Dynamics?We study the dynamical behaviour of the collective field of chaotic systems on small world lattices. Coupled neuronal systems as well as coupled logistic maps are investigated. We observe that significant changes in dynamical properties occur only at a reasonably high strength of nonlocal coupling. Further, spectral features, such as signal-to-noise ratio (SNR), change monotonically with respect to the fraction of random rewiring, i.e. there is no optimal value of the rewiring fraction for which spectral properties are most pronounced. We also observe that for small rewiring, results are similar to those obtained by adding small noise."
"Statistical mechanics of networksWe study the family of network models derived by requiring the expected properties of a graph ensemble to match a given set of measurements of a real-world network, while maximizing the entropy of the ensemble. Models of this type play the same role in the study of networks as is played by the Boltzmann distribution in classical statistical mechanics; they offer the best prediction of network properties subject to the constraints imposed by a given set of observations. We give exact solutions of models within this class that incorporate arbitrary degree distributions and arbitrary but independent edge probabilities. We also discuss some more complex examples with correlated edges that can be solved approximately or exactly by adapting various familiar methods, including mean-field theory, perturbation theory, and saddle-point expansions."
"Social Networks and Citizen Response to Legal ChangeOur goal is to extend the research on the political importance of social networks by investigating the role of networks in shaping citizen responses to changes in the law. We emphasize the development of special-purpose social networks to cope with changing legal requirements and analyze these networks from a problem-solving perspective. The empirical focus of the work is taxpayers' adaptation to the 1986 Tax Reform Act. The results from a panel survey of 475 taxpayers demonstrate that specialized, weak-tie networks play a critical role in shaping responses to legal change. More important problems (i.e., tax increases) stimulate search among broader networks. Broader networks, in turn, lead to greater knowledge about the 1986 Tax Reform Act. Network search is biased by both taxpayer attitudes and motivation: taxpayers seek like-minded discussants, and bigger tax increases lead to more noncompliant weak-tie discussants. Finally, the attitudes of weak-tie discussants produce changes in taxpayers' attitudes about compliance, confirming the important role of networks in shaping compliance behavior."
"Spreading with immunization in high dimensions We investigate a model of epidemic spreading with partial immunization which is controlled by two probabilities, namely, for first infections, $p_0$, and reinfections, $p$. When the two probabilities are equal, the model reduces to directed percolation, while for perfect immunization one obtains the general epidemic process belonging to the universality class of dynamical percolation. We focus on the critical behavior in the vicinity of the directed percolation point, especially in high dimensions $d>2$. It is argued that the clusters of immune sites are compact for $d≤ 4$. This observation implies that a recently introduced scaling argument, suggesting a stretched exponential decay of the survival probability for $p=p_c$, $p_0\ll p_c$ in one spatial dimension, where $p_c$ denotes the critical threshold for directed percolation, should apply in any dimension $d ≤ 3$ and maybe for $d=4$ as well. Moreover, we show that the phase transition line, connecting the critical points of directed percolation and of dynamical percolation, terminates in the critical point of directed percolation with vanishing slope for $d<4$ and with finite slope for $d≥ 4$. Furthermore, an exponent is identified for the temporal correlation length for the case of $p=p_c$ and $p_0=p_c-ε$, $ε\ll 1$, which is different from the exponent $ν_\parallel$ of directed percolation. We also improve numerical estimates of several critical parameters and exponents, especially for dynamical percolation in $d=4,5$."
A mathematical description of natural shapes in our nonlinear worldThe work presents two examples of simple mathematical formulas which are natural nonlinear modifications (one being a generalization) of Gielis' formula. These formulas involve a comparable number of parameters and provide non-Platonic representations of a vast diversity of natural shapes and patterns by incorporating diverse aspects of asymmetry and seeming disorder which are absent in the original Gielis' formula. It is also shown how diverse sequences resembling some natural-world pattern evolutions are also generated by such nonlinear formulas.
"Swarming Behavior of Multi-Agent Systems In this paper we consider a continuous-time anisotropic swarm model in $n$-dimensional space with an attraction/repulsion function and study its aggregation properties. It is shown that the swarm members will aggregate and eventually form a cohesive cluster of finite size around the swarm center. Moreover, the numerical simulations show that all agents will eventually enter into and remain in a bounded region around the swarm center. The model is more general than isotropic swarms and our results provide further insight into the effect of the interaction pattern on individual motion in a swarm system."
"Self-organization in a group of mobile autonomous agentsThis paper considers a discrete time swarm model of a group of mobile autonomous agents with a simple attraction and repulsion function for swarm aggregation and investigates its stability properties. In particular, it is proved that the individuals (members) of the swarm will aggregate and form a cohesive cluster of a finite size depending only on the parameters of the swarm model in a finite time, and the swarm system is completely stable."
"Algorithms for Estimating Information Distance with Application to Bioinformatics and LinguisticsAfter reviewing unnormalized and normalized information distances based on incomputable notions of Kolmogorov complexity, we discuss how Kolmogorov complexity can be approximated by data compression algorithms. We argue that optimal algorithms for data compression with side information can be successfully used to approximate the normalized distance. Next, we discuss an alternative information distance, which is based on relative entropy rate (also known as Kullback-Leibler divergence), and compression-based algorithms for its estimation. Based on available biological and linguistic data, we arrive to unexpected conclusion that in Bioinformatics and Computational Linguistics this alternative distance is more relevant and important than the ones based on Kolmogorov complexity."
Developing Intellectual Network Management Facilities by Means of Pattern Recognition TheoryIn this paper considered question of using pattern recognition methods in network equipment state identification.
Power-law tail distributions and nonergodicityWe establish an explicit correspondence between ergodicity breaking in a system described by power-law tail distributions and the divergence of the moments of these distributions.
"Demography and Design: Predictors of New Product Team PerformanceThe increasing reliance on teams in organizations raises the question of how these teams should be formed. Should they be formed completely of engineers or should they include a range of specialists? Should they be made up to people who have long tenure in the organization, or those with a wide range of experience? As teams increasingly get called upon to do more complex tasks and to cross functional boundaries within the organization, conventional wisdom has suggested that teams be composed of more diverse members. This study suggests that the answer may not be so simple. Using 409 individuals from 45 new product teams in five high-technology companies, this study investigates the impact of diversity on team performance. We found that functional and tenure diversity each has its own distinct effects. The greater the functional diversity, the more team members communicated outside the team's boundaries. This communication was with a variety of groups such as marketing, manufacturing, and top management. The more the external communication, the higher the managerial ratings of innovation. Tenure diversity had its impact on internal group dynamics rather than external communications. Tenure diversity is associated with improved task work such as clarifying group goals and setting priorities. In turn, this clarity is associated with high team ratings of overall performance. Yet diversity is not solely positive. While it does produce internal processes and external communications that facilitate performance, it also directly impedes performance. That is, overall the effect of diversity on performance is negative, even though some aspects of group work are enhanced. It may be that for these teams diversity brings more creativity to problem solving and product development, but it impedes implementation because there is less capability for teamwork than there is for homogeneous teams. These research findings suggest that simply changing the structure of teams (i.e. combining representatives of diverse function and tenure) will not improve performance. The team must find a way to garner the positive process effects of diversity and to reduce the negative direct effects. At the team level, greater negotiation and conflict resolution skills may be necessary. At the organization level, the team may need to be protected from external political pressures and rewarded for team, rather than functional, outcomes."
"Classical Equilibrium Thermostatistics, ""Sancta sanctorum of Statistical Mechanics"", From Nuclei to StarsEquilibrium statistics of Hamiltonian systems is correctly described by the microcanonical ensemble. Classically this is the manifold of all points in the N-body phase space with the given total energy. Due to Boltzmann-Planck's principle, e^S=tr(δ(E-H)), its geometrical size is related to the entropy S(E,N,V,...). This definition does not invoke any information theory, no thermodynamic limit, no extensivity, and no homogeneity assumption. Therefore, it describes the equilibrium statistics of extensive as well of non-extensive systems. Due to this fact it is the fundamental definition of any classical equilibrium statistics. It addresses nuclei and astrophysical objects as well. S(E,N,V,...) is multiply differentiable everywhere, even at phase-transitions. All kind of phase transitions can be distinguished harply and uniquely for even small systems. What is even more important, in contrast to the canonical theory, also the region of phase-space which corresponds to phase-separation is accessible, where the most interesting phenomena occur. No deformed q-entropy is needed for equilibrium. Boltzmann-Planck is the only appropriate statistics independent of whether the system is small or large, whether the system is ruled by short or long range forces."
"Ultimate Fate of Constrained VotersWe determine the ultimate fate of individual opinions in a socially-interacting population of leftists, centrists, and rightists. In an elemental interaction between agents, a centrist and a leftist can become both centrists or both become leftists with equal rates (and similarly for a centrist and a rightist). However leftists and rightists do not interact. This interaction step between pairs of agents is applied repeatedly until the system can no longer evolve. In the mean-field limit, we determine the exact probability that the system reaches consensus (either leftist, rightist, or centrist) or a frozen mixture of leftists and rightists as a function of the initial composition of the population. We also determine the mean time until the final state is reached. Some implications of our results for the ultimate fate in a limit of the Axelrod model are discussed."
"Choices, Decisions, and Problem-SolvingTheory and research on choice and decision-making behavior is reviewed with the intent of identifying the core elements of these behavioral processes. Two distinct theoretical perspectives--""subjective/cognitive"" and ""behaviorist""--are critically examined and evaluated within the framework of their contribution to sociological theory. We then explore lacunae and ambiguities in the research and theory in the field. Definitional distinctions are drawn between the concepts of choice, decision-making, and problem-solving. Finally, we make a preliminary attempt to synthesize the work in this field, to identify core elements and suggest that the moment of choice can be considered as a microcosm of the social and behavioral forces affecting a given action at both the individual and collective level."
"Bridging Epistemologies: The Generative Dance between Organizational Knowledge and Organizational KnowingMuch current work on organizational knowledge, intellectual capital, knowledge-creating organizations, knowledge work, and the like rests on a single, traditional understanding of the nature of knowledge. We call this understanding the ""epistemology of possession,"" since it treats knowledge as something people possess. Yet, this epistemology cannot account for the knowing found in individual and group practice. Knowing as action calls for an ""epistemology of practice."" Moreover, the epistemology of possession tends to privilege explicit over tacit knowledge, and knowledge possessed by individuals over that possessed by groups. Current work on organizations is limited by this privileging and by the scant attention given to knowing in its own right. Organizations are better understood if explicit, tacit, individual and group knowledge are treated as four distinct and coequal forms of knowledge (each doing work the others cannot), and if knowledge and knowing are seen as mutually enabling (not competing). We hold that knowledge is a tool of knowing, that knowing is an aspect of our interaction with the social and physical world, and that the interplay of knowledge and knowing can generate new knowledge and new ways of knowing. We believe this generative dance between knowledge and knowing is a powerful source of organizational innovation. Harnessing this innovation calls for organizational and technological infrastructures that support the interplay of knowledge and knowing. Ultimately, these concepts make possible a more robust framing of such epistemologically-centered concerns as core competencies, the management of intellectual capital, etc. We explore these views through three brief case studies drawn from recent research."
"Simulating Project Work Processes and Organizations: Toward a Micro-Contingency Theory of Organizational DesignThe Virtual Design Team (VDT) extends and operationalizes Galbraith's (1973) information-processing view of organizations. VDT simulates the micro-level information processing, communication, and coordination behavior of participants in a project organization and predicts several measures of participant and project-level performance. VDT-1 (Cohen 1991) and VDT-2 (Christiansen 1993) modeled project organizations containing actors with perfectly congruent goals engaged in complex but routine engineering design work within static organization structures. VDT-3 extends the VDT-2 work process representation to include measures of activity flexibility, complexity, uncertainty, and interdependence strength. It explicitly models the effects of goal incongruency between agents on their information processing and communication behavior while executing more flexible tasks. These extensions allow VDT to model more flexible organizations executing less routine work processes. VDT thus bridges rigorously between cognitive and social psychological micro-organization theory and sociological and economic macro-organization theory for project teams. VDT-3 has been used to model and simulate the design of two major subsystems of a complex satellite launch vehicle. This case study provides initial evidence that the micro-contingency theory embodied in VDT-3 can be used to predict organizational breakdowns, and to evaluate alternative organizational changes to mitigate identified risks. VDT thus supports true ""organizational engineering"" for project teams."
"SGD: Saccharomyces Genome DatabaseThe Saccharomyces Genome Database (SGD) provides Internet access to the complete Saccharomyces cerevisiae genomic sequence, its genes and their products, the phenotypes of its mutants, and the literature supporting these data. The amount of information and the number of features provided by SGD have increased greatly following the release of the S.cerevisiae genomic sequence, which is currently the only complete sequence of a eukaryotic genome. SGD aids researchers by providing not only basic information, but also tools such as sequence similarity searching that lead to detailed information about features of the genome and relationships between genes. SGD presents information using a variety of user-friendly, dynamically created graphical displays illustrating physical, genetic and sequence feature maps. SGD can be accessed via the World Wide Web at http://genome-www.stanford.edu/Saccharomyces/"
"Saccharomyces Genome Database (SGD) provides secondary gene annotation using the Gene Ontology (GO).The Saccharomyces Genome Database (SGD) resources, ranging from genetic and physical maps to genome-wide analysis tools, reflect the scientific progress in identifying genes and their functions over the last decade. As emphasis shifts from identification of the genes to identification of the role of their gene products in the cell, SGD seeks to provide its users with annotations that will allow relationships to be made between gene products, both within Saccharomyces cerevisiae and across species. To this end, SGD is annotating genes to the Gene Ontology (GO), a structured representation of biological knowledge that can be shared across species. The GO consists of three separate ontologies describing molecular function, biological process and cellular component. The goal is to use published information to associate each characterized S.cerevisiae gene product with one or more GO terms from each of the three ontologies. To be useful, this must be done in a manner that allows accurate associations based on experimental evidence, modifications to GO when necessary, and careful documentation of the annotations through evidence codes for given citations. Reaching this goal is an ongoing process at SGD. For information on the current progress of GO annotations at SGD and other participating databases, as well as a description of each of the three ontologies, please visit the GO Consortium page at http://www.geneontology.org. SGD gene associations to GO can be found by visiting our site at http://genome-www.stanford.edu/Saccharomyces/."
"Technicians in the Workplace: Ethnographic Evidence for Bringing Work into Organizational StudiesThis paper lays the groundwork for new models of work and relations of production that reflect changes in the division of labor and occupational structure of a postindustrial economy. It demonstrates how new ideal-typical occupations can be constructed, drawing on a set of ethnographies to propose an empirically grounded model of technicians' work. The paper focuses on two questions: What do technicians do and what do they know? The answers constitute a first cut at the ideal type, technician. The paper then turns to evidence of the difficulties that arise when organizations employ technicians but fail to appreciate the nature of their work. It closes by showing how a contextually derived model of technicians' work enables us to evaluate why some recent trends in organizing are congruent with an increasingly technical workforce, why others may be misguided, and why organizations are likely to face challenges that organizational theorists have but vaguely anticipated. The paper shows that the emergence of technicians' work may signify a shift to a more horizontal division of substantive expertise that undermines the logic of vertical organizing on which most organizational theory and practice still rests."
"Saccharomyces Genome Database (SGD) provides biochemical and structural information for budding yeast proteinsThe Saccharomyces Genome Database (SGD: http://genome-www.stanford.edu/Saccharomyces/) has recently developed new resources to provide more complete information about proteins from the budding yeast Saccharomyces cerevisiae. The PDB Homologs page provides structural information from the Protein Data Bank (PDB) about yeast proteins and/or their homologs. SGD has also created a resource that utilizes the eMOTIF database for motif information about a given protein. A third new resource is the Protein Information page, which contains protein physical and chemical properties, such as molecular weight and hydropathicity scores, predicted from the translated ORF sequence. 10.1093/nar/gkg054"
"Saccharomyces Genome Database (SGD) provides tools to identify and analyze sequences from Saccharomyces cerevisiae and related sequences from other organisms.The Saccharomyces Genome Database (SGD; http://www.yeastgenome.org/), a scientific database of the molecular biology and genetics of the yeast Saccharomyces cerevisiae, has recently developed several new resources that allow the comparison and integration of information on a genome-wide scale, enabling the user not only to find detailed information about individual genes, but also to make connections across groups of genes with common features and across different species. The Fungal Alignment Viewer displays alignments of sequences from multiple fungal genomes, while the Sequence Similarity Query tool displays PSI-BLAST alignments of each S.cerevisiae protein with similar proteins from any species whose sequences are contained in the non-redundant (nr) protein data set at NCBI. The Yeast Biochemical Pathways tool integrates groups of genes by their common roles in metabolism and displays the metabolic pathways in a graphical form. Finally, the Find Chromosomal Features search interface provides a versatile tool for querying multiple types of information in SGD."
"The Platform Organization: Recombining Strategies, Structures, and SurprisesThe global technology strategy of Olivetti, a leading European computer firm, is analyzed over the last decade in order to illustrate how high-tech firms undergo transformations which not only tend to destroy their best core competencies, but also affect their very business identity. Task uncertainty is so pronounced that conventional ways of looking at the organizational structures and processes, such as the transaction costs approach or the strategy-structure link, need to be amended in favor of a more dynamic perspective. Such a perspective looks at organizations as platforms, or contexts, out of which specific structures are extracted, tried out and discarded in a pragmatic manner. A platform is a meta-organization, a formative context that molds structures, and routines shaping them into well-known forms, such as the hierarchy, the matrix and even the network, but on a highly volatile basis. Hence, the platform organization may appear to be confused and inefficient but its value lies in its readiness to sport whatever organizational form is required under the circumstances. Platforms are characterized by surprises, and organization members, no matter how they see themselves after the fact, are busy improvising and tinkering. Drawing on similar studies carried out in Silicon Valley, one can draw the conclusion that high-tech firms can survive if they are smart at doing what ""savages do daily,"" i.e., bricolage."
"Seeing in DepthOn oceanographic research vessels, scientists from different disciplines must work together to obtain samples from the sea beneath their ship. Such juxtaposition of not just theory, but actual laboratory practice, creates unique possibilities for synergy, as members of one discipline make use of the tools of another. Using videotapes of technicians deploying a probe in the mouth of the Amazon, this paper investigates how multiple kinds of space - including the sea under the ship, graphic representations, the work space of the lab, and emboided participation frameworks for the organization of tool-mediated human interaction - are constituted through a range of temporally unfolding, work-relevant, situated practices. Particular attention is paid to how three parties work together to precisely position the probe at a spot where a geochemist wants to take samples. Because each actor uses alternative tools to organize his or her perception in ways appropriate to complementary tasks required for the successful accomplishment of the sampling run, each sees the place they are looking at together in a very different way."
"A Model of Knowledge Management and the N-Form CorporationA model of knowledge management is developed. It builds on the interplay between articulated and tacit knowledge at four different levels: the individual, the small group, the organization, and the interorganizational domain. The model is applied on differences between Western and Japanese patterns of knowledge management. These are related to organizational characteristics, such as employment systems, career patterns, and organization structure. Effective knowledge management is argued to require departures from the logic of hierarchical organization and the M-form structure. The alternative N-form is characterized and suggested as more appropriate. It entails combination of knowledge rather than its division, which is the basic principle in the M-form. Other attributes of the N-form are: temporary constellations of people, the importance of personnel at `lower levels', lateral communication, a catalytic and architectural role for top management, strategies aimed at focusing and economies of depth, and heterarchical structures."
"On the uniform generation of random graphs with prescribed degree sequencesRandom graphs with prescribed degree sequences have been widely used as a model of complex networks. Comparing an observed network to an ensemble of such graphs allows one to detect deviations from randomness in network properties. Here we briefly review two existing methods for the generation of random graphs with arbitrary degree sequences, which we call the “switching” and “matching” methods, and present a new method based on the “go with the winners” Monte Carlo method. The matching method may suffer from nonuniform sampling, while the switching method has no general theoretical bound on its mixing time. The “go with the winners” method has neither of these drawbacks, but is slow. It can however be used to evaluate the reliability of the other two methods and, by doing this, we demonstrate that the deviations of the switching and matching algorithms under realistic conditions are small compared to the “go with the winners” algorithm. Because of its combination of speed and accuracy we recommend the use of the switching method for most calculations."
Phase diagram in Bonabeau social hierarchy model with individually different abilitiesThe 1995 model of Bonabeau et al is generalized by giving each individual a different ability to win or lose a fight. We also introduce different groups such that the losers of fights between different groups are eliminated. The overall phase diagram for the first-order transition between egalitarian and hierarchical societies does not change much by these generalizations.
"Minimum spanning trees on weighted scale-free networksA complete understanding of real networks requires us to understand the consequences of the uneven interaction strengths between a system's components. Here we use the minimum spanning tree (MST) to explore the effect of weight assignment and network topology on the organization of complex networks. We find that if the weight distribution is correlated with the network topology, the MSTs are either scale-free or exponential. In contrast, when the correlations between weights and topology are absent, the MST degree distribution is a power-law and independent of the weight distribution. These results offer a systematic way to explore the impact of weak links on the structure and integrity of complex networks."
"Resisting Attrition Attacks on a Peer-to-Peer SystemPeer-to-peer systems are vulnerable to attrition attacks that include both traditional, network-level denial of service attacks as well as application-level attacks in which malign peers conspire to waste loyal peers' resources. We describe a set of defenses for the LOCKSS digital preservation system that help ensure that application level attacks even from powerful adversaries are less effective than network-level attacks, and that network-level attacks must be intense, wide-spread, and prolonged to impair the system."
"Exactly solvable scale-free network model We study a deterministic scale-free network recently proposed by Barabási, Ravasz and Vicsek. We find that there are two types of nodes: the hub and rim nodes, which form a bipartite structure of the network. We first derive the exact numbers $P(k)$ of nodes with degree $k$ for the hub and rim nodes in each generation of the network, respectively. Using this, we obtain the exact exponents of the distribution function $P(k)$ of nodes with $k$ degree in the asymptotic limit of $k \to ∞$. We show that the degree distribution for the hub nodes exhibits the scale-free nature, $P(k) ∝ k^-γ$ with $γ = \ln3/\ln2 = 1.584962$, while the degree distribution for the rim nodes is given by $P(k) ∝ e^-γ'k$ with $γ' = \ln(3/2) = 0.405465$. Second, we numerically as well as analytically calculate the spectra of the adjacency matrix $A$ for representing topology of the network. We also analytically obtain the exact number of degeneracy at each eigenvalue in the network. The density of states (i.e., the distribution function of eigenvalues) exhibits the fractal nature with respect to the degeneracy. Third, we study the mathematical structure of the determinant of the eigenequation for the adjacency matrix. Fourth, we study hidden symmetry, zero modes and its index theorem in the deterministic scale-free network. Finally, we study the nature of the maximum eigenvalue in the spectrum of the deterministic scale-free network. We will prove several theorems for it, using some mathematical theorems. Thus, we show that most of all important quantities in the network theory can be analytically obtained in the deterministic scale-free network model of Barabási, Ravasz and Vicsek. Therefore, we may call this network model the exactly solvable scale-free network."
"How can we think the complex?This chapter does not deal with specific tools and techniques for managing complex systems, but proposes some basic concepts that help us to think and speak about complexity. We review classical thinking and its intrinsic drawbacks when dealing with complexity. We then show how complexity forces us to build models with indeterminacy and unpredictability. However, we can still deal with the problems created in this way by being adaptive, and profiting from a complex system's capability for selforganization, and the distributed intelligence this may produce."
"Efficient Algorithms for Sampling and Clustering of Large Nonuniform NetworksWe propose efficient algorithms for two key tasks in the analysis of large nonuniform networks: uniform node sampling and cluster detection. Our sampling technique is based on augmenting a simple, but slowly mixing uniform MCMC sampler with a regular random walk in order to speed up its convergence; however the combined MCMC chain is then only sampled when it is in its ""uniform sampling"" mode.Our clustering algorithm determines the relevant neighbourhood of a given node u in the network by first estimating the Fiedler vector of a Dirichlet matrix with u fixed at zero potential, and then finding the neighbourhood of u that yields a minimal weighted Cheeger ratio, where the edge weights are determined by differences in the estimated node potentials. Both of our algorithms are based on local computations, i.e. operations on the full adjacency matrix of the network are not used. The algorithms are evaluated experimentally using three types of nonuniform networks: Dorogovtsev-Goltsev-Mendes ""pseudofractal graphs"", scientific collaboration networks, and randomised ""caveman graphs""."
"Possible Laws for Artificial Life EvolutionMotivated by a recent article on open problems in artificial life, here I postulate three laws which form a mathematical framework to describe artificial life evolutionary dynamics. They are based on a continuous approximation of population dynamics. Four dynamical elements are required in this formulation: ascendant matrix, transverse matrix, fitness function, and the stochastic drive. The first law states that in the absence of stochastic drive the artificial life always seeks for a local fitness attractor and stay there. It gives the reference point to discuss the general evolutionary dynamics. The second law is explicitly expressed in a unique form of stochastic differential equation with all four dynamical elements. The third law defines the relationship between the focused level of description to its lower and higher ones, and also defines the dichotomy of deterministic and stochastic drives. These laws provide a coherence framework to discuss several current problems, such as emergency and stability. In particular, two quantities are emphasized: the fitness function as the standard for selection and the stochasticity as the source of creativity. Those three laws may appear almost self-evident from a statistical physics point of view. However, their equivalent to a most conventional approach for evolutionary dynamics is shown for the first time by the present author, to the best of his knowledge. The computational advantage of the present formulation in the study of artificial life evolution is also discussed."
"What's in a name?Among the several findings deriving from the application of complex network formalism to the investigation of natural phenomena, the fact that linguistic constructions follow power laws presents special interest for its potential implications for psychology and brain science. By corresponding to one of the most essentially human manifestations, such language-related properties suggest that similar dynamics may also be inherent to the brain areas related to language and associative memory, and perhaps even consciousness. The present work reports a preliminary experimental investigation aimed at characterizing and modeling the flow of sequentially induced associations between words from the English language in terms of complex networks. The data is produced through a psychophysical experiment where a word is presented to the subject, who is requested to associate another word. Complex network and graph theory formalism and measurements are applied in order to characterize the experimental data. Several interesting results are identified, including the characterization of attraction basins, association asymmetries, context biasing, as well as a possible power-law underlying word associations, which could be explained by the appearance of strange loops along the hierarchical structure underlying word categories."
"Reinforcing the Resilience of Complex NetworksGiven a connected network, it can be augmented by applying a growing strategy (e.g. random or scale-free rules) over the previously existing structure. Another approach for augmentation, recently introduced, involves incorporating a direct edge between any two nodes which are found to be connected through at least one self-avoiding path of length L. This work investigates the resilience of random and scale-free models augmented by using the three schemes identified above. Considering random and scale-free networks, their giant cluster are identified and reinforced, then the resilience of the resulting networks with respect to highest degree node attack is quantified through simulations. The results, which indicate that substantial reinforcement of the resilience of complex networks can be achieved by the expansions, also confirm the superior robustness of the random expansion."
"The fractal/small-world dichotomy in real-world networksWe draw attention to a clear dichotomy between small-world networks exhibiting exponential neighborhood growth, and fractal-like networks where neighborhoods grow according to a power law. This distinction is observed in a number of real-world networks, and is related to the degree correlations and geographical constraints. We conclude by pointing out that the status of human social networks in this dichotomy is far from clear."
"A simple adaptive-feedback controller for high-quality chaos synchronization Based on the invariance principle of differential equations, a simple adaptive-feedback scheme is proposed to strictly synchronize almost all chaotic systems. Unlike the usual linear feedback, the variable feedback strength is automatically adapted to completely synchronize two almost arbitrary identical chaotic systems, so this scheme is analytical, and simple to implement in practice. Moreover it is quite robust against the effect of noise. The famous Lorenz and R$o$ssler hyperchaos systems are used as illustrative examples."
"On the interpretation of ""off the edge"" avalanchesWe establish both experimentally and theoretically the relation between off the edge and internal avalanches in a sandpile model, a central issue in the interpretation of most experiments in these systems. In BTW simulations and also in the experiments the size distributions of internal avalanches show power laws and critical exponents related with the dimension of the system. We show that, in a SOC scenario, the distributions of off the edge avalanches do not show power laws but follow scaling relations with critical exponents different from their analogous for the internal avalanche distributions."
Bias Analysis in Entropy EstimationWe consider the problem of finite sample corrections for entropy estimation. New estimates of the Shannon entropy are proposed and their systematic error (the bias) is computed analytically. We find that our results cover correction formulas of current entropy estimates recently discussed in literature. The trade-off between bias reduction and the increase of the corresponding statistical error is analyzed.
Simplest equation method to look for exact solutions of nonlinear differential equationsNew method is presented to look for exact solutions of nonlinear differential equations. Two basic ideas are at the heart of our approach. One of them is to use the general solutions of the simplest nonlinear differential equations. Another idea is to take into consideration all possible singularities of equation studied. Application of our approach to search exact solutions of nonlinear differential equations is discussed in detail. The method is used to look for exact solutions of the Kuramoto - Sivashinsky equation and the equation for description of nonlinear waves in a convective fluid. New exact solitary and periodic waves of these equations are given.
"Implementation of Logical Functions in the Game of LifeThe Game of Life cellular automaton is a classical example of a massively parallel collision-based computing device. The automaton exhibits mobile patterns, gliders, and generators of the mobile patterns, glider guns, in its evolution. We show how to construct the basic logical operations, AND, OR, NOT in space-time configurations of the cellular automaton. Also decomposition of complicated Boolean functions is discussed. Advantages of our technique are demonstrated on an example of binary adder, realized via collision of glider streams."
"Scalable Percolation Search in Power Law Networks We introduce a scalable searching algorithm for finding nodes and contents in random networks with Power-Law (PL) and heavy-tailed degree distributions. The network is searched using a probabilistic broadcast algorithm, where a query message is relayed on each edge with probability just above the bond percolation threshold of the network. We show that if each node caches its directory via a short random walk, then the total number of "
"Weighted evolving networks: coupling topology and weights dynamicsWe propose a model for the growth of weighted networks that couples the establishment of new edges and vertices and the weights' dynamical evolution. The model is based on a simple weight-driven dynamics and generates networks exhibiting the statistical properties observed in several real-world systems. In particular, the model yields a non-trivial time evolution of vertices' properties and scale-free behavior for the weight, strength and degree distributions."
"Study on Evolvement Complexity in an Artificial Stock MarketAn artificial stock market is established based on multi-agent modeling method. Each agent has a limit memory of the history of stock price, and will choose an action according to his memory and trading strategy. The trading strategy of each agent evolves ceaselessly as a result of self-teaching mechanism. The ""market data-like"" time series are generated by our model, and by defining a variable to gauge the ""evolvement complexity"" of this system, we have found a phase transition from simple-phase to complex-phase along with the increase of the number of individuals, which may be a ubiquitous phase-transition in multifarious real-life systems."
"Modeling Stock Market Based on Genetic Cellular AutomataAn artificial stock market is established with the modeling method and ideas of cellular automata. Cells are used to represent stockholders, who have the capability of self-teaching and are affected by the investing history of the neighboring ones. The neighborhood relationship among the stockholders is the expanded Von Neumann relationship, and the interaction among them is realized through selection operator and crossover operator. Experiment shows that the large events are frequent in the fluctuations of the stock price generated by the artificial stock market when compared with a normal process and the price returns distribution is a Levy distribution in the central part followed by an approximately exponential truncation."
"The large-scale organization of chemical reaction networks in astrophysicsThe large-scale organization of complex networks, both natural and artificial, has shown the existence of highly heterogeneous patterns of organization. Such patterns typically involve scale-free degree distributions and small world, modular architectures. One example is provided by chemical reaction networks, such as the metabolic pathways. The chemical reactions of the Earth's atmosphere have also been shown to give rise to a scale-free network. Here we present novel data analysis on the structure of several astrophysical networks including the chemistry of the planetary atmospheres and the interstellar medium. Our work reveals that Earth's atmosphere displays a hierarchical organization, close to the one observed in cellular webs. Instead, the other astrophysical reaction networks reveal a much simpler pattern consistent with an equilibrium state. The implications for large-scale regulation of the planetary dynamics are outlined."
"Can two chaotic systems make an order?The recently discovered Parrondo's paradox claims that two losing games can result, under random or periodic alternation of their dynamics, in a winning game: ""losing+losing=winning"". In this paper we follow Parrondo's philosophy of combining different dynamics and we apply it to the case of one-dimensional quadratic maps. We prove that the periodic mixing of two chaotic dynamics originates an ordered dynamics in certain cases. This provides an explicit example (theoretically and numerically tested) of a different Parrondian paradoxical phenomenon: ""chaos+chaos=order"""
"Zipf's law and the creation of musical contextThis article discusses the extension of the notion of context from linguistics to the domain of music. In language, the statistical regularity known as Zipf's law -which concerns the frequency of usage of different words- has been quantitatively related to the process of text generation. This connection is established by Simon's model, on the basis of a few assumptions regarding the accompanying creation of context. Here, it is shown that the statistics of note usage in musical compositions are compatible with the predictions of Simon's model. This result, which gives objective support to the conceptual likeness of context in language and music, is obtained through automatic analysis of the digital versions of several compositions. As a by-product, a quantitative measure of context definiteness is introduced and used to compare tonal and atonal works."
"Poisson Hypothesis for Information Networks (A study in non-linear Markov processes) I. Domain of ValidityIn this paper we study the Poisson Hypothesis, which is a device to analyze approximately the behavior of large queueing networks. We prove it in some simple limiting cases. We show in particular that the corresponding dynamical system, defined by the non-linear Markov process, has a line of fixed points which are global attractors. To do this we derive the corresponding non-linear equation and we explore its self-averaging properties. We also argue that in cases of havy-tail service times the PH can be violated."
"Exploring complex networks by walking on themWe carry out a comparative study on the problem for a walker searching on several typical complex networks. The search efficiency is evaluated for various strategies. Having no knowledge of the global properties of the underlying networks and the optimal path between any two given nodes, it is found that the best search strategy is the self-avoid random walk. The preferentially self-avoid random walk does not help in improving the search efficiency further. In return, topological information of the underlying networks may be drawn by comparing the results of the different search strategies."
"Using Self-Organising Mappings to Learn the Structure of Data ManifoldsIn this paper it is shown how to map a data manifold into a simpler form by progressively discarding small degrees of freedom. This is the key to self-organising data fusion, where the raw data is embedded in a very high-dimensional space (e.g. the pixel values of one or more images), and the requirement is to isolate the important degrees of freedom which lie on a low-dimensional manifold. A useful advantage of the approach used in this paper is that the computations are arranged as a feed-forward processing chain, where all the details of the processing in each stage of the chain are learnt by self-organisation. This approach is demonstrated using hierarchically correlated data, which causes the processing chain to split the data into separate processing channels, and then to progressively merge these channels wherever they are correlated with each other. This is the key to self-organising data fusion."
"Information theory, multivariate dependence, and genetic network inferenceWe define the concept of dependence among multiple variables using maximum entropy techniques and introduce a graphical notation to denote the dependencies. Direct inference of information theoretic quantities from data uncovers dependencies even in undersampled regimes when the joint probability distribution cannot be reliably estimated. The method is tested on synthetic data. We anticipate it to be useful for inference of genetic circuits and other biological signaling networks."
"Enhancing complex-network synchronizationHeterogeneity in the degree (connectivity) distribution has been shown to suppress synchronization in networks of symmetrically coupled oscillators with uniform coupling strength (unweighted coupling). Here we uncover a condition for enhanced synchronization in directed networks with weighted coupling. We show that, in the optimum regime, synchronizability is solely determined by the average degree and does not depend on the system size and the details of the degree distribution. In scale-free networks, where the average degree may increase with heterogeneity, synchronizability is drastically enhanced and may become positively correlated with heterogeneity, while the overall cost involved in the network coupling is significantly reduced as compared to the case of unweighted coupling."
"Modeling the evolution of weighted networksWe present a general model for the growth of weighted networks in which the structural growth is coupled with the edges' weight dynamical evolution. The model is based on a simple weight-driven dynamics and a weights' reinforcement mechanism coupled to the local network growth. That coupling can be generalized in order to include the effect of additional randomness and non-linearities which can be present in real-world networks. The model generates weighted graphs exhibiting the statistical properties observed in several real-world systems. In particular, the model yields a non-trivial time evolution of vertices properties and scale-free behavior with exponents depending on the microscopic parameters characterizing the coupling rules. Very interestingly, the generated graphs spontaneously achieve a complex hierarchical architecture characterized by clustering and connectivity correlations varying as a function of the vertices' degree."
"Networking genetic regulation and neural computation: Directed network topology and its effect on the dynamicsTwo different types of directed networks are investigated, transcriptional regulation networks and neural networks. The directed network structure are studied and also shown to reflect the different processes taking place on the networks. The distribution of influence, identified as the the number of downstream vertices, are used as a tool for investigating random vertex removal. In the transcriptional regulation networks we observe that only a small number of vertices have a large influence. The small influences of most vertices limit the effect of a random removal to in most cases only a small fraction of vertices in the network. The neural network has a rather different topology with respect to the influence, which are large for most vertices. To further investigate the effect of vertex removal we simulate the biological processes taking place on the networks. Opposed to the presumpted large effect of random vertex removal in the neural network, the high density of edges in conjunction with the dynamics used makes the change in the state of the system to be highly localized around the removed vertex."
"Memory Driven Pattern FormationThe diffusion equation is extended by including spatial-temporal memory in such a manner that the conservation of the concentration is maintained. The additional memory term gives rise to the formation of non-trivial stationary solutions. The steady state pattern in an infinite domain is driven by a competition between conventional particle current and a feedback current. We give a general criteria for the existence of a non-trivial stationary state. The applicability of the model is tested in case of a strongly localized, time independent memory kernel. The resulting evolution equation is exactly solvable in arbitrary dimensions and the analytical solutions are compared with numerical simulations. When the memory term offers an spatially decaying behavior, we find also the exact stationary solution in form of a screened potential."
"A comprehensive weighted evolving network modelMany social, technological, biological, and economical systems are best described by weighted networks, whose properties and dynamics depend not only on their structures but also on the connection weights among their nodes. However, most existing research work on complex network models are concentrated on network structures, with connection weights among their nodes being either 1 or 0. In this paper, we propose a new weighted evolving network model. Numerical simulations indicate that this network model yields three power-law distributions of the node degrees, connection weights and node strengths. Particularly, some other properties of the distributions, such as the droop-head and heavy-tail effects, can also be reflected by this model."
"Apollonian networksWe introduce a new family of networks, the Apollonian networks, that are simultaneously scale-free, small world, Euclidean, space-filling and matching graphs. These networks have a wide range of applications ranging from the description of force chains in polydisperse granular packings and geometry of fully fragmented porous media, to hierarchical road systems and area-covering electrical supply networks. Some of the properties of these networks, namely, the connectivity exponent, the clustering coefficient, and the shortest path are calculated and found to be particularly rich. The percolation, the electrical conduction and the Ising models on such networks are also studied and found to be quite peculiar. Consequences for applications are also discussed."
"Global Optimization of Minority Game by Smart AgentsWe propose a new model of minority game with so-called smart agents such that the standard deviation and the total loss in this model reach the theoretical minimum values in the limit of long time. The smart agents use trail and error method to make a choice but bring global optimization to the system, which suggests that the economic systems may have the ability to self-organize into a highly optimized state by agents who are forced to make decisions based on inductive thinking for their limited knowledge and capabilities. When other kinds of agents are also present, the experimental results and analyses show that the smart agent can gain profits from producers and are much more competent than the noise traders and conventional agents in original minority game."
"Dynamical mean-filed approximation to small-world networks of spiking neurons: From local to global, and/or from regular to random couplings By extending a dynamical mean-field approximation (DMA) previously proposed by the author [H. Hasegawa, Phys. Rev. E "
"Phase Transitions in an Aging Network We consider a growing network in which an incoming node gets attached to the $i^th$ existing node with the probability $Π_i ∝ k_i^βτ_i^α$, where $k_i$ is the degree of the $i^th$ node and $τ_i$ its present age. The phase diagram in the $α-β$ plane is obtained. The network shows scale-free behaviour, i.e., the degree distribution $P(k) ∼ k^-γ$ with $γ =3$ only along a line in this plane. Small world property, on the other hand, exists over a large region in the phase diagram."
"Computation of Confidence Levels for Exclusion or Discovery of a Signal with the Method of Fractional Event CountingA method is described, which computes from an observed sample of events upper limits for production rates of particles, or, in case of appearance of a signal, the probability for an upwards fluctuation of the background. For any candidate, a weight is defined, and the computation is based on the sum of observed weights. Candidates may be distributed over many decay channels with different detection efficiencies, physical observables and different or poorly known background. Systematic errors with any possible correlations are taken into account and they are incorporated into the weight definition. It is investigated, under which conditions a Bayesian treatment of systematic errors is correct. Some numerical examples are given and compared with the results of other methods. Simple approximate formulas for observed and expected confidence levels are given for the limiting case of high count rates. A special procedure is introduced, which analyses input data in terms of polynomial distributions. It extracts confidence levels for a signal or background hypothesis on the basis of spectral shapes only, normalizing the total rate to the number of observed events."
"Biology helps to construct weighted scale free networksIn this work we study a simple evolutionary model of bipartite networks which its evolution is based on the duplication of nodes. Using analytical results along with numerical simulation of the model, we show that the above evolutionary model results in weighted scale free networks. Indeed we find that in the one mode picture we have weighted networks with scale free distributions for interesting quantities like the weights, the degrees and the weighted degrees of the nodes and the weights of the edges."
"Statistical Economics on Solomon-NetworksWe propose a Statistical-Mechanics-based framework for modeling economic systems, where each agent is characterized by multiple variables of distinct nature. Each type of variable (e.g. saving ratio, expectations from the market, etc.) constitutes a distinct spin-field (layer) with a particular graph structure characteristic to the layer, with one set of nodes (economic agents) common to all layers. In addition to local interaction of neighboring site variables within a layer, pairs of variables associated with the same agents in different layers interact. Accordingly, each layer may have a distinct dynamics, but both layers are coupled. We call a system with the above architecture a ""Solomon Network"". We present Monte Carlo simulations results for a simple instance of a Solomon Network, where an Ising chain is coupled to a one-dimensional generalized Blume-Capel chain. The hybrid system displays a phase transition which is investigated in the paper."
"beta-Catenin and BMP-2 synergize to promote osteoblast differentiation and new bone formation.Mutations of critical components of the Wnt pathway profoundly affect skeletal development and maintenance, probably via modulation of beta-catenin signaling. We tested the hypothesis that beta-catenin is involved in mesenchymal lineage allocation to osteogenic cells using a beta-catenin mutant with constitutive transcriptional activity (DeltaN151). Although this stable beta-catenin had no effects by itself on osteogenic differentiation of multipotent embryonic cell lines, it synergized with bone morphogenetic protein-2 (BMP-2) resulting in dramatic stimulation of alkaline phosphatase activity, osteocalcin gene expression, and matrix mineralization. Likewise, DeltaN151 and BMP-2 synergistically stimulated new bone formation after subperiosteal injection in mouse calvaria in vivo. Conversely, DeltaN151 prevented adipogenic differentiation from pre-adipocytic or uncommitted mesenchymal cells in vitro. Intriguingly, the synergism with BMP-2 on gene transcription occurred without altering expression of Cbfa1/Runx2, suggesting actions independent or downstream of this osteoblast-specific transcription factor. Thus, beta-catenin directs osteogenic lineage allocation by enhancing mesenchymal cell responsiveness to osteogenic factors, such as BMP-2, in part via Tcf/Lef dependent mechanisms. In vivo, this synergism leads to increased new bone formation. (c) 2004 Wiley-Liss, Inc."
"A Stochastic Evolutionary Model Exhibiting Power-Law Behaviour with an Exponential CutoffRecently several authors have proposed stochastic evolutionary models for the growth of complex networks that give rise to power-law distributions. These models are based on the notion of preferential attachment leading to the “rich get richer” phenomenon. Despite the generality of the proposed stochastic models, there are still some unexplained phenomena, which may arise due to the limited size of networks such as protein and e-mail networks. Such networks may in fact exhibit an exponential cutoff in the power-law scaling, although this cutoff may only be observable in the tail of the distribution for extremely large networks. We propose a modification of the basic stochastic evolutionary model, so that after, for example, a node is chosen preferentially, say according to the number of its inlinks, there is a small probability that this node will be discarded. We show that as a result of this modification, by viewing the stochastic process in terms of an urn transfer model, we obtain a power-law distribution with an exponential cutoff. Unlike many other models, the current model can capture instances where the exponent of the distribution is less than or equal to two. As a proof of concept, we demonstrate the consistency of our model by analysing the protein yeast network, whose distribution is known to follow a power law with an exponential cutoff."
"A statistical approach to the traceroute-like exploration of networks: theory and simulationsMapping the Internet generally consists in sampling the network from a limited set of sources by using ""traceroute""-like probes. This methodology, akin to the merging of different spanning trees to a set of destinations, has been argued to introduce uncontrolled sampling biases that might produce statistical properties of the sampled graph which sharply differ from the original ones. Here we explore these biases and provide a statistical analysis of their origin. We derive a mean-field analytical approximation for the probability of edge and vertex detection that exploits the role of the number of sources and targets and allows us to relate the global topological properties of the underlying network with the statistical accuracy of the sampled graph. In particular we find that the edge and vertex detection probability is depending on the betweenness centrality of each element. This allows us to show that shortest path routed sampling provides a better characterization of underlying graphs with scale-free topology. We complement the analytical discussion with a throughout numerical investigation of simulated mapping strategies in different network models. We show that sampled graphs provide a fair qualitative characterization of the statistical properties of the original networks in a fair range of different strategies and exploration parameters. The numerical study also allows the identification of intervals of the exploration parameters that optimize the fraction of nodes and edges discovered in the sampled graph. This finding might hint the steps toward more efficient mapping strategies."
"Theory of Networked Minority Games based on Strategy Pattern Dynamics We formulate a theory of agent-based models in which agents compete to be in a winning group. The agents may be part of a network or not, and the winning group may be a minority group or not. The novel feature of the present formalism is its focus on the dynamical pattern of strategy rankings, and its careful treatment of the strategy ties which arise during the system's temporal evolution. We apply it to the Minority Game (MG) with connected populations. Expressions for the mean success rate among the agents and for the mean success rate for agents with $k$ neighbors are derived. We also use the theory to estimate the value of connectivity $p$ above which the Binary-Agent-Resource system with high resource level goes into the high-connectivity state."
"Consensus formation on a triad scale-free networkSeveral cases of the Sznajd model of socio-physics, that only a group of people sharing the same opinion can convince their neighbors, have been simulated on a more realistic network with a stronger clustering. In addition, many opinions, instead of usually only two, and a convincing probability have been also considered. Finally, with minor changes we obtain a vote distribution in good agreement with reality."
"Random walk and trapping processes on scale-free networks In this work we investigate the dynamics of random walk processes on scale-free networks in a short to moderate time scale. We perform extensive simulations for the calculation of the mean squared displacement, the network coverage and the survival probability on a network with a concentration $c$ of static traps. We show that the random walkers remain close to their origin, but cover a large part of the network at the same time. This behavior is markedly different than usual random walk processes in the literature. For the trapping problem we numerically compute $Φ(n,c)$, the survival probability of mobile species at time $n$, as a function of the concentration of trap nodes, $c$. Comparison of our results to the Rosenstock approximation indicate that this is an adequate description for networks with $2<γ<3$ and yield an exponential decay. For $γ>3$ the behavior is more complicated and one needs to employ a truncated cumulant expansion."
"Modelling Selforganization and Innovation Processes in NetworksIn this paper we develop a theory to describe innovation processes in a network of interacting units. We introduce a stochastic picture that allows for the clarification of the role of fluctuations for the survival of innovations in such a non-linear system. We refer to the theory of complex networks and introduce the notion of sensitive networks. Sensitive networks are networks in which the introduction or the removal of a node/vertex dramatically changes the dynamic structure of the system. As an application we consider interaction networks of firms and technologies and describe technological innovation as a specific dynamic process. Random graph theory, percolation, master equation formalism and the theory of birth and death processes are the mathematical instruments used in this paper."
"Memory effect in growing treesWe show that the structure of a growing tree preserves an information on the shape of an initial graph. For the exponential trees, evidence of this kind of memory is provided by means of the iterative equations, derived for the moments of the node-node distance distribution. Numerical calculations confirm the result and allow to extend the conclusion to the Barabasi--Albert scale-free trees. The memory effect almost disappears, if subsequent nodes are connected to the network with more than one link."
"Separating internal and external dynamics of complex systemsThe observable behavior of a complex system reflects the mechanisms governing the internal interactions between the system's components and the effect of external perturbations. Here we show that by capturing the simultaneous activity of several of the system's components we can separate the internal dynamics from the external fluctuations. The method allows us to systematically determine the origin of fluctuations in various real systems, finding that while the Internet and the computer chip have robust internal dynamics, highway and Web traffic are driven by external demand. As multichannel measurements are becoming the norm in most fields, the method could help uncover the collective dynamics of a wide array of complex systems."
"Two complementary representations of a scale-free network Several studies on real complex networks from different fields as biology, economy, or sociology have shown that the degree of nodes (number of edges connected to each node) follows a scale-free power-law distribution like $P(k)≈ k^-γ$, where $P(k)$ denotes the frequency of the nodes that are connected to $k$ other nodes. Here we have carried out a study on scale-free networks, where a line graph transformation (i.e., edges in an initial network are transformed into nodes) is applied on a power-law distribution. Our results indicate that a power-law distribution as $P(k)≈ k^-γ +1$ is found for the transformed network together with a peak for low-degree nodes. In the present work we show a parametrization of this behaviour and discuss its application on real networks."
Quantum Game Theory in FinanceThis is a short review of the background and recent development in quantum game theory and its possible application in economics and finance. The intersection of science and society is also discussed. The review is addressed to non--specialists.
"Distance-d covering problems in scale-free networks with degree correlationsA number of problems in communication systems demand the distributed allocation of network resources in order to provide better services, sampling and distribution methods. The solution to these issues is becoming more challenging due to the increasing size and complexity of communication networks. We report here on an heuristic method that allows to find near-optimal solutions to the covering problem in real communication networks. The results show that the optimal allocation of resources strongly depends on the topology of the underlying networks. Whether a centralized or distributed design is to be used relies upon the degree correlations between connected vertices."
"Optimization of Network Robustness to Waves of Targeted and Random Attack We study the robustness of complex networks to multiple waves of simultaneous (i) targeted attacks in which the highest degree nodes are removed and (ii) random attacks (or failures) in which fractions $p_t$ and $p_r$ respectively of the nodes are removed until the network collapses. We find that the network design which optimizes network robustness has a bimodal degree distribution, with a fraction $r$ of the nodes having degree $k_2= (\kav - 1 +r)/r$ and the remainder of the nodes having degree $k_1=1$, where $\kav$ is the average degree of all the nodes. We find that the optimal value of $r$ is of the order of $p_t/p_r$ for $p_t/p_r\ll 1$."
"Altruistic Contents of Quantum Prisoner's DilemmaWe examine the classical contents of quantum games. It is shown that a quantum strategy can be interpreted as a classical strategies with effective density-dependent game matrices composed of transposed matrix elements. In particular, successful quantum strategies in dilemma games are interpreted in terms of a symmetrized game matrix that corresponds to an altruistic game plan."
"Network Models in Class C on Arbitrary GraphsWe consider network models of quantum localisation in which a particle with a two-component wave function propagates through the nodes and along the edges of an arbitrary directed graph, subject to a random SU(2) rotation on each edge it traverses. The propagation through each node is specified by an arbitrary but fixed S-matrix. Such networks model localisation problems in class C of the classification of Altland and Zirnbauer, and, on suitable graphs, they model the spin quantum Hall transition. We extend the analyses of Gruzberg, Ludwig and Read and of Beamond, Cardy and Chalker to show that, on an arbitrary graph, the mean density of states and the mean conductance may be calculated in terms of observables of a classical history-dependent random walk on the same graph. The transition weights for this process are explicitly related to the elements of the S-matrices. They are correctly normalised but, on graphs with nodes of degree greater than 4, not necessarily non-negative (and therefore interpretable as probabilities) unless a sufficient number of them happen to vanish. Our methods use a supersymmetric path integral formulation of the problem which is completely finite and rigorous."
"A Deterministic Super Small-World Network of IntegersWe propose a simple rule that deterministically generates networks with very large clustering coefficient and very small average distance. The average distances of these networks are so small that they can be approximated as a constant independent of the number of vertices. We refer to these networks as super small-world networks, since the average distances of these networks are even smaller than the average distances of the small-world networks, which depend logarithmical on the number of vertices. These networks' degree distributions cannot be described using the power-law distribution precisely. But the distributions share some common characteristics with those of scale-free networks, and the coarse-grained versions of the distributions are very similar to the power-law distribution."
Awaking and Sleeping a Complex NetworkA network with local dynamics of logistic type is considered. We implement a mean-field multiplicative coupling among first-neighbor nodes. When the coupling parameter is small the dynamics is dissipated and there is no activity: the network is 
"Complex networks created by aggregationWe study aggregation as a mechanism for the creation of complex networks. In this evolution process vertices merge together, which increases the number of highly connected hubs. We study a range of complex network architectures produced by the aggregation. Fat-tailed (in particular, scale-free) distributions of connections are obtained both for networks with a finite number of vertices and growing networks. We observe a strong variation of a network structure with growing density of connections and find the phase transition of the condensation of edges. Finally, we demonstrate the importance of structural correlations in these networks."
"Frequency synchronization in random oscillator network We study the frequency-synchronization of randomly coupled oscillators. By analyzing the continuum limit, we obtain the sufficient condition for the mean-field type synchronization. We especially find that the critical coupling constant $K$ becomes 0 in the random scale free network, $P(k)∝ k^-γ$, if $2 < γ ≤ 3$. Numerical simulations in finite networks are consistent with these analysis."
"Perturbation: the Catastrophe Causer in Scale-Free NetworksA new model about cascading occurrences caused by perturbation is established to search after the mechanism because of which catastrophes in networks occur. We investigate the avalanche dynamics of our model on 2-dimension Euclidean lattices and scale-free networks and find out the avalanche dynamic behaviors is very sensitive to the topological structure of networks. The experiments show that the catastrophes occur much more frequently in scale-free networks than in Euclidean lattices and the greatest catastrophe in scale-free networks is much more serious than that in Euclidean lattices. Further more, we have studied how to reduce the catastrophes' degree, and have schemed out an effective strategy, called targeted safeguard-strategy for scale-free networks."
"Democracy: Order out of ChaosWe construct a majority cellular automata based model to explain the power-law signatures in Indonesian general election results. The understanding of second-order phase transitions between two different conditions inspires the model. The democracy is assumed as critical point between the two extreme socio-political situations of totalitarian and anarchistic social system - where democracy can fall into the twos. The model is in multi-party candidates system run for equilibrium or equilibria, and used to fit and analyze the three of democratic national elections in Indonesia, 1955, 1999, and 2004."
"Stable resonances and signal propagation in a chaotic network of coupled unitsWe apply the linear response theory developed in \citeRuelle to analyze how a periodic signal of weak amplitude, superimposed upon a chaotic background, is transmitted in a network of non linearly interacting units. We numerically compute the complex susceptibility and show the existence of specific poles (stable resonances) corresponding to the response to perturbations transverse to the attractor. Contrary to the poles of correlation functions they depend on the pair emitting/receiving units. This dynamic differentiation, induced by non linearities, exhibits the different ability that units have to transmit a signal in this network."
"Resistance Noise Near to Electrical Breakdown: Steady State of Random Networks as a Function of the BiasA short review is presented of a recently developed computational approach which allows the study of the resistance noise over the full range of bias values, from the linear regime up to electrical breakdown. Resistance noise is described in terms of two competing processes in a random resistor network. The two processes are thermally activated and driven by an electrical bias. In the linear regime, a scaling relation has been found between the relative variance of resistance fluctuations and the average resistance. The value of the critical exponent is significantly higher than that associated with 1/f noise. In the nonlinear regime, occurring when the bias overcomes the threshold value, the relative variance of resistance fluctuations scales with the bias. Two regions can be identified in this regime: a moderate bias region and a pre-breakdown one. In the first region, the scaling exponent has been found independent of the values of the model parameters and of the bias conditions. A strong nonlinearity emerges in the pre-breakdown region which is also characterized by non-Gaussian noise. The results compare well with measurements of electrical breakdown in composites and with electromigration experiments in metallic lines."
"Neural Networks with Finite Width Action PotentialsThe significance of having finite widths of action potentials in integrate and fire neural networks is investigated. Models suggested by Hopfield and Herz [1] with zero action potential has been generalized to include pulse shapes of arbitrary widths and shapes. The convergence to limit cycle is examined both analytically and in simulation experiments. Hopfield's proof for nonleaking models has been extended nontrivially to the case of finite widths. It is pointed out that the concept of simultaneity in such networks maybe subject to bin widths in simulation experiments. The effects of varying the shape of the action potential and its width are examined. The roles of the magnitude of a leaking resistance connected to the neurons, a common external current and synaptic currents between neighbors are also examined and found to bear important consequences to the dynamical development of the network."
"Neural Networks with c-NOT Gated NodesWe try to design a quantum neural network with qubits instead of classical neurons with deterministic states, and also with quantum operators replacing teh classical action potentials. With our choice of gates interconnecting teh neural lattice, it appears that the state of the system behaves in ways reflecting both the strengths of coupling between neurons as well as initial conditions. We find that depending whether there is a threshold for emission from excited to ground state, the system shows either aperiodic oscillations or coherent ones with periodicity depending on the strength of coupling."
Semiclassical Neural NetworkWe have constructed a simple semiclassical model of neural network where neurons have quantum links with one another in a chosen way and affect one another in a fashion analogous to action potentials. We have examined the role of stochasticity introduced by the quantum potential and compare the system with the classical system of an integrate-and-fire model by Hopfield. Average periodicity and short term retentivity of input memory are noted.
"A note on ""Weighted Evolving Networks: Coupling Topology and Weight Dynamics""We discuss a newly proposed model by Barrat et al. (Phys. Rev. Lett. 92, 228701, 2004) for weighted evolving networks and suggest yet another model which can be viewed in the framework of worldwide airport network as ""busy airports get busier""."
"Objects That Make Objects: The Population Dynamics of Structural Complexity To analyze the evolutionary emergence of structural complexity in physical processes we introduce a general, but tractable, model of objects that interact to produce new objects. Since the objects--"
A distributed trust modelAn abstract is not available.
"Xenopus Cds1 is regulated by DNA-dependent protein kinase and ATR during the cell cycle checkpoint response to double-stranded DNA ends.The checkpoint kinase Cds1 (Chk2) plays a key role in cell cycle checkpoint responses with functions in cell cycle arrest, DNA repair, and induction of apoptosis. Proper regulation of Cds1 is essential for appropriate cellular responses to checkpoint-inducing insults. While the kinase ATM has been shown to be important in the regulation of human Cds1 (hCds1), here we report that the kinases ATR and DNA-dependent protein kinase (DNA-PK) play more significant roles in the regulation of Xenopus Cds1 (XCds1). Under normal cell cycle conditions, nonactivated XCds1 constitutively associates with a Xenopus ATR complex. The association of XCds1 with this complex does not require a functional forkhead activation domain but does require a putative SH3 binding region that is found in XCds1. In response to double-stranded DNA ends, the amino terminus of XCds1 is rapidly phosphorylated in a sequential pattern. First DNA-PK phosphorylates serine 39, a site not previously recognized as important in Cds1 regulation. Xenopus ATM, ATR, and/or DNA-PK then phosphorylate three consensus serine/glutamine sites. Together, these phosphorylations have the dual function of inducing dissociation from the ATR complex and independently promoting the full activation of XCds1. Thus, the checkpoint-mediated activation of XCds1 requires phosphorylation by multiple phosphoinositide 3-kinase-related kinases, protein-protein dissociation, and autophosphorylation."
"Evolution in complex systemsWhat features characterise complex system dynamics? Power laws and scale invariance of fluctuations are often taken as the hallmarks of complexity, drawing on analogies with equilibrium critical phenomena[1-3]. Here we argue that slow, directed dynamics, during which the system's properties change significantly, is fundamental. The underlying dynamics is related to a slow, decelerating but spasmodic release of an intrinsic strain or tension. Time series of a number of appropriate observables can be analysed to confirm this effect. The strain arises from local frustration. As the strain is released through ""quakes"", some system variable undergoes record statistics with accompanying log-Poisson statistics for the quake event times[4]. We demonstrate these phenomena via two very different systems: a model of magnetic relaxation in type II superconductors and the Tangled Nature model of evolutionary ecology, and show how quantitative indications of ageing can be found."
"Evidence for the Independence of Waged and Unwaged Income, Evidence for Boltzmann Distributions in Waged Income, and the Outlines of a Coherent Theory of Income DistributionTwo sets of high quality income data are analysed in detail, one set from the UK, one from the USA. It is firstly demonstrated that both a log-normal distribution and a Boltzmann distribution can give very accurate fits to both these data sets. The absence of a power tail in the US data set is then discussed. Taken in conjunction with detailed evidence from the UK and Japanese income data, a strong case is made for the mathematically separate treatment of waged and unwaged income. The authors present a case for preferring the use of the Boltzmann distribution over the log-normal function, this leads to a brief review of the work of a number of researchers, which shows that a coherent theory for the distribution of all income can be postulated."
"Social Anti-Percolation, Resistance and Negative Word-of-MouthA known result from marketing research is that many products fail to meet their expected market share. A possible explanation for this phenomenon is the inherent resistance of the social network, that is greatly increased if effects of negative word of mouth (NWOM) are taken into account. Here we suggest an extension for the Social Percolation framework that incorporates NWOM. The proposed models are subjected to computer simulations, and the results show that the percolation threshold increases considerably. This new variant of percolation models presents physical properties that are different than the standard percolation model, and possibly even a first-order phase transition. The model is also discussed in the marketing context."
"Simulating the conflict between reputation and profitability for online rating portalsWe simulate the process of possible interactions between a set of competitive services and a set of portals that provide online rating for these services. We argue that to have a profitable business, these portals are forced to have subscribed services that are rated by the portals. To satisfy the subscribing services, we make the assumption that the portals improve the rating of a given service by one unit per transaction that involves payment. In this study we follow the ""what-if"" methodology, analysing strategies that a service may choose from to select the best portal for it to subscribe to, and strategies for a portal to accept the subscription such that its reputation loss, in terms of the integrity of its ratings, is minimised. We observe that the behaviour of the simulated agents in accordance to our model is quite natural from the real-would perspective. One conclusion from the simulations is that under reasonable conditions, if most of the services and rating portals in a given industry do not accept a subscription policy similar to the one indicated above, they will lose, respectively, their ratings and reputations, and, moreover the rating portals will have problems in making a profit. Our prediction is that the modern portal-rating based economy sector will eventually evolve into a subscription process similar to the one we suggest in this study, as an alternative to a business model based purely on advertising."
"Synchronization by Nonlinear Frequency PullingWe analyze a model for the synchronization of nonlinear oscillators due to reactive coupling and nonlinear frequency pulling motivated by the physics of arrays of nanoscale oscillators. We study the model for the mean field case of all-to-all coupling, deriving results for the onset of synchronization as the coupling or nonlinearity increase, and the fully locked state when all the oscillators evolve with the same frequency."
"Performance Variability and Project DynamicsWe present a dynamical theory of complex cooperative projects such as large engineering design or software development efforts, comprised of concurrent and interrelated tasks. The model accounts for temporal fluctuations both in task performance and in the interactions between related tasks. We show that as the system size increases, so does the average completion time. Also, for fixed system size, the dynamics of individual project realizations can exhibit large deviations from the average when fluctuations increase past a threshold, causing long delays in completion times. This effect is in agreement with empirical observations, and can be mitigated by arranging projects in a hierarchical or modular structure."
"Stock markets are not what we think they are: the key roles of cross-ownership and corporate treasury stockWe describe and document three mechanisms by which corporations can influence or even control stock prices. (i) Parent and holding companies wield control over other publicly traded companies. (ii) Through clever management of treasury stock based on buyback programs and stock issuance, stock price fluctuations can be amplified or curbed. (iii) Finally, history shows a close interdependance between the level of stock prices on the one hand and merger and acquisition activity on the other hand. This perspective in which Boards of Directors of major companies shepherd the market offers a natural interpretation of the so-called ""herd behavior"" observed in stock markets. The traditional view holds that by driving profit expectations, corporations have an indirect role in shaping the market. In this paper, we suggest that over the last decades they became more and more the direct moving force of stock markets."
"Hollywood blockbusters and long-tailed distributions: An empirical study of the popularity of moviesNumerical data for all movies released in theaters in the USA during the period 1997-2003 are examined for the distribution of their popularity in terms of (i) the number of weeks they spent in the Top 60 according to the weekend earnings, and (ii) the box-office gross during the opening week, as well as, the total duration for which they were shown in theaters. These distributions show long tails where the most popular movies are located. Like the study of Redner [S. Redner, Eur. Phys. J. B 4, 131 (1998)] on the distribution of citations to individual papers, our results are consistent with a power-law dependence of the rank distribution of gross revenues for the most popular movies with a exponent close to -1/2."
"Strategic updating of threshold response in an agent-based market modelI propose an agent-based model of a single-asset financial market described in terms of few parameters. I show that the effect of agents adjusting their threshold response to new information is to generate a market price which fluctuates endlessly and a volatility which displays a mean-reverting behavior. This agent-based model generically leads to an absence of autocorrelation in returns, excess volatility, volatility clustering, and endogeneous bursts of activity that is not attributable to external noise. This study illustrates a possible link between the famous El Farol bar problem and financial markets."
"On supercorrelated systems and phase space entrainmentIt is demonstrated that power-laws which are modified by logarithmic corrections arise in supercorrelated systems. Their characteristic feature is the energy attributed to a state (or value of a general cost function) which depends nonlinearly on the phase space distribution of the constituents. A onedimensional dissipative deterministic model is introduced which is attracted to a supercorrelated state (phase space entrainment). Extensions of this model may have applications in the study of transport and equilibration phenomena, particularly for supply and information networks."
"Network Structures from Selection PrinciplesWe present an analysis of the topologies of a class of networks which are optimal in terms of the requirements of having as short a route as possible between any two nodes while yet keeping the congestion in the network as low as possible. Strikingly, we find a variety of distinct topologies and novel phase transitions between them on varying the number of links per node. Our results suggest that the emergence of the topologies observed in nature may arise both from growth mechanisms and the interplay of dynamical mechanisms with a selection process."
"Competition and adaptation in an Internet evolution modelWe model the evolution of the Internet at the Autonomous System level as a process of competition for users and adaptation of bandwidth capability. We find the exponent of the degree distribution as a simple function of the growth rates of the number of autonomous systems and the total number of connections in the Internet, both empirically measurable quantities. This fact place our model apart from others in which this exponent depends on parameters that need to be adjusted in a model dependent way. Our approach also accounts for a high level of clustering as well as degree-degree correlations, both with the same hierarchical structure present in the real Internet. Further, it also highlights the interplay between bandwidth, connectivity and traffic of the network."
"Statistics of lines of natural images and implications for visual detectionAs borders between different regions, lines are an important element of natural images. Already at the level of the mammalian primary visual cortex (V1), neurons respond best to lines of a given orientation. We reduce a set of images to linear segments and analyze their statistical properties. In particular, appropriately defined Fourier spectra show more power in their transverse component than in the longitudinal one. We then characterize filters that are best suited for extracting information from such images, and find some qualitative consistency with neural connections in V1. We also demonstrate that such filters are efficient in reconstructing missing lines in an image."
"Entangled Quantum NetworksWe present some results from simulation of a network of nodes connected by c-NOT gates with nearest neighbors. Though initially we begin with pure states of varying boundary conditions, the updating with time quickly involves a complicated entanglement involving all or most nodes. As a normal c-NOT gate, though unitary for a single pair of nodes, seems to be not so when used in a network in a naive way, we use a manifestly unitary form of the transition matrix with c?-NOT gates, which invert the phase as well as flipping the qubit. This leads to complete entanglement of the net, but with variable coefficients for the different components of the superposition. It is interesting to note that by a simple logical back projection the original input state can be recovered in most cases. We also prove that it is not possible for a sequence of unitary operators working on a net to make it move from an aperiodic regime to a periodic one, unlike some classical cases where phase-locking happens in course of evolution. However, we show that it is possible to introduce by hand periodic orbits to sets of initial states, which may be useful in forming dynamic pattern recognition systems."
"Bounded confidence model on a still growing scale-free networkA Bounded Confidence (BC) model of socio-physics, in which the agents have continuous opinions and can influence each other only if the distance between their opinions is below a threshold, is simulated on a still growing scale-free network considering several different strategies: for each new node (or vertex), that is added to the network all individuals of the network have their opinions updated following a Deffuant model recipe. The results obtained are compared with the original model, with numerical simulations on different graph structures and also when it is considered on the usual fixed BA network. In particular, the comparison with the latter leads us to conclude that it does not matter much whether the network is still growing or is fixed during the opinion dynamics."
"Self-organization of structures and networks from merging and small-scale fluctuationsWe discuss merging-and-creation as a self-organizing process for scale-free topologies in networks. Three power-law classes characterized by the power-law exponents 3/2, 2 and 5/2 are identified and the process is generalized to networks. In the network context the merging can be viewed as a consequence of optimization related to more efficient signaling."
Average path length in random networks Analytic solution for the average path length in a large class of random graphs is found. We apply the approach to classical random graphs of Erdös and Rényi (ER) and to scale-free networks of Barabási and Albert (BA). In both cases our results confirm previous observations: small world behavior in classical random graphs $l_ER ∼ \ln N$ and ultra small world effect characterizing scale-free BA networks $l_BA ∼ \ln N/\ln\ln N$. In the case of scale-free random graphs with power law degree distributions we observed the saturation of the average path length in the limit of $N\to∞$ for systems with the scaling exponent $2< α <3$ and the small-world behaviour for systems with $α>3$.
"Average path length in uncorrelated random networks with hidden variables Analytic solution for the average path length in a large class of uncorrelated random networks with hidden variables is found. We apply the approach to classical random graphs of Erdos and Renyi (ER), evolving networks introduced by Barabasi and Albert (BA) as well as random networks with asymptotic scale-free connectivity distributions characterized by an arbitrary scaling exponent $α>2$. Our result for $2<α<3$ shows that structural properties of asymptotic scale-free networks including numerous examples of real-world systems are even more intriguing then ultra-small world behavior noticed in pure scale-free structures and for large system sizes $N\to∞$ there is a saturation effect for the average path length."
"An associative network with spatially organized connectivityWe investigate the properties of an autoassociative network of threshold-linear units whose synaptic connectivity is spatially structured and asymmetric. Since the methods of equilibrium statistical mechanics cannot be applied to such a network due to the lack of a Hamiltonian, we approach the problem through a signal-to-noise analysis, that we adapt to spatially organized networks. The conditions are analyzed for the appearance of stable, spatially non-uniform profiles of activity with large overlaps with one of the stored patterns. It is also shown, with simulations and analytic results, that the storage capacity does not decrease much when the connectivity of the network becomes short range. In addition, the method used here enables us to calculate exactly the storage capacity of a randomly connected network with arbitrary degree of dilution."
"Oscillating kinks in forced oscillatory media: A new type of instabilityA new type of instability resulting in oscillatory propagating kinks is presented. It is observed in periodically forced oscillatory media at 1:1 resonance, where phase kinks have close similarities to pulses in excitable media. Considering the periodically forced complex Ginzburg-Landau equation, examples for transitions involving oscillating kinks between different dynamical regimes are described. The oscillatory instability is discussed within the framework of a bifurcation analysis of the kink profiles"
Self-organized pulses of dynamic systems with three-dimensional phase spaceThe possibility of production of pulses with scale-invariant properties at presence of fluctuations of parameters of self-oscillatory system with three-dimensional phase space is shown. The system of equations of inertial nonlinearity oscillator is numerically investigated. The formulas of quantitative characteristics of the form and self-similar values of informational entropy of complex pulses allowing to extract self-organized signals are obtained.
"Existence and Stability of Standing Pulses in Neural Networks : I ExistenceWe consider the existence of standing pulse solutions of a neural network integro-differential equation. These pulses are bistable with the zero state and may be an analogue for short term memory in the brain. The network consists of a single-layer of neurons synaptically connected by lateral inhibition. Our work extends the classic Amari result by considering a non-saturating gain function. We consider a specific connectivity function where the existence conditions for single-pulses can be reduced to the solution of an algebraic system. In addition to the two localized pulse solutions found by Amari, we find that three or more pulses can coexist. We also show the existence of nonconvex “dimpled” pulses and double pulses. We map out the pulse shapes and maximum firing rates for different connection weights and gain functions."
"Existence and Stability of Standing Pulses in Neural Networks: II StabilityWe analyze the stability of standing pulse solutions of a neural network integro-differential equation. The network consists of a coarse-grained layer of neurons synaptically connected by lateral inhibition with a non-saturating nonlinear gain function. When two standing single-pulse solutions coexist, the small pulse is unstable, and the large pulse is stable. The large single-pulse is bistable with the “all-off” state. This bistable localized activity may have strong implications for the mechanism underlying working memory. We show that dimple pulses have similar stability properties to large pulses but double pulses are unstable."
"Indirect Allee Effect, Bistability and Chaotic Oscillations in a Predator-Prey Discrete Model of Logistic Type A cubic discrete coupled logistic equation is proposed to model the predator-prey problem. The coupling depends on the population size of both species and on a positive constant $λ$, which could depend on the prey reproduction rate and on the predator hunting strategy. Different dynamical regimes are obtained when $λ$ is modified. For small $λ$, the species become extinct. For a bigger $λ$, the preys survive but the predators extinguish. Only when the prey population reaches a critical value then predators can coexist with preys. For increasing $λ$, a bistable regime appears where the populations apart of being stabilized in fixed quantities can present periodic, quasiperiodic and chaotic oscillations. Finally, bistability is lost and the system settles down in a steady state, or, for the biggest permitted $λ$, in an invariant curve. We also present the basins for the different regimes. The use of the critical curves lets us determine the influence of the zones with different number of first rank preimages in the bifurcation mechanisms of those basins."
"Genetic analysis of rapid tolerance to ethanol's incoordinating effects in mice: inbred strains and artificial selection.Ethanol tolerance, a decrease in drug responsiveness with repeated administrations, is an important diagnostic criterion for alcoholism. Rapid tolerance develops within 8-24 hours of an initial ethanol exposure and shares many similarities with chronic tolerance. The genetic contribution to rapid tolerance to ethanol-induced ataxia was estimated using a panel of inbred strains of mice. Strains differed significantly in the degree of rapid tolerance development, which had a broad-sense heritability estimate of 0.11. Artificial selection was carried out to develop lines of mice that would show High (HRT) and Low (LRT) levels of Rapid Tolerance. Starting with HS/Npt mice, derived from a systematic cross of eight inbred strains, a significant response to selection was seen in replicate 1 by the third selection generation. No difference was found in replicate 2. Heritability estimates after the fourth generation were 0.25 for HRT-1 mice and 0.06 for LRT-1 mice. HRT-1 and LRT-1 mice also differed significantly in chronic tolerance development to four doses of ethanol. These studies provide evidence for a genetic contribution to rapid tolerance and support a genetic link between rapid and chronic tolerance to ethanol's ataxic effects."
Discrete Baker Transformation and Cellular Automata In this paper we propose a rule-independent description of applications of cellular automata rules for one-dimensional additive cellular automata on cylinders of finite sizes. This description is shown to be a useful tool for for answering questions about automata's state transition diagrams (STD). The approach is based on two transformations: one (called 
"On the synchronization of networks with prescribed degree distributionsWe show that the degree distributions of graphs do not suffice to characterize the synchronization of systems evolving on them. We prove that, for any given degree sequence satisfying certain conditions, a connected graph having that degree sequence exists for which the first nontrivial eigenvalue of the graph Laplacian is arbitrarily close to zero. Consequently, dynamical systems defined on such graphs have poor synchronization properties. The result holds under quite mild assumptions, and shows that there exists classes of random, scale-free, regular, small-world, and other common network architectures which impede synchronization. The proof is based on a construction that also serves as an algorithm for building non-synchronizing networks having a prescribed degree distribution."
"Social Structure and Opinion FormationWe present a dynamical theory of opinion formation that takes explicitly into account the structure of the social network in which in- dividuals are embedded. The theory predicts the evolution of a set of opinions through the social network and establishes the existence of a martingale property, i.e. that the expected weighted fraction of the population that holds a given opinion is constant in time. Most importantly, this weighted fraction is not either zero or one, but corresponds to a non-trivial distribution of opinions in the long time limit. This co-existence of opinions within a social network is in agreement with the often observed locality effect, in which an opinion or a fad is localized to given groups without infecting the whole society. We verified these predictions, as well as those concerning the fragility of opinions and the importance of highly connected individuals in opinion formation, by performing computer experiments on a number of social networks."
"Features of the Extension of a Statistical Measure of Complexity to Continuous SystemsWe discuss some aspects of the extension to continuous systems of a statistical measure of complexity introduced by Lopez-Ruiz, Mancini and Calbet (LMC) [Phys. Lett. A 209 (1995) 321]. In general, the extension of a magnitude from the discrete to the continuous case is not a trivial process and requires some choice. In the present study, several possibilities appear available. One of them is examined in detail. Some interesting properties desirable for any magnitude of complexity are discovered on this particular extension."
"Circuits in random graphs: from local trees to global loopsWe compute the number of circuits and of loops with multiple crossings in random regular graphs. We discuss the importance of this issue for the validity of the cavity approach. On the one hand we obtain analytical results for the infinite volume limit in agreement with existing exact results. On the other hand we implement a counting algorithm, enumerate circuits at finite N , and draw some general conclusions about the finite- N behaviour of the number of circuits."
"Number of spanning clusters at the high-dimensional percolation thresholdsA scaling theory is used to derive the dependence of the average number <k> of spanning clusters at threshold on the lattice size L. This number should become independent of L for dimensions d<6, and vary as log L at d=6. The predictions for d>6 depend on the boundary conditions, and the results there may vary between L^d-6 and L^0. While simulations in six dimensions are consistent with this prediction (after including corrections of order loglog L), in five dimensions the average number of spanning clusters still increases as log L even up to L = 201. However, the histogram P(k) of the spanning cluster multiplicity does scale as a function of kX(L), with X(L)=1+const/L, indicating that for sufficiently large L the average <k> will approach a finite value: a fit of the 5D multiplicity data with a constant plus a simple linear correction to scaling reproduces the data very well. Numerical simulations for d>6 and for d=4 are also presented."
"The Chromatic Number of Random Regular GraphsGiven any integer d >= 3, let k be the smallest integer such that d < 2k log k. We prove that with high probability the chromatic number of a random d-regular graph is k, k+1, or k+2, and that if (2k-1) \log k < d < 2k \log k then the chromatic number is either k+1 or k+2."
"Analytical Studies on a Modified Nagel-Schreckenberg Model with the Fukui-Ishibashi Acceleration RuleWe propose and study a one-dimensional traffic flow cellular automaton model of high-speed vehicles with the Fukui-Ishibashi-type (FI) acceleration rule for all cars, and the Nagel-Schreckenberg-type (NS) stochastic delay mechanism. By using the car-oriented mean field theory, we obtain analytically the fundamental diagrams of the average speed and vehicle flux depending on the vehicle density and stochastic delay probability. Our theoretical results, which may contribute to the exact analytical theory of the NS model, are in excellent agreement with numerical simulations."
"Distribution of Korean Family NamesThe family name distribution in Korea is investigated in comparison with previous studies in other countries. In Korea, both the family name and its birthplace, where the ancestor of the family originated, are commonly used to distinguish one family name from the others. The family name distributions with and without the information of the regional origins are analyzed by using different data sets of various sizes, and compared with previous studies performed in other countries. The growth rate of the family is empirically obtained. Contrary to commonly used assumptions, the growth rate is found to be higher for the smaller family."
"Long-lived states of oscillator chain with dynamical trapsA simple model of oscillator chain with dynamical traps and additive white noise is considered. Its dynamics was studied numerically. As demonstrated, when the trap effect is pronounced nonequilibrium phase transitions of a new type arise. Locally they manifest themselves via distortion of the particle arrangement symmetry. Depending on the system parameters the particle arrangement is characterized by the corresponding distributions taking either a bimodal form, or twoscale one, or unimodal onescale form which, however, deviates substantially from the Gaussian distribution. The individual particle velocities exhibit also a number of anomalies, in particular, their distribution can be extremely wide or take a quasi-cusp form. A large number of different cooperative structures and superstructures made of these formations are found in the visualized time patterns. Their evolution is, in some sense, independent of the individual particle dynamics, enabling us to regard them as dynamical phases."
"Unattainability of a purely topological criterion for the existence of a phase transition for non-confining potentialsThe relation between thermodynamic phase transitions in classical systems and topology changes in their configuration space is discussed for a one-dimensional, analytically tractable solid-on-solid model. The topology of a certain family of submanifolds of configuration space is investigated, corroborating the hypothesis that, in general, a change of the topology within this family is a necessary condition in order to observe a phase transition. Considering two slightly differing versions of this solid-on-solid model, one showing a phase transition in the thermodynamic limit, the other not, we find that the difference in the “quality” or “strength” of this topology change appears to be insignificant. This example indicates the unattainability of a condition of exclusively topological nature which is sufficient as to guarantee the occurrence of a phase transition in systems with non-confining potentials."
"Pricing Exotic Options in a Path Integral ApproachIn the framework of Black-Scholes-Merton model of financial derivatives, a path integral approach to option pricing is presented. A general formula to price path dependent options on multidimensional and correlated underlying asset is obtained and implemented by means of various flexible and efficient algorithms. As example, we detail the cases of Asian, Barrier Knock Out, Reverse Cliquet and Basket call options, evaluating prices and Greeks. The numerical results are compared with those obtained with other procedures used in quantitative finance and are found to be in good agreement. In particular, when pricing At the money and Out of the money options, path integral exhibits very competitive performances."
"Why Mapping the Internet is HardDespite great effort spent measuring topological features of large networks like the Internet, it was recently argued that sampling based on taking paths through the network (e.g., traceroutes) introduces a fundamental bias in the observed degree distribution. We examine this bias analytically and experimentally. For classic random graphs with mean degree c, we show analytically that traceroute sampling gives an observed degree distribution P(k) ~ 1/k for k < c, even though the underlying degree distribution is Poisson. For graphs whose degree distributions have power-law tails P(k) ~ k^-alpha, the accuracy of traceroute sampling is highly sensitive to the population of low-degree vertices. In particular, when the graph has a large excess (i.e., many more edges than vertices), traceroute sampling can significantly misestimate alpha."
"The Sznajd Consensus Model with Continuous OpinionsIn the consensus model of Sznajd, opinions are integers and a randomly chosen pair of neighbouring agents with the same opinion forces all their neighbours to share that opinion. We propose a simple extension of the model to continuous opinions, based on the criterion of bounded confidence which is at the basis of other popular consensus models. Here the opinion s is a real number between 0 and 1, and a parameter ε is introduced such that two agents are compatible if their opinions differ from each other by less than ε. If two neighbouring agents are compatible, they take the mean s_m of their opinions and try to impose this value to their neighbours. We find that if all neighbours take the average opinion s_m the system reaches complete consensus for any value of the confidence bound ε. We propose as well a weaker prescription for the dynamics and discuss the corresponding results."
"Bulk and Boundary Critical Behavior at Lifshitz Points Lifshitz points are multicritical points at which a disordered phase, a homogeneous ordered phase, and a modulated ordered phase meet. Their bulk universality classes are described by natural generalizations of the standard $φ^4$ model. Analyzing these models systematically via modern field-theoretic renormalization group methods has been a long-standing challenge ever since their introduction in the middle of the 1970s. We survey the recent progress made in this direction, discussing results obtained via dimensionality expansions, how they compare with Monte Carlo results, and open problems. These advances opened the way towards systematic studies of boundary critical behavior at $m$-axial Lifshitz points. The possible boundary critical behavior depends on whether the surface plane is perpendicular to one of the $m$ modulation axes or parallel to all of them. We show that the semi-infinite field theories representing the corresponding surface universality classes in these two cases of perpendicular and parallel surface orientation differ crucially in their Hamiltonian's boundary terms and the implied boundary conditions, and explain recent results along with our current understanding of this matter."
"Application of Artificial Neural Network in Jitter Analysis of Dispersion-Managed Communication SystemArtificial Neural Network (ANN) is used as numerical methode in solving modified Nonlinear Schroedinger (NLS) equation with Dispersion Managed System (DMS) for jitter analysis. We take the optical axis z and the time t as input, and then some relevant values such as the change of position and the center frequency of the pulse, and further the mean square time of incoming pulse which are needed for jitter analysis. It shows that ANN yields numerical solutions which are adaptive with respect to the numerical errors and also verifies the previous numerical results using conventional numerical method. Our result indicates that DMS can minimize the timing jitter induced by some amplifiers."
"Increasing Returns to Scale, Dynamics of Industrial Structure and Size Distribution of FirmsA model is presented of the market dynamics to emphasis the effects of increasing returns to scale, including the description of the born and death of the adaptive producers. The evolution of market structure and its behavior with the technological shocks are discussed. Its dynamics is in good agreement with some empirical stylized facts of industrial evolution. Together with the diversities of demand and adaptive growth strategies of firms, the generalized model has reproduced the power-law distribution of firm size. Three factors mainly determine the competitive dynamics and the skewed size distributions of firms: 1. Self-reinforcing mechanism; 2. Adaptive firm grows strategies; 3. Demand diversities or widespread heterogeneity in the technological capabilities of different firms. Key words: Econophysics, Increasing returns, Industry dynamics, Size distribution of firms"
"Neural cryptography with feedbackNeural cryptography is based on a competition between attractive and repulsive stochastic forces. A feedback mechanism is added to neural cryptography which increases the repulsive forces. Using numerical simulations and an analytic approach, the probability of a successful attack is calculated for different model parameters. Scaling laws are derived which show that feedback improves the security of the system. In addition, a network with feedback generates a pseudorandom bit sequence which can be used to encrypt and decrypt a secret message."
"An $ε$-expansion for Small-World Networks I construct a well-defined expansion in $ε=2-d$ for diffusion processes on small-world networks. The technique permits one to calculate the average over disorder of moments of the Green's function, and is used to calculate the average Green's function and fluctuations to first non-leading order in $ε$, giving results which agree with numerics. This technique is also applicable to other problems of diffusion in random media."
Phase transitions for rock-scissors-paper game on different networksMonte Carlo simulations and dynamical mean-field approximations are performed to study the phase transitions in rock-scissors-paper game on different host networks. These graphs are originated from lattices by introducing quenched and annealed randomness simultaneously. In the resulting phase diagrams three different stationary states are identified for all structures. The comparison of results on different networks suggests that the value of clustering coefficient plays an irrelevant role in the emergence of a global oscillating phase. The critical behavior of phase transitions seems to be universal and can be described by the same exponents.
"Return times of random walk on generalized random graphsRandom walks are used for modeling various dynamics in, for example, physical, biological, and social contexts. Furthermore, their characteristics provide us with useful information on the phase transition and critical phenomena of even broader classes of related stochastic models. Abundant results are obtained for random walk on simple graphs such as the regular lattices and the Cayley trees. However, random walks and related processes on more complex networks, which are often more relevant in the real world, are still open issues, possibly yielding different characteristics. In this paper, we investigate the return times of random walks on random graphs with arbitrary vertex degree distributions. We analytically derive the distributions of the return times. The results are applied to some types of networks and compared with numerical data."
"Entrainment of randomly coupled oscillator networks by a pacemakerEntrainment by a pacemaker, representing an element with a higher frequency, is numerically investigated for several classes of random networks which consist of identical phase oscillators. We find that the entrainment frequency window of a network decreases exponentially with its depth, defined as the mean forward distance of the elements from the pacemaker. Effectively, only shallow networks can thus exhibit frequency-locking to the pacemaker. The exponential dependence is also derived analytically as an approximation for large random asymmetric networks."
"Transmission of severe acute respiratory syndrome in dynamical small-world networksThe outbreak of severe acute respiratory syndrome (SARS) is still threatening the world because of a possible resurgence. In the current situation that effective medical treatments such as antiviral drugs are not discovered yet, dynamical features of the epidemics should be clarified for establishing strategies for tracing, quarantine, isolation, and regulating social behavior of the public at appropriate costs. Here we propose a network model for SARS epidemics and discuss why superspreaders emerged and why SARS spread especially in hospitals, which were key factors of the recent outbreak. We suggest that superspreaders are biologically contagious patients, and they may amplify the spreads by going to potentially contagious places such as hospitals. To avoid mass transmission in hospitals, it may be a good measure to treat suspected cases without hospitalizing them. Finally, we indicate that SARS probably propagates in small-world networks associated with human contacts and that the biological nature of individuals and social group properties are factors more important than the heterogeneous rates of social contacts among individuals. This is in marked contrast with epidemics of sexually transmitted diseases or computer viruses to which scale-free network models often apply."
"Diffusion-annihilation processes in complex networks We present a detailed analytical study of the $A+A\to∅$ diffusion-annihilation process in complex networks. By means of microscopic arguments, we derive a set of rate equations for the density of $A$ particles in vertices of a given degree, valid for any generic degree distribution, and which we solve for uncorrelated networks. For homogeneous networks (with bounded fluctuations), we recover the standard mean-field solution, i.e. a particle density decreasing as the inverse of time. For heterogeneous (scale-free networks) in the infinite network size limit, we obtain instead a density decreasing as a power-law, with an exponent depending on the degree distribution. We also analyze the role of finite size effects, showing that any finite scale-free network leads to the mean-field behavior, with a prefactor depending on the network size. We check our analytical predictions with extensive numerical simulations on homogeneous networks with Poisson degree distribution and scale-free networks with different degree exponents."
"Neural Networks Processing Mean Values of Random VariablesWe introduce a class of neural networks derived from probabilistic models in the form of Bayesian belief networks. By imposing additional assumptions about the nature of the probabilistic models represented in the belief networks, we derive neural networks with standard dynamics that require no training to determine the synaptic weights, that can pool multiple sources of evidence, and that deal cleanly and consistently with inconsistent or contradictory evidence. The presented neural networks capture many properties of Bayesian belief networks, providing distributed versions of probabilistic models."
"Do extremists impose the structure of social networks?The structure and the properties of complex networks essentially depend on the way how nodes get connected to each other. We assume here that each node has a feature which attracts the others. We model the situation by assigning two numbers to each node, ω and α, where ω indicates some property of the node and α the affinity towards that property. A node A is more likely to establish a connection with a node B if B has a high value of ω and A has a high value of α. Simple computer simulations show that networks built according to this principle have a degree distribution with a power law tail, whose exponent is determined only by the nodes with the largest value of the affinity α (the ""extremists""). This means that the extremists lead the formation process of the network and manage to shape the final topology of the system. The latter phenomenon may have implications in the study of social networks and in epidemiology."
"Scale-free nonlinear conservative cascades and their stationary spectraWe show that a variety of complex processes can be viewed from the unified standpoint of scale-free nonlinear conservative cascades. Examples include certain turbulence models, percolation, cluster coagulation (aggregation) and fragmentation, `coarse-grained' forest fire model of self-organized criticality, and scale-free network growth. We classify such cascades by the values of three indices, and show how power-law steady spectra may arise. The power-law exponent is proven to depend only on the values of the three indices by a simple algebraic formula."
"A study on a self-organized criticality in a dynamical many-body systemA novel mechanism for the generation of self-organized criticality (SOC) is discussed in terms of the coupled-vibration model where the total system is forced under the uniform expansion of the Hubble type. This system shows a robust SOC behavior while the maximum size of the fluctuation, number of correlated particles in it and the temporal size of the system evolve as a function of time."
"Adaptive Boolean Networks and Minority Games with Time--Dependent Capacities In this paper we consider a network of boolean agents that compete for a limited resource. The agents play the so called Generalized Minority Game where the capacity level is allowed to vary externally. We study the properties of such a system for different values of the mean connectivity $K$ of the network, and show that the system with K=2 shows a high degree of coordination for relatively large variations of the capacity level."
"Evolutionary changes in heat-inducible gene expression in lines of Escherichia coli adapted to high temperature.The involvement of heat-inducible genes, including the heat-shock genes, in the acute response to temperature stress is well established. However, their importance in genetic adaptation to long-term temperature stress is less clear. Here we use high-density arrays to examine changes in expression for 35 heat-inducible genes in three independent lines of Escherichia coli that evolved at high temperature (41.5 degrees C) for 2,000 generations. These lines exhibited significant changes in heat-inducible gene expression relative to their ancestor, including parallel changes in fkpA, gapA, and hslT. As a group, the heat-inducible genes were significantly more likely than noncandidate genes to have evolved changes in expression. Genes encoding molecular chaperones and ATP-dependent proteases, key components of the cytoplasmic stress response, exhibit relatively little expression change; whereas genes with periplasmic functions exhibit significant expression changes suggesting a key role for the extracytoplasmic stress response in the adaptation to high temperature. Following acclimation at 41.5 degrees C, two of the three lines exhibited significantly improved survival at 50 degrees C, indicating changes in inducible thermotolerance. Thus evolution at high temperature led to significant changes at the molecular level in heat-inducible gene expression and at the organismal level in inducible thermotolerance and fitness."
"Genetic architecture of thermal adaptation in Escherichia coli.Elucidating the genetic basis of adaptation on a genomewide scale has evaded biologists, but complete genome sequences and DNA high-density array technology make genomewide surveys more tractable. Six lines of Escherichia coli adapted for 2,000 generations to a stressful high temperature of 41.5 degrees C were examined on a genomewide scale for duplication/deletion events by using DNA high-density arrays. A total of five duplication and deletion events were detected. These five events occurred in three of the six lines, whereas the remaining three lines contained no detectable events. Three of the duplications were at 2.85 Mb of the E. coli chromosome, providing evidence for the replicability of the adaptation to high temperature. Four candidate genes previously shown to play roles in stress and starvation survival were identified in the region of common duplication. Expression of the two candidate genes examined is elevated over expression levels in the ancestral lines or the lines without the duplication. In the two cases where the duplication at 2.85 Mb has been further characterized, the timing of the genome reorganization is coincident with significant increases in relative fitness. In both of these cases, the model for the origin of the duplication is a complex recombination event involving insertion sequences and repeat sequences. These results provide additional evidence for the idea that gene duplication plays an integral role in adaptation, specifically as a means for gene amplification."
"ATR and ATM-Dependent Movement of BLM Helicase during Replication Stress Ensures Optimal ATM Activation and 53BP1 Focus Formation.The BLM helicase, a deficiency in which markedly increases cancer incidence in humans, is required for optimal repair during DNA replication. We show that BLM rapidly moves from PML nuclear bodies to damaged replication forks, returning to PML bodies several hours later, owing to activities of the DNA damage response kinases ATR and ATM, respectively. Immunofluorescence and cellular fractionation demonstrate that BLM partitions to different sub-cellular compartments after replication stress. Unexpectedly, fibroblasts lacking BLM were deficient in phospho-ATM (S-1981) and 53-binding protein-1 (53BP1), and these proteins failed to form foci following replication stress. Expression of a dominant p53 mutant or helicase-deficient BLM restored replication stress-induced 53BP1 foci, but only mutant p53 restored optimal ATM activation. Thus, optimal repair of damaged replication fork lesions likely requires both ATR and ATM, BLM recruits 53BP1 to these lesions independent of its helicase activity, and optimal activation of ATM requires both p53 and BLM helicase activities."
Hypertext for the aged: effects of text topologies
"Conservation and Evolution of Cis-Regulatory Systems in Ascomycete FungiRelatively little is known about the mechanisms through which gene expression regulation evolves. To investigate this, we systematically explored the conservation of regulatory networks in fungi by examining the cis-regulatory elements that govern the expression of coregulated genes. We first identified groups of coregulated Saccharomyces cerevisiae genes enriched for genes with known upstream or downstream cis-regulatory sequences. Reasoning that many of these gene groups are coregulated in related species as well, we performed similar analyses on orthologs of coregulated S. cerevisiae genes in 13 other ascomycete species. We find that many species-specific gene groups are enriched for the same flanking regulatory sequences as those found in the orthologous gene groups from S. cerevisiae, indicating that those regulatory systems have been conserved in multiple ascomycete species. In addition to these clear cases of regulatory conservation, we find examples of cis-element evolution that suggest multiple modes of regulatory diversification, including alterations in transcription factor-binding specificity, incorporation of new gene targets into an existing regulatory system, and cooption of regulatory systems to control a different set of genes. We investigated one example in greater detail by measuring the in vitro activity of the S. cerevisiae transcription factor Rpn4p and its orthologs from Candida albicans and Neurospora crassa. Our results suggest that the DNA binding specificity of these proteins has coevolved with the sequences found upstream of the Rpn4p target genes and suggest that Rpn4p has a different function in N. crassa."
"Computational identification of developmental enhancers: conservation and function of transcription factor binding-site clusters in Drosophila melanogaster and Drosophila pseudoobscuraBACKGROUND:The identification of sequences that control transcription in metazoans is a major goal of genome analysis. In a previous study, we demonstrated that searching for clusters of predicted transcription factor binding sites could discover active regulatory sequences, and identified 37 regions of the Drosophila melanogaster genome with high densities of predicted binding sites for five transcription factors involved in anterior-posterior embryonic patterning. Nine of these clusters overlapped known enhancers. Here, we report the results of in vivo functional analysis of 27 remaining clusters.RESULTS:We generated transgenic flies carrying each cluster attached to a basal promoter and reporter gene, and assayed embryos for reporter gene expression. Six clusters are enhancers of adjacent genes: giant, fushi tarazu, odd-skipped, nubbin, squeeze and pdm2; three drive expression in patterns unrelated to those of neighboring genes; the remaining 18 do not appear to have enhancer activity. We used the Drosophila pseudoobscura genome to compare patterns of evolution in and around the 15 positive and 18 false-positive predictions. Although conservation of primary sequence cannot distinguish true from false positives, conservation of binding-site clustering accurately discriminates functional binding-site clusters from those with no function. We incorporated conservation of binding-site clustering into a new genome-wide enhancer screen, and predict several hundred new regulatory sequences, including 85 adjacent to genes with embryonic patterns.CONCLUSIONS:Measuring conservation of sequence features closely linked to function - such as binding-site clustering - makes better use of comparative sequence data than commonly used methods that examine only sequence identity."
The Economic Implications of Learning by Doing
"Shannon Information and Kolmogorov ComplexityWe compare the elementary theories of Shannon information and Kolmogorov complexity, the extent to which they have a common purpose, and where they are fundamentally different. We discuss and relate the basic notions of both theories: Shannon entropy versus Kolmogorov complexity, the relation of both to universal coding, Shannon mutual information versus Kolmogorov (`algorithmic') mutual information, probabilistic sufficient statistic versus algorithmic sufficient statistic (related to lossy compression in the Shannon theory versus meaningful information in the Kolmogorov theory), and rate distortion theory versus Kolmogorov's structure function. Part of the material has appeared in print before, scattered through various publications, but this is the first comprehensive systematic comparison. The last mentioned relations are new."
"Glucose intake induces an increase in activator protein 1 and early growth response 1 binding activities, in the expression of tissue factor and matrix metalloproteinase in mononuclear cells, and in plasma tissue factor and matrix metalloproteinase concentrations.BACKGROUND: Glucose intake has been shown to cause an increase in intranuclear nuclear factor-kappa B and a decrease in inhibitor kappa B that are consistent with a proinflammatory effect. We investigated the effect of glucose intake on 2 other proinflammatory transcription factors, activator protein 1 (AP-1) and early growth response 1 (Egr-1), and on the genes regulated by them, ie, the genes for matrix metalloproteinases 2 (MMP-2) and 9 (MMP-9) and tissue factor (TF), respectively. OBJECTIVE: The objective of the study was to ascertain whether the intake of 75 g glucose induces an increase in AP-1, Egr-1, and the genes regulated by them. DESIGN: Eight healthy subjects were given 75 g glucose dissolved in 300 mL water to drink. Blood samples were collected before and 1, 2, and 3 h after glucose intake. Four weeks later, the same subjects were given 300 mL water sweetened with saccharine, and blood samples were collected at the same time points. Mononuclear cells (MNCs) were separated, and nuclear fractions were isolated. RESULTS: AP-1 and Egr-1 binding activities were significantly higher 1 and 2 h after glucose intake and then decreased toward the baseline by 3 h. The expression of MMP-2 and TF in MNC homogenates also was significantly higher at 2 and 3 h. Plasma concentrations of MMP-2 were significantly higher at 3 h, whereas those of MMP-9 were significantly higher at 1, 2, and 3 h. In addition, TF was significantly higher at 2 and 3 h. Intake of saccharine-sweetened water had no significant effect on the inflammatory mediators measured in this study. CONCLUSION: Glucose induces proinflammatory changes, including increases in AP-1, Egr-1, MMPs, and TF, the factors that regulate processes that are potentially relevant to atherosclerotic plaque rupture and thrombosis."
"Expression profiling identifies genes that continue to respond to insulin in adipocytes made insulin-resistant by treatment with tumor necrosis factor-alpha.We have employed microarray technology using RNA from normal 3T3-L1 adipocytes and from 3T3-L1 adipocytes made insulin-resistant by treatment with tumor necrosis factor-alpha to identify a new class of insulin-responsive genes. These genes continued to respond normally to insulin even though the adipocytes themselves were metabolically insulin-resistant, i.e. they displayed a significantly decreased rate of insulin-stimulated glucose uptake. Approximately 12,000 genes/expressed sequence tags (ESTs) were screened. Of these, 40 genes/ESTs were identified that became insulin-resistant as expected (e.g. Socs-3, junB, and matrix metalloproteinase-11). However, 61 genes/ESTs continued to respond normally to insulin. Although some of these genes were previously shown to be regulated by insulin (e.g. Glut-1 and beta3-adrenergic receptor), other novel insulin-sensitive genes were also identified (e.g. Egr-1, epiregulin, Fra-1, and ABCA1). Real-time reverse transcription-PCR analysis confirmed the expression patterns of several of the differentially expressed genes. One gene that remained insulin-sensitive in the insulin-resistant adipocytes is the transcription factor Egr-1. Using an antisense strategy, we show that tissue factor and macrophage colony-stimulating factor, two cardiovascular risk factors, are downstream EGR-1 target genes in the adipocyte. Taken together, these data support the hypothesis that some signaling pathways remain insulin-sensitive in metabolically insulin-resistant adipocytes. These pathways may promote abnormal gene expression in hyperinsulinemic states like obesity and type II diabetes and thus may contribute to pathologies associated with these conditions."
"Insulin inhibits the pro-inflammatory transcription factor early growth response gene-1 (Egr)-1 expression in mononuclear cells (MNC) and reduces plasma tissue factor (TF) and plasminogen activator inhibitor-1 (PAI-1) concentrations.We have recently demonstrated that an infusion of a low dose of insulin reduces the intranuclear NF-kappa B (a pro-inflammatory transcription factor) content in MNC while also reducing the plasma concentration of NF-kappa B dependent pro-inflammatory cytokines and adhesion molecules. We have now tested the effect of insulin on the pro-inflammatory transcription factor, early growth response-1 (Egr-1) and plasma concentration of tissue factor (TF) and plasminogen activator inhibitor-1 (PAI-1), two major proteins whose expression is modulated by Egr-1. Insulin was infused at the rate of 2 IU/h in 5% dextrose (100 mL/h) and KCI (8 mmol/h) for 4 h in the fasting state in ten obese subjects. Blood samples were obtained at 0, 2, 4 and 6 h. MNC were isolated and their total homogenates and nuclear fractions were prepared and Egr-1 was measured by electrophoretic mobility shift assay (EMSA). Plasma TF and PAI-1 were assayed by ELISA. There was a significant fall in Egr-1 at 2 (66 +/- 14% of basal level) and 4 h (47 +/- 17% of the basal level; P<0.01). PAI-1 levels (basal = 100%) decreased significantly after insulin infusion at 2 h (57 +/- 6.7% of the basal level) and at 4 h (58 +/- 8.3% of the basal level; P<0.001). Plasma TF levels (basal = 100%) decreased to 76 +/- 7.7% of the basal level at 2 h and to 85 +/- 10.4% of the basal level at 4 h (P<0.05). Thus, insulin reduces intranuclear Egr-1 and the expression of TF and PAI-1. These data provide further evidence that insulin has an anti-inflammatory effect including the inhibition of TF and PAI-1 expression. These effects suggest a potential beneficial effect of insulin in thrombin formation and fibrinolysis in atherothrombosis."
"Activation of serum response factor in the depolarization induction of Egr-1 transcription in pancreatic islet beta-cells.The results of the current studies define the major elements whereby glucose metabolism in islet beta-cells leads to transcriptional activation of an early response gene in insulinoma cell lines and in rat islets. Glucose stimulation (2-20 mm) resulted in a 4-fold increase in Egr-1 mRNA at 30 min, as did the depolarizing agents KCl and tolbutamide. This response was inhibited by diazoxide and EGTA, indicating that beta-cell depolarization and Ca(2+) influx, respectively, are essential. Pharmacological inhibition of the Egr-1 induction by H89 (48%) and calmidazolium (35%), but not by mitogen-activated protein kinase/extracellular signal-regulated kinase kinase 1 and 2 or phosphatidylinositol 3-kinase inhibitors, implied that protein kinase A and Ca(2+)/calmodulin pathways are involved. Deletion mapping of the Egr-1 promoter revealed that the proximal -198 base pairs containing two serum response elements (SREs) and one cAMP-response element retained the depolarization response. Depolarization resulted in phosphorylation of cAMP-response element-binding protein, yet partial inhibition by a dominant negative cAMP-response element-binding protein, along with a robust response of a cAMP-response element-mutated Egr-1 promoter suggested the presence of a second Ca(2+)-responsive element. Depolarization activation of 5XSRE-LUC and serum response factor (SRF)-GAL4 constructs, along with activation of SRF-GAL4 by co-transfection with constitutively active calmodulin kinase IV and protein kinase A, and binding of Ser(103)-phosphorylated SRF in nuclear extracts, indicated that the SRE.SRF complexes contribute to the Ca(2+)-mediated transcriptional regulation of Egr-1. The results of the current experiments demonstrate for the first time SRE-dependent transcription and the role of SRF, a transcription factor known to be a major component of growth responses, in glucose-mediated transcriptional regulation in insulinoma cells."
"Activation of Elk-1, an Ets transcription factor, by glucose and EGF treatment of insulinoma cells.Elk-1, a member of the ternary complex factor family of Ets domain proteins that bind serum response elements, is activated by phosphorylation in a cell-specific manner in response to growth factors and other agents. The purpose of the current study was to determine whether Elk-1 activation contributes to glucose-/depolarization-induced Ca(2+)-dependent induction of immediate early response genes in pancreatic islet beta-cells. The results of experiments in insulinoma (MIN6) cells demonstrated that Elk-1-binding sites (Ets elements) in the Egr-1 gene promoter contribute to transcriptional activation of the gene. Treatment with either epidermal growth factor (EGF), a known inducer of beta-cell hyperplasia, glucose, or KCl-induced depolarization resulted in Ser(383) phosphorylation and transcriptional activation of Elk-1 (4 +/- 0.3-, P = 0.003, 2.3 +/- 0.19-, P = 0.002, and 2.2 +/- 0.1- fold, P = 0.001 respectively). The depolarization response was inhibited by the Ca(2+) channel blocker verapamil and by the MEK inhibitor PD98059 (53 +/- 6 and 55 +/- 0.5%, respectively). EGF-induced activation of Elk-1 was also inhibited by PD98059 (60 +/- 5%). A dominant negative Ras produced partial inhibition (42%) of the depolarization-induced Elk-1 transcriptional activation. Transfection with a constitutively active Ca(2+)/calmodulin kinase IV plasmid also resulted in Elk-1 transcriptional activation. Experiments with p38, phosphatidylinositol 3-kinase, and protein kinase A inhibitors indicated that these pathways are not involved. We conclude that Elk-1 activation contributes to glucose-/depolarization-induced Ca(2+)-dependent induction of immediate early growth response genes in pancreatic islet beta-cells. Furthermore, the results demonstrated a convergence of nutrient- and growth factor-mediated signaling pathways on Elk-1 activation through induction of Ras/mitogen-activated protein kinase ERK-1 and -2. The role of these pathways in the glucose-induced proliferation of islet beta-cells can now be assessed."
"Lipotoxicity of the pancreatic beta-cell is associated with glucose-dependent esterification of fatty acids into neutral lipids.Prolonged exposure of isolated islets to supraphysiologic concentrations of palmitate decreases insulin gene expression in the presence of elevated glucose levels. This study was designed to determine whether or not this phenomenon is associated with a glucose-dependent increase in esterification of fatty acids into neutral lipids. Gene expression of sn-glycerol-3-phosphate acyltransferase (GPAT), diacylglycerol acyltransferase (DGAT), and hormone-sensitive lipase (HSL), three key enzymes of lipid metabolism, was detected in isolated rat islets. Their levels of expression were not affected after a 72-h exposure to elevated glucose and palmitate. To determine the effects of glucose on palmitate-induced neutral lipid synthesis, isolated rat islets were cultured for 72 h with trace amounts of [14C]palmitate with or without 0.5 mmol/l unlabeled palmitate, at 2.8 or 16.7 mmol/l glucose. Glucose increased incorporation of [14C]palmitate into complex lipids. Addition of exogenous palmitate directed lipid metabolism toward neutral lipid synthesis. As a result, neutral lipid mass was increased upon prolonged incubation with elevated palmitate only in the presence of high glucose. The ability of palmitate to increase neutral lipid synthesis in the presence of high glucose was concentration-dependent in HIT cells and was inversely correlated to insulin mRNA levels. 2-Bromopalmitate, an inhibitor of fatty acid mitochondrial beta-oxidation, reproduced the inhibitory effect of palmitate on insulin mRNA levels. In contrast, palmitate methyl ester, which is not metabolized, and the medium-chain fatty acid octanoate, which is readily oxidized, did not affect insulin gene expression, suggesting that fatty-acid inhibition of insulin gene expression requires activation of the esterification pathway. These results demonstrate that inhibition of insulin gene expression upon prolonged exposure of islets to palmitate is associated with a glucose-dependent increase in esterification of fatty acids into neutral lipids."
"Minireview: Glucagon-like peptides regulate cell proliferation and apoptosis in the pancreas, gut, and central nervous system.Gut peptides exert diverse effects regulating satiety, gastrointestinal motility and acid secretion, epithelial integrity, and both nutrient absorption and disposal. These actions are initiated by activation of specific G protein-coupled receptors and may be mediated by direct or indirect effects on target cells. More recent evidence demonstrates that gut peptides, exemplified by glucagon-like peptides-1 and 2 (GLP-1 and GLP-2), directly regulate signaling pathways coupled to cell proliferation and apoptosis. GLP-1 receptor activation enhances beta-cell proliferation and promotes islet neogenesis via activation of pdx-1 expression. The proliferative effects of GLP-1 appear to involve multiple intracellular pathways, including stimulation of Akt, activation of protein kinase Czeta, and transactivation of the epidermal growth factor receptor through the c-src kinase. GLP-1 receptor activation also promotes cell survival in beta-cells and neurons via increased levels of cAMP leading to cAMP response element binding protein activation, enhanced insulin receptor substrate-2 activity and, ultimately, activation of Akt. These actions of GLP-1 are reflected by expansion of beta-cell mass and enhanced resistance to beta-cell injury in experimental models of diabetes in vivo. GLP-2 also promotes intestinal cell proliferation and confers resistance to cellular injury in a variety of cell types. Administration of GLP-2 to animals with experimental intestinal injury promotes regeneration of the gastrointestinal epithelial mucosa and confers resistance to apoptosis in an indirect manner via yet-to-be identified GLP-2 receptor-dependent regulators of mucosal growth and cell survival. These proliferative and antiapoptotic actions of GLP-1 and GLP-2 may contribute to protective and regenerative actions of these peptides in human subjects with diabetes and intestinal disorders, respectively."
"MUSCLE: a multiple sequence alignment method with reduced time and space complexity. In a previous paper, we introduced MUSCLE, a new program for creating multiple alignments of protein sequences, giving a brief summary of the algorithm and showing MUSCLE to achieve the highest scores reported to date on four alignment accuracy benchmarks. Here we present a more complete discussion of the algorithm, describing several previously unpublished techniques that improve biological accuracy and / or computational complexity. We introduce a new option, MUSCLE-fast, designed for high-throughput applications. We also describe a new protocol for evaluating objective functions that align two profiles. We compare the speed and accuracy of MUSCLE with CLUSTALW, Progressive POA and the MAFFT script FFTNS1, the fastest previously published program known to the author. Accuracy is measured using four benchmarks: BAliBASE, PREFAB, SABmark and SMART. We test three variants that offer highest accuracy (MUSCLE with default settings), highest speed (MUSCLE-fast), and a carefully chosen compromise between the two (MUSCLE-prog). We find MUSCLE-fast to be the fastest algorithm on all test sets, achieving average alignment accuracy similar to CLUSTALW in times that are typically two to three orders of magnitude less. MUSCLE-fast is able to align 1,000 sequences of average length 282 in 21 seconds on a current desktop computer. MUSCLE offers a range of options that provide improved speed and / or alignment accuracy compared with currently available programs. MUSCLE is freely available at http://www.drive5.com/muscle. "
"An adaptive and iterative algorithm for refining multiple sequence alignmentMultiple sequence alignment is a basic tool in computational genomics. The art of multiple sequence alignment is about placing gaps. This paper presents a heuristic algorithm that improves multiple protein sequences alignment iteratively. A consistency-based objective function is used to evaluate the candidate moves. During the iterative optimization, well-aligned regions can be detected and kept intact. Columns of gaps will be inserted to assist the algorithm to escape from local optimal alignments. The algorithm has been evaluated using the BAliBASE benchmark alignment database. Results show that the performance of the algorithm does not depend on initial or seed alignments much. Given a perfect consistency library, the algorithm is able to produce alignments that are close to the global optimum. We demonstrate that the algorithm is able to refine alignments produced by other software, including ClustalW, SAGA and T-COFFEE. The program is available upon request."
"Sensitivity and tolerance to ethanol in mouse lines selected for ethanol-induced hypothermia.Within-family selective breeding techniques have been used to create two lines of mice to be insensitive (HOT) and two lines to be sensitive (COLD) to the hypothermic effects of an acute 3.0-g/kg ethanol (EtOH) injection. Previous studies have found HOT mice to be relatively resistant to the development of tolerance to this effect, whereas COLD mice readily develop tolerance. The breeding program is currently in selected Generation 52, and the HOT and COLD mice differ by about 10 degrees C (average of both replicates) in their selected hypothermic response. Starting with selection Generation 20, separate lines of mice were inbred from the HOT-2 and COLD-2 selected lines, while selection continued for the original two replicate lines of HOT and COLD mice. To assess whether different dose treatments would produce differential tolerance development in the HOT and COLD selected lines, we administered different dose regimens across 5 days to HOT and COLD mice. The COLD mice developed tolerance while the HOT mice did not, regardless of total EtOH administered. In a separate study, we administered EtOH (3.0 g/kg) to mice for 3 days to assess a shorter tolerance paradigm. We also present here responses to the selection dose of 3.0-g/kg EtOH in the inbred HOT (IHOT-2) and COLD (ICOLD-2) mice tested after 41 generations of brother-sister mating. In addition, we report recent attempts to find doses of EtOH that would produce an equivalent initial hypothermic response in each of the six lines (HOT-1, COLD-1, HOT-2, COLD-2, ICOLD-2, and IHOT-2). When doses were selected to produce similar initial hypothermic sensitivity, tolerance was tested by giving three daily doses and examining the attenuation of the hypothermic response on the third day. All three COLD lines developed significant tolerance, while the HOT lines did not. The HOT and COLD mice provide a genetic model to study mechanisms mediating acute EtOH-induced hypothermia as well as tolerance development."
Time-stamping with Binary Linking Schemes
Exploiting Paraphrases in a Question Answering System
"Magnetic models on Apollonian networksThermodynamic and magnetic properties of Ising models defined on the triangular Apollonian network are investigated. This and other similar networks are inspired by the problem of covering an Euclidian domain with circles of maximal radii. Maps for the thermodynamic functions in two subsequent generations of the construction of the network are obtained by formulating the problem in terms of transfer matrices. Numerical iteration of this set of maps leads to exact values for the thermodynamic properties of the model. Different choices for the coupling constants between only nearest neighbors along the lattice are taken into account. For both ferromagnetic and anti-ferromagnetic constants, long range magnetic ordering is obtained. With exception of a size dependent effective critical behavior of the correlation length, no evidence of asymptotic criticality was detected."
Neural Cryptography with QueriesNeural cryptography is based on synchronization of tree parity machines by mutual learning. We extend previous key-exchange protocols by replacing random inputs with queries depending on the current state of the neural networks. The probability of a successful attack is calculated for different model parameters using numerical simulations. The results show that queries restore the security against cooperating attackers. The success probability can be reduced without increasing the average synchronization time.
"Statistical Mechanics of Dilute Batch Minority Games with Random External InformationWe study the dynamics and statics of a dilute batch minority game with random external information. We focus on the case in which the number of connections per agent is infinite in the thermodynamic limit. The dynamical scenario of ergodicity breaking in this model is different from the phase transition in the standard minority game and is characterised by the onset of long-term memory at finite integrated response. We demonstrate that finite memory appears at the AT-line obtained from the corresponding replica calculation, and compare the behaviour of the dilute model with the minority game with market impact correction, which is known to exhibit similar features."
"Life Above Threshold: From List Decoding to Area Theorem and MSEWe consider communication over memoryless channels using low-density parity-check code ensembles above the iterative (belief propagation) threshold. What is the computational complexity of decoding (i.e., of reconstructing all the typical input codewords for a given channel output) in this regime? We define an algorithm accomplishing this task and analyze its typical performance. The behavior of the new algorithm can be expressed in purely information-theoretical terms. Its analysis provides an alternative proof of the area theorem for the binary erasure channel. Finally, we explain how the area theorem is generalized to arbitrary memoryless channels. We note that the recently discovered relation between mutual information and minimal square error is an instance of the area theorem in the setting of Gaussian channels."
"Weighted networks of scientific communication: the measurement and geometrical role of weightIn order to take the weight of connection into consideration and to find a natural measurement of weight, we have collected papers in Econophysics and constructed a network of scientific communication to integrate idea transportation among econophysicists by collaboration, citation and personal discussion. Some basic statistics such as weight per degree are discussed in \citefan. In this paper, by including the papers published recently, further statistical results for the network are reported. Clustering coefficient of weighted network is introduced and empirically studied in this network. We also compare the typical statistics on this network under different weight measurements, including random and inverse weight. The conclusion from weight-randomized network is helpful to the investigation of the geometrical role of weight."
"Back-propagation of accuracyIn this paper we solve the problem: how to determine maximal allowable errors, possible for signals and parameters of each element of a network proceeding from the condition that the vector of output signals of the network should be calculated with given accuracy? ""Back-propagation of accuracy"" is developed to solve this problem. The calculation of allowable errors for each element of network by back-propagation of accuracy is surprisingly similar to a back-propagation of error, because it is the backward signals motion, but at the same time it is very different because the new rules of signals transformation in the passing back through the elements are different. The method allows us to formulate the requirements to the accuracy of calculations and to the realization of technical devices, if the requirements to the accuracy of output signals of the network are known."
"Order From Chaos: A Reconsideration of Fundamental PrinciplesTraditional discussions of the Second Law of Thermodynamics studied the limits of very specific types of devices, such as heat engines, chemical reactions, and molecules channeled by valves. Allahverdyan and Nieuwenhuizen (<A HREF=""/abs/cond-mat/0110422"">cond-mat/0110422</A>) have come the closest to proving a more general form of the Second Law, applicable to field effect devices -- but recently (<A HREF=""/abs/cond-mat/0408537"">cond-mat/0408537</A>) they have observed counterexamples and loopholes. This paper discusses recent field effect nanotechnologies which might permit a more substantial counterexample. Efforts were made to disprove the possibility of extracting electricity from ambient heat, from another perspective -- but these efforts led only to a new result on the equivalence of classical and quantum statistics, which may be important to the backwards-time interpretation of quantum mechanics."
"Entropy scaling laws for diffusionComment to the letter of Samanta et al., Phys. Rev. Lett. 92, 145901 (2004)."
Special Issue on Ubiquitous Games
A mixed reality mystery game
"Wizards, Bureaucrats, Warriors, and Hackers: Writing the History of the Internet"
Brave New World or Blind Alley? American History on the World Wide Web
"Price Clustering and Discreteness: Is there Chaos behind the Noise?We investigate the ""compass rose"" (Crack, T.F. and Ledoit, O. (1996), Journal of Finance, 51(2), pg. 751-762) patterns revealed in phase portraits (delay plots) of stock returns. The structures observed in these diagrams have been attributed mainly to price clustering and discreteness. Using wavelet based denoising, we examine the noise-free versions of a set of FTSE100 stock returns time series. We reveal evidence of non-periodic cyclical dynamics. As a second stage we apply Surrogate Data Analysis on the original and denoised stock returns. Our results suggest that there is a strong nonlinear and possibly deterministic signature in the data generating processes of the stock returns sequences."
"Vulnerability and Protection of Critical InfrastructuresCritical infrastructure networks are a key ingredient of modern society. We discuss a general method to spot the critical components of a critical infrastructure network, i.e. the nodes and the links fundamental to the perfect functioning of the network. Such nodes, and not the most connected ones, are the targets to protect from terrorist attacks. The method, used as an improvement analysis, can also help to better shape a planned expansion of the network."
"From collective rhythm to adaptive synchronizationA novel viewpoint, i.e., adaptive synchronization, is proposed to explore collective rhythm observed in many complex, self-organizing systems. We show that a simple adaptive coupling is able to tip arrays of oscillators towards collective synchronization. Two arrays of simply coupled Hindmarsh-Rose chaotic neurons are used to illustrate cooperative dynamics of neural activity like the central pattern generators, which supplies a new idea for biological experiments and numerical simulations. The results enhance the viewpoint that chaos is a necessary ingredient in life, and indicate that such small-world adaptive coupling may be a universal essence of the collective rhythm observed in nature."
"Chimera States for Coupled OscillatorsArrays of identical oscillators can display a remarkable spatiotemporal pattern in which phase-locked oscillators coexist with drifting ones. Discovered two years ago, such ""chimera states"" are believed to be impossible for locally or globally coupled systems; they are peculiar to the intermediate case of nonlocal coupling. Here we present an exact solution for this state, for a ring of phase oscillators coupled by a cosine kernel. We show that the stable chimera state bifurcates from a spatially modulated drift state, and dies in a saddle-node bifurcation with an unstable chimera."
"Perturbing the topology of the Game of Life increases its robustness to asynchronyAn experimental analysis of the asynchronous version of the ""Game of Life"" is performed to estimate how topology perturbations modify its evolution. We focus on the study of a phase transition from an ""inactive-sparse phase"" to a ""labyrinth phase"" and produce experimental data to quantify these changes as a function of the density of the initial configuration, the value of the synchrony rate, and the topology missing-link rate. An interpretation of the experimental results is given using the hypothesis that initial ""germs"" colonize the whole lattice and the validity of this hypothesis is tested."
"Fourier's law and maximum path informationBy using a path information defined for the measure of the uncertainty of instable dynamics, a theoretical derivation of Fourier's law of heat conduction is given on the basis of maximum information method associated with the principle of least action."
"Switching by agents between two trading behaviors and the stylized facts of financial marketsI propose an agent-based model of a single-asset financial market, described in terms of a small number of parameters. I show that switching by agents between two trading behaviors (informed vs. liquidity traders) leads to a market price that fluctuates endlessly and a volatility that displays a mean-reverting behavior. This agent-based model generically leads to price returns having statistical properties similar to the stylized facts observed in financial time series: an absence of autocorrelation in returns, stochastic volatility, excess volatility, volatility clustering that is not attributable to the external signal. The model's parsimonious structure allows the identification of the mechanism leading to these effects. I investigate some properties of this model theoretically and present analytical results."
Innovation flow through social networks: Productivity distributionA detailed empirical analysis of the productivity of non financial firms across several countries and years shows that productivity follows a non-Gaussian distribution with power law tails. We demonstrate that these empirical findings can be interpreted as consequence of a mechanism of exchanges in a social network where firms improve their productivity by direct innovation or/and by imitation of other firm's technological and organizational solutions. The type of network-connectivity determines how fast and how efficiently information can diffuse and how quickly innovation will permeate or behaviors will be imitated. From a model for innovation flow through a complex network we obtain that the expectation values of the productivity level are proportional to the connectivity of the network of links between firms. The comparison with the empirical distributions reveals that such a network must be of a scale-free type with a power-law degree distribution in the large connectivity range.
"Analysis of scale-free networks based on a threshold graph with intrinsic vertex weightsMany real networks are complex and have power-law vertex degree distribution, short diameter, and high clustering. We analyze the network model based on thresholding of the summed vertex weights, which belongs to the class of networks proposed by Caldarelli et al. (2002). Power-law degree distributions, particularly with the dynamically stable scaling exponent 2, realistic clustering, and short path lengths are produced for many types of weight distributions. Thresholding mechanisms can underlie a family of real complex networks that is characterized by cooperativeness and the baseline scaling exponent 2. It contrasts with the class of growth models with preferential attachment, which is marked by competitiveness and baseline scaling exponent 3."
"Epidemic spread in weighted networksWe study the detailed epidemic spreading process in scale-free networks with weight that denote familiarity between two people or computers. The result shows that spreading velocity reaches a peak quickly then decays representing power-law time behavior, and comparing to non-weighted networks, precise hierarchical dynamics is not found although the nodes with larger strength is preferential to be infected."
"Minority games with finite score memoryWe analyze grand-canonical minority games with infinite and finite score memory and different updating timescales (from `on-line' games to `batch' games) in detail with various complementary methods, both analytical and numerical. We focus on the emergence of `stylized facts' and on the production of exploitable information, as well as on the dynamic behaviour of the models. We find that with finite score memory no agent can be frozen, and that all the current analytical methods fail to provide satisfactory explanation of the observed behaviours."
"Multifractal Analysis and Local Hoelder Exponents Approach to Detecting Stock Markets CrashesThis paper is devoted to problem of detecting critical events at finiacial markets using methods of multifractal analysis. Namely, the local regularity of time-series is studied. As a result, one can find out a special behavior or signal of regularity before crashes. This spesial behaviour of local Hoelder exponents inherent in financial time series can be used in detecting critcal events or crashes at financial markets."
"Controlling the spreading in small-world networks The spreading (propagation) of diseases, viruses, and disasters such as power blackout through a huge-scale and complex network is one of the most concerned issues today. In this paper, we study the control of such spreading in a nonlinear spreading model of small-world networks. We found that the short-cut adding probability $p$ in the N-W model \citeN-W:1999 of small-world networks determines the Hopf bifurcation and other bifurcating behaviors in the proposed model. We further show a control technique that stabilize a periodic spreading behavior onto a stable equilibrium over the proposed model of small-world networks."
EDUTELLA: A P2P Networking Infrastructure Based on RDF
"The Color of Money and the Nature of Value: Greenbacks and Gold in Postbellum AmericaMoney measures value in market economies. Money's own value is socially constructed since people attribute worth to a medium whose physical characteristics are essentially irrelevant to its monetary role. Money works best when it can be taken for granted and its social construction is hidden. During the greenback era, two monetary alternatives (gold-based money and paper money) were debated, which raised many questions about the nature of monetary value. Using a ""macrocultural"" approach, we analyze the rethoric of greenbacker and bullionist writings to study the social construction and deconstruction of a taken-for-granted institution."
"Cellular automata with majority rule on evolving networkThe cellular automata discrete dynamical system is considered as the two-stage process: the majority rule for the change in the automata state and the rule for the change in topological relations between automata. The influence of changing topology to the cooperative phenomena, namely zero-temperature ferromagnetic phase transition, is observed."
"Heterogeneity and feedback in an agent-based market modelI propose an agent-based model of a single-asset financial market, described in terms of a small number of parameters, that generates price returns with statistical properties similar to the stylized facts observed in financial time series. I show that the joint effect of feedback and heterogeneity leads to a market price that fluctuates endlessly and a volatility that displays a mean-reverting behavior. This agent-based model generically leads to an absence of autocorrelation in returns, stochastic volatility, excess volatility, volatility clustering and endogeneous bursts of market activity that is not attributable to external noise. The model's parsimonious structure allows the identification of the mechanism leading to these effects. I investigate some properties of this model theoretically and present numerical simulation of other properties."
"Evolution of heterogeneity in an agent-based market modelAn agent-based model of a single-asset financial market, described in terms of a small number of parameters is presented in this paper. The joint effect of feedback and heterogeneity leads to price returns with statistical properties similar to the stylized facts observed in financial time series. The paper focus on the evolution of heterogeneity in the model."
"Preferential compactness of networksWe introduce evolving networks where new vertices preferentially connect to the more central parts of a network. This makes such networks compact. Finite networks grown under the preferential compactness mechanism have complex architectures, but infinite ones tend towards the opposite, having rapidly decreasing distributions of connections. We present an analytical solution of the problem for tree-like networks. Our approach links a collective self-optimization mechanism of the emergence of complex network architectures to self-organization mechanisms."
"Links between nonlinear dynamics and statistical mechanics in a simple one-dimensional modelWe consider the links between nonlinear dynamics and thermodynamics in the framework of a simple nonlinear model for DNA. Two analyses of the phase transition, either with the transfer integral approach or by considering the instability of a nonlinear particular solution, are discussed. Conversely, the computation of the largest Lyapunov exponent is obtained within a thermodynamic treatment. Differences with the Peyrard-Bishop model are also discussed."
"Exponential distribution of financial returns at mesoscopic time lags: a new stylized factWe study the probability distribution of stock returns at mesoscopic time lags (return horizons) ranging from about an hour to about a month. While at shorter microscopic time lags the distribution has power-law tails, for mesoscopic times the bulk of the distribution (more than 99% of the probability) follows an exponential law. The slope of the exponential function is determined by the variance of returns, which increases proportionally to the time lag. At longer times, the exponential law continuously evolves into Gaussian distribution. The exponential-to-Gaussian crossover is well described by the analytical solution of the Heston model with stochastic volatility."
"The long memory of the efficient market For the London Stock Exchange we demonstrate that the signs of orders obey a long-memory process. The autocorrelation function decays roughly as $τ^-α$ with $α ≈ 0.6$, corresponding to a Hurst exponent $H ≈ 0.7$. This implies that the signs of future orders are quite predictable from the signs of past orders; all else being equal, this would suggest a very strong market inefficiency. We demonstrate, however, that fluctuations in order signs are compensated for by anti-correlated fluctuations in transaction size and liquidity, which are also long-memory processes. This tends to make the returns whiter. We show that some institutions display long-range memory and others don't."
"On the topology of the world exchange arrangements webExchange arrangements among different countries over the world are foundations of the world economy, which generally stand behind the daily economic evolution. As the first study of the world exchange arrangements web (WEAW), we built a bipartite network with countries as one type of nodes and currencies as the other, and found it to have a prominent scale-free feature with a power-law degree distribution. In a further empirical study of the currency section of the WEAW, we calculated the clustering coefficients, average nearest-neighbors degree, and average shortest distance. As an essential economic network, the WEAW is found to be a correlated disassortative network with a hierarchical structure, possessing a more prominent scale-free feature than the world trade web (WTW)."
"Complexity vs stability in small-world networksAccording to the May-Wigner stability theorem, increasing the complexity of a network inevitably leads to its destabilization, such that a small perturbation will be able to disrupt the entire system. One of the principal arguments against this observation is that it is valid only for random networks, and therefore does not apply to real-world networks, which presumably are structured. Here we examine how the introduction of small-world topological structure into networks affect their stability. Our results indicate that, in structured networks, the parameter values at which the stability-instability transition occurs with increasing complexity is identical to that predicted by the May-Wigner criteria. However, the nature of the transition, as measured by the finite-size scaling exponent, appears to change as the network topology transforms from regular to random, with the small-world regime as the cross-over region. This behavior is related to the localization of the largest eigenvalues along the real axis in the eigenvalue plain with increasing regularity in the network."
"Coarse-grained periodic orbits and bifurcations in a Markov chain model for evolution of labor divisionWe construct a Markov process model to describe the evolution of labor division and its dynamical behavior is investigated by numerical simulations in detail. We have shown that under the mechanism of increasing returns, the division of labor will emerge from the initial homogenous distribution and with the change of parameters there are period-adding coarse-grained bifurcations in the model. The model gives an example of emergent property in the evolution of complex systems and reveals an interesting dynamical behavior of the Markov chain process. Key words: Evolution, Bifurcation, Pattern formation PACS number(s): 87.23.-n, 89.75.Fb, 05.45.-a"
"Base of nonlinear dynamics or Real Dynamics, Ideal Dynamics, Unpredictable Dynamics and ""Schrodinger cat""In the paper paradoxes underlying thermodynamics and a quantum mechanics are discussed. Their solution is given from the point of view of influence of the exterior observer (surrounding medium) destroying correlations of system, or boundedness of self-knowledge of system in a case when both the observer, and a surrounding medium are included in system. Concepts Real Dynamics, Ideal Dynamics and Unpredictable Dynamics are entered. Consideration an appearance of a life is given from the point of view of these three Dynamics."
Stochastic simulations of web search engines
"The spatial structure of networksWe study networks that connect points in geographic space, such as transportation networks and the Internet. We find that there are strong signatures in these networks of topography and use patterns, giving the networks shapes that are quite distinct from one another and from non-geographic networks. We offer an explanation of these differences in terms of the costs and benefits of transportation and communication, and give a simple model based on the Monte Carlo optimization of these costs and benefits that reproduces well the qualitative features of the networks studied."
"Superpositional Quantum Network TopologiesWe introduce superposition-based quantum networks composed of (i) the classical perceptron model of multilayered, feedforward neural networks and (ii) the algebraic model of evolving reticular quantum structures as described in quantum gravity. The main feature of this model is moving from particular neural topologies to a quantum metastructure which embodies many differing topological patterns. Using quantum parallelism, training is possible on superpositions of different network topologies. As a result, not only classical transition functions, but also topology becomes a subject of training. The main feature of our model is that particular neural networks, with different topologies, are quantum states. We consider high-dimensional dissipative quantum structures as candidates for implementation of the model."
"A conjecture on the distribution of firm profitA common assumption of political economy is that profit rates across firms or sectors tend to uniformity, and often models are formulated in which this tendency is assumed to have been realised. But in reality this tendency is never realised and the distribution of firm profits is not degenerate but skewed to the right. The mode is less than the mean and super-profits are present. To understand the distribution of firm profits a general probabilistic argument is sketched that yields a candidate functional form. The overall properties of the derived distribution are qualitatively consistent with empirical measures, although there is more work to be done."
"Quantum computation with Josephson-qubits by using a current-biased information busWe propose an effective scheme for manipulating quantum information stored in a superconducting nanocircuit. The Josephson qubits are coupled via their separate interactions with an information bus, a large current-biased Josephson junction treated as an oscillator with adjustable frequency. The bus is sequentially coupled to only one qubit at a time. Distant Josephson qubits without any direct interaction can be indirectly coupled with each other by independently interacting with the bus sequentially, via exciting/de-exciting vibrational quanta in the bus. This is a superconducting analog of the successful ion trap experiments on quantum computing. Our approach differs from previous schemes that simultaneously coupled two qubits to the bus, as opposed to their sequential coupling considered here. The significant quantum logic gates can be realized by using these tunable and selective couplings. The decoherence properties of the proposed quantum system are analyzed within the Bloch-Redfield formalism. Numerical estimations of certain important experimental parameters are provided."
"Scale Invariant Fractal and Slow Dynamics in Nucleation and Growth Processes We propose a stochastic counterpart of the classical Kolmogorov-Johnson-Mehl-Avrami (KJMA) model to describe the nucleation-and-growth phenomena of a stable phase (S-phase). We report that for growth velocity of S-phase $v=s(t)/t$ where $s(t)$ is the mean value of the interval size $x$ of metastable phase (M-phase) and for $v=x/τ(x)$ where $τ(x)$ is the mean nucleation time, the system exhibits a power law decay of M-phase. We also find that the resulting structure exhibits self-similarity and can be best described as a fractal. Interestingly, the fractal dimension $d_f$ helps generalising the exponent $(1+d_f)$ of the power-law decay. However, when either $v=v_0$ (constant) or $v=σ/t$ ($σ$ is a constant) the decay is exponential and it is accompanied by the violation of scaling."
"Citation Statistics From More Than a Century of Physical ReviewWe study the statistics of citations from all Physical Review journals for the 110-year period 1893 until 2003. In addition to characterizing the citation distribution and identifying publications with the highest citation impact, we investigate how citations evolve with time. There is a positive correlation between the number of citations to a paper and the average age of citations. Citations from a publication have an exponentially decaying age distribution; that is, old papers tend to not get cited. In contrast, the citations to a publication are consistent with a power-law age distribution, with an exponent close to -1 over a time range of 2 -- 20 years. We also identify a number of strongly-correlated citation bursts and other dramatic features in the time history of citations to individual publications."
"How the trading activity scales with the company sizes in the FTSE 100This paper investigates the scaling dependencies between measures of ""activity"" and of ""size"" for companies included in the FTSE 100. The ""size"" of companies is measured by the total market capitalization. The ""activity"" is measured with several quantities related to trades (transaction value per trade, transaction value per hour, tick rate), to the order queue (total number of orders, total value), and to the price dynamic (spread, volatility). The outcome is that systematic scaling relations are observed: 1) the value exchanged by hour and value in the order queue have exponents lower than 1 respectively 0.90 and 0.75; 2) the tick rate and the value per transaction scale with the exponents 0.39 and 0.44; 3) the annualized volatility is independent of the size, and the tick-by-tick volatility decreases with the market capitalization with an exponent -0.23; 4) the spread increases with the volatility with an exponent 0.94. A theoretical random walk argument is given that relates the volatility exponents with the exponents in points 1 and 2."
"Pre-logarithmic and logarithmic fields in a sandpile modelWe consider the unoriented two-dimensional Abelian sandpile model on the half-plane with open and closed boundary conditions, and relate it to the boundary logarithmic conformal field theory with central charge c=-2. Building on previous results, we first perform a complementary lattice analysis of the operator effecting the change of boundary condition between open and closed, which confirms that this operator is a weight -1/8 boundary primary field, whose fusion agrees with lattice calculations. We then consider the operators corresponding to the unit height variable and to a mass insertion at an isolated site of the upper half plane and compute their one-point functions in presence of a boundary containing the two kinds of boundary conditions. We show that the scaling limit of the mass insertion operator is a weight zero logarithmic field."
Anharmonic Oscillator Equations:Treatment Parallel to Mathieu EquationThe treatment of anharmonic oscillators (including double-wells) by instanton methods is wellknown. The alternative differential equation method is not so wellknown. Here we reformulate the latter completely parallel to the strong coupling case of the cosine potential and Mathieu equation for which extensive literature and monographs exist.
"Dynamics of Money and Income Distributions We study the model of interacting agents proposed by Chatterjee et al that allows agents to both save and exchange wealth. Closed equations for the wealth distribution are developed using a mean field approximation. We show that when all agents have the same fixed savings propensity, subject to certain well defined approximations defined in the text, these equations yield the conjecture proposed by Chatterjee for the form of the stationary agent wealth distribution. If the savings propensity for the equations is chosen according to some random distribution we show further that the wealth distribution for large values of wealth displays a Pareto like power law tail, ie P(w)∼ w^1+a. However the value of $a$ for the model is exactly 1. Exact numerical simulations for the model illustrate how, as the savings distribution function narrows to zero, the wealth distribution changes from a Pareto form to to an exponential function. Intermediate regions of wealth may be approximately described by a power law with $a>1$. However the value never reaches values of  1.6-1.7 that characterise empirical wealth data. This conclusion is not changed if three body agent exchange processes are allowed. We conclude that other mechanisms are required if the model is to agree with empirical wealth data."
"Coherence in scale-free networks of chaotic maps We study fully synchronized states in scale-free networks of chaotic logistic maps as a function of both dynamical and topological parameters. Three different network topologies are considered: (i) random scale-free topology, (ii) deterministic pseudo-fractal scale-free network, and (iii) Apollonian network. For the random scale-free topology we find a coupling strength threshold beyond which full synchronization is attained. This threshold scales as $k^-μ$, where $k$ is the outgoing connectivity and $μ$ depends on the local nonlinearity. For deterministic scale-free networks coherence is observed only when the coupling strength is proportional to the neighbor connectivity. We show that the transition to coherence is of first-order and study the role of the most connected nodes in the collective dynamics of oscillators in scale-free networks."
"Self-similar disk packings as model spatial scale-free networksThe network of contacts in space-filling disk packings, such as the Apollonian packing, are examined. These networks provide an interesting example of spatial scale-free networks, where the topology reflects the broad distribution of disk areas. A wide variety of topological and spatial properties of these systems are characterized. Their potential as models for networks of connected minima on energy landscapes is discussed."
"Glucose induces early growth response gene (Egr-1) expression in pancreatic beta cells.A copy deoxyribonucleic acid (cDNA) clone of the immediate early growth response gene, egr-1 (Krox-24, Zif268, NGFI-1), was isolated through subtractive hybridization screening to identify glucose-induced genes in pancreatic beta cells. Glucose rapidly and transiently induced egr-1 mRNA in the SV40-transformed murine beta-cell line, MIN6. Glucose also increased egr-1 mRNA expression in INS-1, betaTC3 and RINm5F beta-cell lines, although with different kinetics. Expression of the 82 kDa Egr-1 protein was induced both in MIN6 cells stimulated with glucose in vitro and in primary rat islet cells stimulated in vivo or in vitro. This response is unique to beta cells since glucose did not affect egr-1 expression in NIH-3T3 fibroblasts or glucose-sensitive hepatocytes. In beta cells egr-1 induction is specifically associated with insulin secretion, as it was not observed after stimulation with serum or insulin but was elicited by insulin secretagogues, including membrane depolarizing agents and cAMP agonists. Moreover, induction of egr-1 by glucose was inhibited by EDTA, indicating dependence on influx of extracellular Ca2+. Other immediate early response genes, c-fos and junB, were also induced following glucose stimulation with kinetics similar to egr-1, whereas c-jun and junD expression were not affected. Since the zinc-finger protein encoded by egr-1 is highly homologous to transcription factors that control expression of glucose-regulated genes in yeast, Egr-1 could mediate delayed adaptive responses of beta cells to sustained glucose stimulation through transcriptional regulation."
"Apoptosis and the beta-Cell in Type 1 and Type 2 Diabetes.Type 2 diabetes is characterized by both insulin resistance and impaired insulin secretion. The defect in insulin secretion clearly involves beta-cell dysfunction. Until recently there has been controversy surrounding a possible defect in beta-cell mass. In this presentation data will be given which affirm that there is a defect in beta-cell mass which precedes the development of type 2 diabetes (hyperglycemia). After a threshold of 60% decrease in beta-cell mass there is a marked increase in fasting blood glucose for each further decrement in beta-cell mass. Data will also be presented to support the notion that the mechanism subserving this defect is an increased frequency of beta-cell apoptosis which leads to the loss of beta-cell mass despite ongoing new beta-cell input, predominantly from new islet formation (islet neogenesis). Finally, potential causes of the increased frequency of beta-cell apoptosis will be reviewed. Copyright (c) 2004 S. Karger AG, Basel."
"Pancreatic islets from type 2 diabetic patients have functional defects and increased apoptosis that are ameliorated by metformin.Several properties of pancreatic beta-cells in type 2 diabetes (T2D) were studied by using islets isolated from T2D subjects. Moreover, because metformin has protective effects on nondiabetic beta-cells exposed to high glucose or free fatty acid levels, we investigated its direct action on T2D islet cells. Diabetic islets were characterized by reduced insulin content, decreased amount of mature insulin granules, impaired glucose-induced insulin secretion, reduced insulin mRNA expression, and increased apoptosis with enhanced caspase-3 and -8 activity. These alterations were associated with increased oxidative stress, as shown by higher nitrotyrosine concentrations, increased expression of protein kinase C-beta2 and nicotinamide adenine dinucleotide phosphate reduced-oxidase, and changes in mRNA expression of manganese- superoxide dismutase, Cu/Zn-superoxide dismutase, catalase, and glutathione peroxidase. Twenty-four-hour incubation of T2D islets with metformin was associated with increased insulin content, increased number and density of mature insulin granules, improved glucose-induced insulin release, and increased insulin mRNA expression. Moreover, apoptosis was reduced, with concomitant decrease of caspase-3 and -8 activity. These changes were accompanied by reduction or normalization of several markers of oxidative stress. Thus, T2D islets have several functional and survival defects, which can be ameliorated by metformin; the beneficial effects of the drug are mediated, at least in part, by a reduction of oxidative stress."
"Early growth response gene 1-mediated apoptosis is essential for transforming growth factor beta1-induced pulmonary fibrosis.Fibrosis and apoptosis are juxtaposed in pulmonary disorders such as asthma and the interstitial diseases, and transforming growth factor (TGF)-beta(1) has been implicated in the pathogenesis of these responses. However, the in vivo effector functions of TGF-beta(1) in the lung and its roles in the pathogenesis of these responses are not completely understood. In addition, the relationships between apoptosis and other TGF-beta(1)-induced responses have not been defined. To address these issues, we targeted bioactive TGF-beta(1) to the murine lung using a novel externally regulatable, triple transgenic system. TGF-beta(1) produced a transient wave of epithelial apoptosis that was followed by mononuclear-rich inflammation, tissue fibrosis, myofibroblast and myocyte hyperplasia, and septal rupture with honeycombing. Studies of these mice highlighted the reversibility of this fibrotic response. They also demonstrated that a null mutation of early growth response gene (Egr)-1 or caspase inhibition blocked TGF-beta(1)-induced apoptosis. Interestingly, both interventions markedly ameliorated TGF-beta(1)-induced fibrosis and alveolar remodeling. These studies illustrate the complex effects of TGF-beta(1) in vivo and define the critical role of Egr-1 in the TGF-beta(1) phenotype. They also demonstrate that Egr-1-mediated apoptosis is a prerequisite for TGF-beta(1)-induced fibrosis and remodeling."
"Early growth response 1 protein, an upstream gatekeeper of the p53 tumor suppressor, controls replicative senescence.The proliferation of most primary cells in culture is limited by replicative senescence and crisis, p53-dependent events. However, the regulation of p53 itself has not been defined. We find that deletion of the early growth response 1 (EGR1) transcription factor leads to a striking phenotype, including complete bypass of senescence and apparent immortal growth consistent with loss of a suppressor gene. EGR1-null mouse embryo fibroblasts (MEFs) exhibit decreased expression of p53, p21(Cip1/Waf1), and other p53 ""marker"" proteins. Precrisis WT but not EGR1-null cells exhibit irradiation-induced arrest. WT MEFs that emerge from crisis exhibit a mutated p53 (sequence confirmed), colony formation, and tumorigenicity. In contrast, high-passage EGR1-null MEFs retain the WT p53 sequence but with much reduced expression, remain untransformed, and grow continuously. An EGR1-expressing retrovirus restores p53 expression and sencescence to EGR1-null but not p53-null MEFs or postcrisis WT cells. Taken together, the results establish EGR1 as a major regulator of cell senescence and previously undescribed upstream ""gatekeeper"" of the p53 tumor suppressor pathway."
"Treatment and outcome analysis of 205 patients with multidrug-resistant tuberculosis.Multidrug-resistant tuberculosis, a disease caused by Mycobacterium tuberculosis strains that are resistant at least to rifampin and isoniazid, entails extended treatment, expensive and toxic regimens, and higher rates of treatment failure and death. We retrospectively analyzed the outcomes in 205 patients treated at our center for multidrug-resistant tuberculosis, with strains resistant to a median of six drugs, and compared the results with those of our previous series. Logistic regression and survival analysis were used to evaluate short- and long-term outcomes, respectively. Initial favorable response, defined as at least three consecutive negative sputum cultures over a period of at least 3 months, was 85% compared with 65% in the prior cohort. The current cohort had greater long-term success rates, 75% versus 56%, and lower tuberculosis death rates, 12% versus 22%, than the earlier one. Surgical resection and fluoroquinolone therapy were associated with improved microbiological and clinical outcomes in the 205 patients studied after adjusting for other variables. The improvement was statistically significant for surgery and among older patients for fluoroquinolone therapy."
"Outcome of chemotherapy in 107 patients with pulmonary tuberculosis resistant to isoniazid and rifampin.SETTING: National Masan Tuberculosis Hospital, Korea. OBJECTIVE: Treatment for multidrug-resistant tuberculosis (MDR-TB) is considered to be clinically important, but there are few reports on this topic. We therefore retrospectively evaluated the outcomes of chemotherapy only for pulmonary MDR-TB. DESIGN: We reviewed the clinical courses of 107 patients with pulmonary disease due to Mycobacterium tuberculosis resistant to rifampin and isoniazid who were under follow-up between March 1996 and June 1996 after hospitalization between January 1993 and January 1996. We performed a retrospective cohort study for all the patients' records. Their regimens were selected individually and preferably included four medications that they had not been given previously and to which the strain was fully susceptible. RESULTS: The 107 patients (mean age 38.3 years) had previously received a mean of five drugs, and were shedding bacilli that were resistant to a mean of four drugs. Of 63 patients with sufficient follow-up data, 52 (82.5%) responded to chemotherapy (as indicated by negative sputum cultures for at least three consecutive months); 11 (17.5%) had no response, as shown by continually positive cultures. In a univariate analysis, an unfavorable response was significantly associated with resistance to a greater number of drugs before the current courses of treatment (relative risk 21.5; 95% confidence interval 1.2-3.0; P < 0.05). The mean period of follow-up was 17 months. There was no subsequent relapse among the patients with responses, and there were no tuberculosis-related deaths. CONCLUSION: In this study, multidrug-resistant pulmonary tuberculosis responded relatively well to carefully selected regimens."
"Gene quantification using real-time quantitative PCR: an emerging technology hits the mainstream.The recent flood of reports using real-time Q-PCR testifies to the transformation of this technology from an experimental tool into the scientific mainstream. Many of the applications of real-time Q-PCR include measuring mRNA expression levels, DNA copy number, transgene copy number and expression analysis, allelic discrimination, and measuring viral titers. The range of applications of real-time Q-PCR is immense and has been fueled in part by the proliferation of lower-cost instrumentation and reagents. Successful application of real-time Q-PCR is not trivial. However, this review will help guide the reader through the variables that can limit the usefulness of this technology. Careful consideration of the assay design, template preparation, and analytical methods are essential for accurate gene quantification."
"Analysis of Relative Gene Expression Data Using Real-Time Quantitative PCR and the 2−ΔΔCT MethodThe two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data. Copyright 2001 Elsevier Science (USA)."
"Scale Free Networks from Self-OrganisationWe show how scale-free degree distributions can emerge naturally from growing networks by using random walks on the network. The algorithm uses only local graph information so this is a process of self-organisation. We demonstrate that this result holds for a wide range of parameters of the walk algorithm. We show that the standard mean field equations are an excellent approximation to the real networks we grow, but that fall short of a true scale-free network when the number of vertices is one million or smaller. We also generalise the random walk algorithm to produce weighted networks with power law distributions of both weight and degree. We suggest that a random walk self-organisation mechanism lies behind the many scale-free networks found in the real world."
"Statistical Mechanics Characterization of Neuronal MosaicsThe spatial distribution of neuronal cells is an important requirement for achieving proper neuronal function in several parts of the nervous system of most animals. For instance, specific distribution of photoreceptors and related neuronal cells, particularly the ganglion cells, in mammal's retina is required in order to properly sample the projected scene. This work presents how two concepts from the areas of statistical mechanics and complex systems, namely the "
Collection of Master-Slave Synchronized Chaotic SystemsIn this work the open-plus-closed-loop (OPCL) method of synchronization is used in order to synchronize the systems from the Sprott's collection of the simplest chaotic systems. The method is general and we were looking for the simplest coupling between master and slave system. The interval of parameters were synchronization is achieved are obtained analytically using Routh-Hurwitz conditions. Detailed calculations and numerical simulation are given for the system I from the Sprott's collection. Working in the same manner for non-linear systems based on ordinary differential equations the method can be adopted for the teaching of the topic.
"Homeless individuals and drug-resistant tuberculosis in south Texas.Drug-resistant tuberculosis was found in 21 percent of homeless individuals in New York City between 1982 and 1987. To see if this relationship existed in south Texas, we evaluated all admissions to a Texas Health Department facility with culture-proven tuberculosis. Four hundred forty-three patients were admitted between September 1987 and October 1990. Twenty-six, (5.9 percent) of these patients were identified as homeless. Alcoholism, tobacco abuse, divorce, and unemployment were common demographic characteristics. Six male patients and one female patient (27 percent) had Mycobacterium tuberculosis resistant to one or more antituberculosis drugs. Five were Hispanic, one was white, and one was black. The six male patients had resistance to only one drug, either rifampin or ethambutol. The female patient had resistance to streptomycin, isoniazid, and rifampin. These findings illustrate that drug-resistant tuberculosis exists among homeless individuals in south Texas. As the number of homeless people increases, physicians need to recognize that pulmonary tuberculosis is a frequent infection in this population and that the causal mycobacteria may well be resistant to one or more antituberculosis agents."
"Treatment of multidrug-resistant tuberculosis.The frequency of infections with M. tuberculosis resistant to antituberculous drugs is increasing in the United States and globally. This increase is a major threat to tuberculosis treatment and control programs. To prevent this situation from worsening, initial treatment programs that entail directly observed therapy supported by effective inducements or enforcements must be used. Retreatment of patients who have multidrug-resistant tuberculosis should be carried out in programs with comprehensive microbiologic, pharmacokinetic, psychosocial, and nutritional support systems. Regimens of multiple drugs, which generally are poorly tolerated and more toxic than traditional regimens, must be administered for 18 to 36 months. Resectional surgery may be required for substantial numbers of patients. For patients with AIDS who acquire tuberculosis caused by multiply-resistant strains, the disease may prove lethal before effective therapy can be implemented. Ultraviolet irradiation systems should be used to protect health care personnel and other patients in high-risk environments. Enhanced federal, state, and local programs for prevention and control are urgently needed, and research to identify new medications and systems for their delivery is essential."
"Document Similarity Using a Phrase Indexing Graph ModelDocument clustering techniques mostly rely on single term analysis of text, such as the vector space model. To better capture the structure of documents, the underlying data model should be able to represent the phrases in the document as well as single terms. We present a novel data model, the Document Index Graph, which indexes Web documents based on phrases rather than on single terms only. The semistructured Web documents help in identifying potential phrases that when matched with other documents indicate strong similarity between the documents. The Document Index Graph captures this information, and finding significant matching phrases between documents becomes easy and efficient with such model. The model is flexible in that it could revert to a compact representation of the vector space model if we choose not to index phrases. However, using phrase indexing yields more accurate document similarity calculations. The similarity between documents is based on both single term weights and matching phrase weights. The combined similarities are used with standard document clustering techniques to test their effect on the clustering quality. Experimental results show that our phrase-based similarity, combined with single-term similarity measures, gives a more accurate measure of document similarity and thus significantly enhances Web document clustering quality."
"The Effects of Canvassing, Telephone Calls, and Direct Mail on Voter Turnout: A Field ExperimentWe report the results of a randomized field experiment involving approximately 30,000 registered voters in New Haven, Connecticut. Nonpartisan get-out-the-vote messages were conveyed through personal canvassing, direct mail, and telephone calls shortly before the November 1998 election. A variety of substantive messages were used. Voter turnout was increased substantially by personal canvassing, slightly by direct mail, and not at all by telephone calls. These findings support our hypothesis that the long-term retrenchment in voter turnout is partly attributable to the decline in face-to-face political mobilization."
"From Kuramoto to Crawford: exploring the onset of synchronization in populations of coupled oscillatorsThe Kuramoto model describes a large population of coupled limit-cycle oscillators whose natural frequencies are drawn from some prescribed distribution. If the coupling strength exceeds a certain threshold, the system exhibits a phase transition: some of the oscillators spontaneously synchronize, while others remain incoherent. The mathematical analysis of this bifurcation has proved both problematic and fascinating. We review 25 years of research on the Kuramoto model, highlighting the false turns as well as the successes, but mainly following the trail leading from Kuramoto’s work to Crawford’s recent contributions. It is a lovely winding road, with excursions through mathematical biology, statistical physics, kinetic theory, bifurcation theory, and plasma physics."
"Gating charges in the activation and inactivation processes of the HERG channel.The hERG channel has a relatively slow activation process but an extremely fast and voltage-sensitive inactivation process. Direct measurement of hERG's gating current (Piper, D.R., A. Varghese, M.C. Sanguinetti, and M. Tristani-Firouzi. 2003. PNAS. 100:10534-10539) reveals two kinetic components of gating charge transfer that may originate from two channel domains. This study is designed to address three questions: (1) which of the six positive charges in hERG's major voltage sensor, S4, are responsible for gating charge transfer during activation, (2) whether a negative charge in the cytoplasmic half of S2 (D466) also contributes to gating charge transfer, and (3) whether S4 serves as the sole voltage sensor for hERG inactivation. We individually mutate S4's positive charges and D466 to cysteine, and examine (a) effects of mutations on the number of equivalent gating charges transferred during activation (z(a)) and inactivation (z(i)), and (b) sidedness and state dependence of accessibility of introduced cysteine side chains to a membrane-impermeable thiol-modifying reagent (MTSET). Neutralizing the outer three positive charges in S4 and D466 in S2 reduces z(a), and cysteine side chains introduced into these positions experience state-dependent changes in MTSET accessibility. On the other hand, neutralizing the inner three positive charges in S4 does not affect z(a). None of the charge mutations affect z(i). We propose that the scheme of gating charge transfer during hERG's activation process is similar to that described for the Shaker channel, although hERG has less gating charge in its S4 than in Shaker. Furthermore, channel domain other than S4 contributes to gating charge involved in hERG's inactivation process."
Hollywood Camera Movements and the Films of Howard Hawks: A Functional Semiotic Approach
"THE HULK, AN ANG LEE FILM"
"Systems biology markup language: Level 2 and beyond.The SBML (systems biology markup language) is a standard exchange format for computational models of biochemical networks. We continue developing SBML collaboratively with the modelling community to meet their evolving needs. The recently introduced SBML Level 2 includes several enhancements to the original Level 1, and features under development for SBML Level 3 include model composition, multistate chemical species and diagrams."
"The systems biology markup language (SBML): a medium for representation and exchange of biochemical network modelsMotivation: Molecular biotechnology now makes it possible to build elaborate systems models, but the systems biology community needs information standards if models are to be shared, evaluated and developed cooperatively."
"[Neuronal networks and memory: role of the hippocampus]Learning and memory are related both to cognitive processes and to neurobiological mechanisms. The human pathology focused on the role of the hippocampus and animal experiments have analyzed its implications. The most usually admitted hypothesis is that memories are underlied by distributed specific neural networks defined through the strengthening of certain synapses, under the action of the flow of information during learning. The best candidate for this strengthening of the synapses is a change in synaptic plasticity similar to the artificial phenomenon of long-term potentiation. During memory processes, the hippocampus would play a particular role in information processing (analyzing novelty and significance of the information) and would allow the specification of the neural network, mainly in the cortical territories. We report data in olfactory learning in rats comforting these hypotheses. Considering neurochemistry of memory processes, specific synaptic changes and neuromodulatory processes must be distinguished. We report data about vasopressin illustrating both kinds of mechanisms in the hippocampus."
Experiences in the use of a media space
"Scale-invariant statistics of period in directed earthquake networkA new law regarding structure of the earthquake networks is found. The seismic data taken in California is mapped to a growing directed network. Then, statistics of period in the network, which implies that after how many earthquakes an earthquake returns to the initial location, is studied. It is found that the period distribution obeys a power law, showing the fundamental difficulty of statistical estimate of period."
"MultiNeuron - Neural Networks Simulator For Medical, Physiological, and Psychological ApplicationsThis work describes neural software applied in medicine and physiology to: investigate and diagnose immune deficiencies; diagnose and study allergic and pseudoallergic reactions; forecast emergence or aggravation of stagnant cardiac insufficiency in patients with cardiac rhythm disorders; forecast development of cardiac arrhythmia after myocardial infarction; reveal relationships between the accumulated radiation dose and a set of immunological, hormonal, and bio-chemical parameters of human blood and find a method to be able to judge by these parameters the dose value; propose a technique for early diagnosis of chor-oid melanomas; Neural networks also help to predict human relations within a group."
"Opinion dynamics: rise and fall of political partiesWe analyze the evolution of political organizations using a model in which agents change their opinions via two competing mechanisms. Two agents may interact and reach consensus, and additionally, individual agents may spontaneously change their opinions by a random, diffusive process. We find three distinct possibilities. For strong diffusion, the distribution of opinions is uniform and no political organizations (parties) are formed. For weak diffusion, parties do form and furthermore, the political landscape continually evolves as small parties merge into larger ones. Without diffusion, a pattern develops: parties have the same size and they possess equal niches. These phenomena are analyzed using pattern formation and scaling techniques."
"Entropy Maximization as a Holistic Design Principle for Complex Optimal Networks and the Emergence of Power LawsWe present a general holistic theory for the organization of complex networks, both human-engineered and naturally-evolved. Introducing concepts of value of interactions and satisfaction as generic network performance measures, we show that the underlying organizing principle is to meet an overall performance target for wide-ranging operating or environmental conditions. This design or survival requirement of reliable performance under uncertainty leads, via the maximum entropy principle, to the emergence of a power law vertex degree distribution. The theory also predicts exponential or Poisson degree distributions depending on network redundancy, thus explaining all three regimes as different manifestations of a common underlying phenomenon within a unified theoretical framework."
"The similarity metricA new class of distances appropriate for measuring similarity relations between sequences, say one type of similarity per distance, is studied. We propose a new “normalized information distance”, based on the noncomputable notion of Kolmogorov complexity, and show that it is in this class and it minorizes every computable distance in the class (that is, it is universal in that it discovers all computable similarities). We demonstrate that it is a metric and call it the "
"Extracting useful information from noisy exponentially decaying signalAnalysing data that consists of one or more truncated exponential functions is of great interest in a wide range of fields. Data consisting of one or more exponential functions are measured by a wide range of instruments, examples include: nuclear magnetic resonance, (NMR); magnetic resonance imaging (MRI); the analysis of radioactive decay data; chromatography; lifetime fluorescence imaging; spin resonance, (ESR). Many of the algorithms that are currently in used for 'characterising' this data, are difficult to interpret or are they useless and they produce erroneous results. Some of the key technical issues associated with this problem are discussed in this article we also present some results that use some elementary properties of exponential properties of exponential and harmonic functions. These properties allow us to develop relationships between these functions which we exploit to analyse exponentially decaying signals in noisy environments"
"Statistics of infections with diversity in the pathogenicityThe statistics of outbreaks in a model for the propagation of meningococcal diseases is analyzed, taking into account the possibility that the population is fragmented into weakly connected patches. It is shown that, depending on the size of of the sample studied, the ratio between the variance and the mean of infected cases can vary from one (Poisson statistics) to the inverse of the infection rate."
"Coupling Josephson qubits via a current-biased information busJosephson qubits without direct interaction can be effectively coupled by sequentially connecting them to an information bus: a current-biased large Josephson junction treated as an oscillator with adjustable frequency. The coupling between any qubit and the bus can be controlled by modulating the magnetic flux applied to that qubit. This tunable and selective coupling provides two-qubit entangled states for implementing elementary quantum logic operations, and for experimentally testing Bell's inequality."
"Stock Price Clustering and Discreteness: The ""Compass Rose"" and PredictabilityIn this letter we investigate the information provided by the ""compass rose"" (Crack, T.F. and Ledoit, O. (1996), Journal of Finance, 51(2), pg. 751-762) patterns revealed in phase portraits of daily stock returns. It has been initially suggested that the compass rose is just a manifestation of price clustering and discreteness and the tick size, factors that can affect the unbiasedness of an array of statistical tests based on stock returns. We show that this may not entirely be the case."
"Introduction to Random Boolean NetworksThe goal of this tutorial is to promote interest in the study of random Boolean networks (RBNs). These can be very interesting models, since one does not have to assume any functionality or particular connectivity of the networks to study their generic properties. Like this, RBNs have been used for exploring the configurations where life could emerge. The fact that RBNs are a generalization of cellular automata makes their research a very important topic. The tutorial, intended for a broad audience, presents the state of the art in RBNs, spanning over several lines of research carried out by different groups. We focus on research done within artificial life, as we cannot exhaust the abundant research done over the decades related to RBNs."
"Power Law Tails in the Italian Personal Income DistributionWe investigate the shape of the Italian personal income distribution using microdata from the Survey on Household Income and Wealth, made publicly available by the Bank of Italy for the years 1977--2002. We find that the upper tail of the distribution is consistent with a Pareto-power law type distribution, while the rest follows a two-parameter lognormal distribution. The results of our analysis show a shift of the distribution and a change of the indexes specifying it over time. As regards the first issue, we test the hypothesis that the evolution of both gross domestic product and personal income is governed by similar mechanisms, pointing to the existence of correlation between these quantities. The fluctuations of the shape of income distribution are instead quantified by establishing some links with the business cycle phases experienced by the Italian economy over the years covered by our dataset."
"Navigation in a small world with local information It is commonly known that there exist short paths between vertices in a network showing the small-world effect. Yet vertices, for example, the individuals living in society, usually are not able to find the shortest paths, due to the very serious limit of information. To theoretically study this issue, here the navigation process of launching messages toward designated targets is investigated on a variant of the one-dimensional small-world network (SWN). In the network structure considered, the probability of a shortcut falling between a pair of nodes is proportional to $r^-α$, where $r$ is the lattice distance between the nodes. When $α =0$, it reduces to the SWN model with random shortcuts. The system shows the dynamic small-world (SW) effect, which is different from the well-studied static SW effect. We study the effective network diameter, the path length as a function of the lattice distance, and the dynamics. They are controlled by multiple parameters, and we use data collapse to show that the parameters are correlated. The central finding is that, in the one-dimensional network studied, the dynamic SW effect exists for $0≤ α ≤ 2$. For each given value of $α $ in this region, the point that the dynamic SW effect arises is $ML^′∼ 1$, where $M$ is the number of useful shortcuts and $L^′$ is the average reduced (effective) length of them."
"Pair Correlations in Scale-Free NetworksCorrelation between nodes is found to be a common and important property in many complex networks. Here we investigate degree correlations of the Barabasi-Albert (BA) Scale-Free model with both analytical results and simulations, and find two neighboring regions, a disassortative one for low degrees and a neutral one for high degrees. The average degree of the neighbors of a randomly picked node is expected to diverge in the limit of infinite network size. As an generalization of the concept of correlation, we also study the correlations of other scalar properties, including age and clustering coefficient. Finally we propose a correlation measurement in bipartite networks."
"Epidemic spread in weighted scale-free networksWe study the detailed epidemic spreading process in scale-free networks with links' weights that denote familiarity between two individuals. Experimental results show that spreading velocity reaches a peak quickly then decays in power-law form. Numerical study exhibits that the nodes with larger strength is preferential to be infected, but the hierarchical dynamics are not clearly found, which is different from the well-known result in unweighed network case."
"Fluctuation Statistics in Networks: a Stochastic Path Integral ApproachWe investigate the statistics of fluctuations in a classical stochastic network of nodes joined by connectors. The nodes carry generalized charge that may be randomly transferred from one node to another. Our goal is to find the time evolution of the probability distribution of charges in the network. The building blocks of our theoretical approach are (1) known probability distributions for the connector currents, (2) physical constraints such as local charge conservation, and (3) a time-scale separation between the slow charge dynamics of the nodes and the fast current fluctuations of the connectors. We derive a stochastic path integral representation of the evolution operator for the slow charges. Once the probability distributions on the discrete network have been studied, the continuum limit is taken to obtain a statistical field theory. We find a correspondence between the diffusive field theory and a Langevin equation with Gaussian noise sources, leading nevertheless to non-trivial fluctuation statistics. To complete our theory, we demonstrate that the cascade diagrammatics, recently introduced by Nagaev, naturally follows from the stochastic path integral. We extend the diagrammatics to calculate current correlation functions for an arbitrary network. One primary application of this formalism is that of full counting statistics (FCS). We stress however, that the formalism is suitable for general classical stochastic problems as an alternative to the traditional master equation or Doi-Peliti technique. The formalism is illustrated with several examples: both instantaneous and time averaged charge fluctuation statistics in a mesoscopic chaotic cavity, as well as the FCS and new results for a generalized diffusive wire."
"A Generalized Approach to Complex NetworksThis work reports on how the formalization of complex network concepts in terms of discrete mathematics, especially mathematical morphology, allows a series of generalizations and important results ranging from new measurements of the network topology to new network growth models. First, the concepts of node degree and clustering coefficient are extended in order to characterize not only specific nodes, but any generic subnetwork. Second, the consideration of distance transform and rings are used to further extend those concepts in order to obtain a signature, instead of a single scalar measurement, ranging from the single node to whole graph scales. The use of the closing operation is also proposed as a means to analyze the proximity of 3-cycles along a complex network. The potential of such concepts is illustrated with respect to the random and Barabási-Albert models, as well as distance-based preferential-attachment networks. A generalization of the Barabási-Albert network, characterized by preferential attachment with respect to the generalized degree, is also proposed and shown to exhibit properties which are intermediate between the Barabási-Albert and random models. Each of these cases is characterized and analyzed with respect to particularly relevant subnetworks contained in the original complex network, namely hubs, 3-cycles and outmost nodes."
"Predictability of large future changes in major financial indicesWe present a systematic algorithm testing for the existence of collective self-organization in the behavior of agents in social systems, with a concrete empirical implementation on the Dow Jones Industrial Average index (DJIA) over the 20th century and on Hong Kong Hang Seng composite index (HSI) since 1969. The algorithm combines ideas from critical phenomena, the impact of agents' expectation, multi-scale analysis and the mathematical method of pattern recognition of sparse data. Trained on the three major crashes in DJIA of the century, our algorithm exhibits a remarkable ability for generalization and detects in advance 8 other significant drops or changes of regimes. An application to HSI gives promising results as well. The results are robust with respect to the variations of the recognition algorithm. We quantify the prediction procedure with error diagrams."
"Complex networks of earthquakes and aftershocksWe invoke a metric to quantify the correlation between any two earthquakes. This provides a simple and straightforward alternative to using space-time windows to detect aftershock sequences and obviates the need to distinguish main shocks from aftershocks. Directed networks of earthquakes are constructed by placing a link, directed from the past to the future, between pairs of events that are strongly correlated. Each link has a weight giving the relative strength of correlation such that the sum over the incoming links to any node equals unity for aftershocks, or zero if the event had no correlated predecessors. Events can be aftershocks of many previous events, and also generate many aftershocks. The probability distribution for the number of incoming and outgoing links are both scale free, and the networks are highly clustered and modular. The Omori law holds for aftershock rates with a decorrelation time that grows with the magnitude of the initiating shock. Another scaling law is found for the fat-tailed distribution of distances between earthquakes and their aftershocks, which extends over the range covered by the catalogue, or hundreds of kilometers, even for intermediate magnitude events. This result is inconsistent with the hypothesis of aftershock zone scaling, but consistent with observations of remote triggering. We also find evidence that seismicity is dominantly triggered by small earthquakes. This approach, using concepts from the modern theory of complex networks, together with a metric to estimate correlations, opens up new avenues of research, as well as new tools to understand seismicity."
"Generation of uncorrelated random scale-free networks Uncorrelated random scale-free networks are useful null models to check the accuracy an the analytical solutions of dynamical processes defined on complex networks. We propose and analyze a model capable to generate random uncorrelated scale-free networks with no multiple and self-connections. The model is based on the classical configuration model, with an additional restriction on the maximum possible degree of the vertices. We check numerically that the proposed model indeed generates scale-free networks with no two and three vertex correlations, as measured by the average degree of the nearest neighbors and the clustering coefficient of the vertices of degree $k$, respectively."
"Conservation laws for the voter model in complex networksWe consider the voter model dynamics in random networks with an arbitrary distribution of the degree of the nodes. We find that for the usual node-update dynamics the average magnetization is not conserved, while an average magnetization weighted by the degree of the node is conserved. However, for a link-update dynamics the average magnetization is still conserved. For the particular case of a Barabasi-Albert scale-free network the voter model dynamics leads to a partially ordered metastable state with a finite size survival time. This characteristic time scales linearly with system size only when the updating rule respects the conservation law of the average magnetization. This scaling identifies a universal or generic property of the voter model dynamics associated with the conservation law of the magnetization."
"Naimark-Sacker Bifurcations in Linearly Coupled Quadratic Maps We report exact analytical expressions locating the $0\to1$, $1\to2$ and $2\to4$ bifurcation curves for a prototypical system of two linearly coupled quadratic maps. Of interest is the precise location of the parameter sets where Naimark-Sacker bifurcations occur, starting from a non-diagonal period-2 orbit. This result is the key to understand the onset of synchronization in networks of quadratic maps."
"Supply and Production Networks: From the Bullwhip Effect to Business CyclesNetwork theory is rapidly changing our understanding of complex systems, but the relevance of topological features for the dynamic behavior of metabolic networks, food webs, production systems, information networks, or cascade failures of power grids remains to be explored. Based on a simple model of supply networks, we offer an interpretation of instabilities and oscillations observed in biological, ecological, economic, and engineering systems. We find that most supply networks display damped oscillations, even when their units - and linear chains of these units - behave in a non-oscillatory way. Moreover, networks of damped oscillators tend to produce growing oscillations. This surprising behavior offers, for example, a new interpretation of business cycles and of oscillating or pulsating processes. The network structure of material flows itself turns out to be a source of instability, and cyclical variations are an inherent feature of decentralized adjustments. In particular, we show how to treat production and supply networks as transport problems governed by balance equations and equations for the adaptation of production speeds. The stability and dynamic behavior of supply networks is investigated for different topologies, including sequential supply chains, ""supply circles"", ""supply ladders"", and ""supply hierarchies"". Moreover, analytical conditions for absolute and convective instabilities are derived. The empirically observed bullwhip effect in supply chains is explained as a form of convective instability based on resonance effects. An application of this theory to the optimization of production networks has large optimization potentials."
"Endogenous Versus Exogenous Shocks in Complex Networks: an Empirical Test Using Book Sale RankingAre large biological extinctions such as the Cretaceous/Tertiary KT boundary due to a meteorite, extreme volcanic activity or self-organized critical extinction cascades? Are commercial successes due to a progressive reputation cascade or the result of a well orchestrated advertisement? Determining the chain of causality for extreme events in complex systems requires disentangling interwoven exogenous and endogenous contributions with either no clear or too many signatures. Here, we study the precursory and recovery signatures accompanying shocks, that we test on a unique database of the Amazon sales ranking of books. We find clear distinguishing signatures classifying two types of sales peaks. Exogenous peaks occur abruptly and are followed by a power law relaxation, while endogenous sale peaks occur after a progressively accelerating power law growth followed by an approximately symmetrical power law relaxation which is slower than for exogenous peaks. These results are rationalized quantitatively by a simple model of epidemic propagation of interactions with long memory within a network of acquaintances. The slow relaxation of sales implies that the sales dynamics is dominated by cascades rather than by the direct effects of news or advertisements, indicating that the social network is close to critical."
Minimizing the required memory bandwidth in VLSI system realizations
"Robustness in bacterial chemotaxis. Networks of interacting proteins orchestrate the responses of living cells to a variety of external stimuli, but how sensitive is the functioning of these protein networks to variations in their biochemical parameters? One possibility is that to achieve appropriate function, the reaction rate constants and enzyme concentrations need to be adjusted in a precise manner, and any deviation from these 'fine-tuned' values ruins the network's performance. An alternative possibility is that key properties of biochemical networks are robust; that is, they are insensitive to the precise values of the biochemical parameters. Here we address this issue in experiments using chemotaxis of Escherichia coli, one of the best-characterized sensory systems. We focus on how response and adaptation to attractant signals vary with systematic changes in the intracellular concentration of the components of the chemotaxis network. We find that some properties, such as steady-state behaviour and adaptation time, show strong variations in response to varying protein concentrations. In contrast, the precision of adaptation is robust and does not vary with the protein concentrations. This is consistent with a recently proposed molecular mechanism for exact adaptation, where robustness is a direct consequence of the network's architecture. "
The Weblog Handbook
"An outsider's view on ""topic-oriented blogging"""
Memory allocation and mapping in high-level synthesis
"Memory bank customization and assignment in behavioral synthesisWith increasing design complexity and chip area, on-chip memory has become an important component whose integration needs to be addressed during system design. Modern embedded DRAM technology allows for large amounts of on-chip memory space. However, in order to utilize the available memory intelligently, the memory has to be appropriately customized for the specific application. We address the topic of incorporating the application-specific customization of memory bank configuration into behavioral synthesis. The strategy involves a partitioning of behavioral arrays into memory banks based on a cost function that estimates the performance implications. For a given candidate partition, we present a heuristic for determining the access sequence that minimizes page misses in a bank while respecting data dependences. The output of the exploration is a graph displaying the variation of delay and memory area with the bank configuration. Our experiments on several memory-intensive examples confirm that the exploration results can provide critical feedback to the designer about the optimal memory configuration for a given application."
Architectural exploration and optimization of local memory in embedded systems
Sparse Functional Stores for Imperative Programs
GURRR: A Global Unified Resource Requirements Representation
The semantics of program dependence
Value Dependence Graphs: Representation Without Taxation
Semantics of programming languages: a tool-oriented approach
A complete transformational toolkit for compilers
A Simple Graph-Based Intermediate Representation
From Quads to Graphs: An Intermediate Representation 's Journey
"Saturated fatty acids synergize with elevated glucose to cause pancreatic beta-cell death.We have proposed the ""glucolipotoxicity"" hypothesis in which elevated free fatty acids (FFAs) together with hyperglycemia are synergistic in causing islet beta-cell damage because high glucose inhibits fat oxidation and consequently lipid detoxification. The effects of 1-2 d culture of both rat INS 832/13 cells and human islet beta-cells were investigated in medium containing glucose (5, 11, 20 mM) in the presence or absence of various FFAs. A marked synergistic effect of elevated concentrations of glucose and saturated FFA (palmitate and stearate) on inducing beta-cell death by apoptosis was found in both INS 832/13 and human islet beta-cells. In comparison, linoleate (polyunsaturated) synergized only modestly with high glucose, whereas oleate (monounsaturated) was not toxic. Treating cells with the acyl-coenzyme A synthase inhibitor triacsin C, or the AMP kinase activators metformin and 5-aminoimidazole-4-carboxamide-1-beta-D-ribofuranoside that redirect lipid partitioning to oxidation, curtailed glucolipotoxicity. In contrast, the fat oxidation inhibitor etomoxir, like glucose, markedly enhanced palmitate-induced cell death. The data indicate that FFAs must be metabolized to long chain fatty acyl-CoA to exert toxicity, the effect of which can be reduced by activating fatty acid oxidation. The results support the glucolipotoxicity hypothesis of beta-cell failure proposing that elevated FFAs are particularly toxic in the context of hyperglycemia."
"Glucose, other secretagogues, and nerve growth factor stimulate mitogen-activated protein kinase in the insulin-secreting beta-cell line, INS-1.The signaling pathways whereby glucose and hormonal secretagogues regulate insulin-secretory function, gene transcription, and proliferation of pancreatic beta-cells are not well defined. We show that in the glucose-responsive beta-cell line INS-1, major secretagogue-stimulated signaling pathways converge to activate 44-kDa mitogen-activated protein (MAP) kinase. Thus, glucose-induced insulin secretion was found to be associated with a small stimulatory effect on 44-kDa MAP kinase, which was synergistically enhanced by increased levels of intracellular cAMP and by the hormonal secretagogues glucagon-like peptide-1 and pituitary adenylate cyclase-activating polypeptide. Activation of 44-kDa MAP kinase by glucose was dependent on Ca2+ influx and may in part be mediated by MEK-1, a MAP kinase kinase. Stimulation of Ca2+ influx by KCl was in itself sufficient to activate 44-kDa MAP kinase and MEK-1. Phorbol ester, an activator of protein kinase C, stimulated 44-kDa MAP kinase by both Ca(2+)-dependent and -independent pathways. Nerve growth factor, independently of changes in cytosolic Ca2+, efficiently stimulated 44-kDa MAP kinase without causing insulin release, indicating that activation of this kinase is not sufficient for secretion. In the presence of glucose, however, nerve growth factor potentiated insulin secretion. In INS-1 cells, activation of 44-kDa MAP kinase was partially correlated with the induction of early response genes junB, nur77, and zif268 but not with stimulation of DNA synthesis. Our findings suggest a role of 44-kDa MAP kinase in mediating some of the pleiotropic actions of secretagogues on the pancreatic beta-cell."
"Palmitate inhibition of insulin gene expression is mediated at the transcriptional level via ceramide synthesis.Chronic exposure to elevated levels of fatty acids impairs pancreatic beta cell function, a phenomenon thought to contribute to the progressive deterioration of insulin secretion in type 2 diabetes. We have previously demonstrated that prolonged exposure of isolated islets to elevated levels of palmitate inhibits preproinsulin mRNA levels in the presence of high glucose concentrations. However, whether this occurs via transcriptional or post-transcriptional mechanisms has not been determined. In addition, the nature of the lipid metabolites involved in palmitate inhibition of insulin gene expression is unknown. In this study, we show that palmitate decreases glucose-stimulated preproinsulin mRNA levels in isolated rat islets, an effect that is not mediated by changes in preproinsulin mRNA stability, but is associated with inhibition of glucose-stimulated insulin promoter activity. Prolonged culture of isolated islets with palmitate is associated with increased levels of intracellular ceramide. Palmitate-induced ceramide generation is prevented by inhibitors of de novo ceramide synthesis. Further, exogenous ceramide inhibits insulin mRNA levels, whereas blockade of de novo ceramide synthesis prevents palmitate inhibition of insulin gene expression. We conclude that prolonged exposure to elevated levels of palmitate affects glucose-stimulated insulin gene expression via transcriptional mechanisms and ceramide synthesis."
"Monounsaturated fatty acids prevent the deleterious effects of palmitate and high glucose on human pancreatic beta-cell turnover and function.Glucotoxicity and lipotoxicity contribute to the impaired beta-cell function observed in type 2 diabetes. Here we examine the effect of saturated and monounsaturated fatty acids at different glucose concentrations on human beta-cell turnover and secretory function. Exposure of cultured human islets to saturated fatty acid and/or to an elevated glucose concentration for 4 days increased beta-cell DNA fragmentation and decreased beta-cell proliferation. In contrast, the monounsaturated palmitoleic acid or oleic acid did not affect DNA fragmentation and induced beta-cell proliferation. Moreover, each monounsaturated fatty acid prevented the deleterious effects of both palmitic acid and high glucose concentration. The cell-permeable ceramide analogue C(2)-ceramide mimicked both the palmitic acid-induced beta-cell apoptosis and decrease in proliferation. Furthermore, the ceramide synthetase inhibitor fumonisin B1 blocked the deleterious effects of palmitic acid on beta-cell turnover. In addition, palmitic acid decreased Bcl-2 expression and induced release of cytochrome c from the mitochondria into the cytosol, which was prevented by fumonisin B1 and by oleic acid. Finally, each monounsaturated fatty acid improved beta-cell secretory function that was reduced by palmitic acid and by high glucose. Thus, in human islets, the saturated palmitic acid and elevated glucose concentration induce beta-cell apoptosis, decrease beta-cell proliferation, and impair beta-cell function, which can be prevented by monounsaturated fatty acids. The deleterious effect of palmitic acid is mediated via formation of ceramide and activation of the apoptotic mitochondrial pathway, whereas Bcl-2 may contribute to the protective effect of monounsaturated fatty acids."
"Fatty acids, lipotoxicity and insulin secretion."
"Metformin restores insulin secretion altered by chronic exposure to free fatty acids or high glucose: a direct metformin effect on pancreatic beta-cells.Because metformin affects glucose and free fatty acid (FFA) metabolism in peripheral insulin target tissues, we investigated the effect of this drug in restoring a normal secretory pattern in rat pancreatic islets whose function has been impaired by chronic exposure to elevated FFA or glucose concentrations. We cultured rat pancreatic islets with or without FFA (2 mmol/l oleate/palmitate 2:1) or high glucose (16.7 mmol/l) concentrations in the presence or absence of metformin (0.25-12.5 microg/ml) and then measured insulin release, glucose utilization, glucose, and FFA oxidation. When compared with control islets, islets exposed to high FFA or glucose concentrations showed an increased basal and a decreased glucose-induced insulin release. In islets cultured for an additional 24 h with FFA or glucose in the presence of metformin (2.5 microg/ml), both basal and glucose-induced insulin secretions were restored. Both glucose utilization and glucose oxidation were altered in islets pre-exposed to high FFA or glucose concentrations. In particular, regarding control islets, glucose utilization was increased at 2.8 mmol/l glucose and decreased at 16.7 mmol/l glucose; glucose oxidation was similar to control islets at 2.8 mmol/l glucose but decreased at 16.7 mmol/l glucose. In contrast, oleate oxidation was increased in islets pre-exposed to FFA. All of these abnormalities were reversed in islets cultured for an additional 24 h with high FFA or glucose concentrations in the presence of metformin (2.5 microg/ml). In conclusion, our data show that metformin is able to restore the intracellular abnormalities of glucose and FFA metabolism and to restore a normal secretory pattern in rat pancreatic islets whose secretory function has been impaired by chronic exposure to elevated FFA or glucose levels. These data raise the possibility that, in diabetic patients, metformin (in addition to its peripheral effects) may have a direct beneficial effect on the beta-cell secretory function."
"Minireview: Secondary beta-cell failure in type 2 diabetes--a convergence of glucotoxicity and lipotoxicity. Chronic hyperglycemia and hyperlipidemia can exert deleterious effects on beta-cell function, respectively referred to as glucotoxicity and lipotoxicity. Over time, both contribute to the progressive deterioration of glucose homeostasis characteristic of type 2 diabetes. The mechanisms of glucotoxicity involve several transcription factors and are, at least in part, mediated by generation of chronic oxidative stress. Lipotoxicity is probably mediated by accumulation of a cytosolic signal derived from the fatty acid esterification pathway. Our view that hyperglycemia is a prerequisite for lipotoxicity is supported by several recent studies performed in our laboratories. First, prolonged in vitro exposure of isolated islets to fatty acids decreases insulin gene expression in the presence of high glucose concentrations only, and glucose is rate-limiting for the incorporation of fatty acids into neutral lipids. Second, normalization of blood glucose in Zucker diabetic fatty rats prevents accumulation of triglycerides and impairment of insulin gene expression in islets, whereas normalization of plasma lipid levels is without effect. Third, high-fat feeding in Goto-Kakizaki rats significantly impairs glucose-induced insulin secretion in vitro, whereas a similar diet has no effect in normoglycemic animals. We propose that chronic hyperglycemia, independent of hyperlipidemia, is toxic for beta-cell function, whereas chronic hyperlipidemia is deleterious only in the context of concomitant hyperglycemia. "
"Prevention of glucose toxicity in HIT-T15 cells and Zucker diabetic fatty rats by antioxidants.Chronic exposure of pancreatic islets to supraphysiologic concentrations of glucose causes adverse alterations in beta cell function, a phenomenon termed glucose toxicity and one that may play a secondary pathogenic role in type 2 diabetes. However, no mechanism of action has been definitively identified for glucose toxicity in beta cells. To ascertain whether chronic oxidative stress might play a role, we chronically cultured the beta cell line, HIT-T15, in medium containing 11.1 mM glucose with and without the antioxidants, N-acetyl-L-cysteine (NAC) or aminoguanidine (AG). Addition of NAC or AG to the culture medium at least partially prevented decreases in insulin mRNA, insulin gene promoter activity, DNA binding of two important insulin promoter transcription factors (PDX-1/STF-1 and RIPE-3b1 activator), insulin content, and glucose-induced insulin secretion. These findings suggested that one mechanism of glucose toxicity in the beta cell may be chronic exposure to reactive oxygen species, i.e., chronic oxidative stress. To ascertain the effects of these drugs on diabetes, NAC or AG was given to Zucker diabetic fatty rats, a laboratory model of type 2 diabetes, from 6 through 12 weeks of age. Both drugs prevented a rise in blood oxidative stress markers (8-hydroxy-2'-deoxyguanosine and malondialdehyde + 4-hydroxy-2-nonenal), and partially prevented hyperglycemia, glucose intolerance, defective insulin secretion as well as decrements in beta cell insulin content, insulin gene expression, and PDX-1 (STF-1) binding to the insulin gene promoter. We conclude that chronic oxidative stress may play a role in glucose toxicity, which in turn may worsen the severity of type 2 diabetes."
"Regulation of life and death by the zinc finger transcription factor Egr-1.The biosynthesis of the zinc finger transcription factor Egr-1 is stimulated by many extracellular signaling molecules including hormones, neurotransmitters, growth and differentiation factors, and cytotoxic metabolites. The 5'-flanking region of the Egr-1 gene contains genetic elements that are essential in connecting stimulation of the cells with enhanced transcription of the Egr-1 gene, and subsequently, transcription of Egr-1-responsive genes. Thus, Egr-1 links cellular signaling cascades with changes in the gene expression pattern. Many biological functions have been attributed to Egr-1. Here, we discuss evidence for Egr-1 control of cellular proliferation and programmed cell death."
Global Prevalence of DiabetesOBJECTIVE—The goal of this study was to estimate the prevalence of diabetes and the number of people of all ages with diabetes for years 2000 and 2030.
"Glucagon-like peptide-1 treatment delays the onset of diabetes in 8 week-old db/db mice.AIMS/HYPOTHESIS: Glucagon-like peptide-1 ameliorates the symptoms of diabetes through stimulation of insulin secretion and enhancement of beta-cell mass. We have therefore investigated the effects of glucagon-like peptide-1 on the development of diabetes, using db/db mice as a model of Type II diabetes. METHODS: The potent glucagon-like peptide-1 analogue Exendin-4 or vehicle (control) was administered (i.p.; 1 nmol/kg) to obese 6-week old db/db mice daily for 14 days ( n=10). RESULTS: By 8 weeks of age, control db/db mice developed hyperglycaemia (fasting: 10.4+/-0.5 mmol/l), hyperinsulinaemia and impaired glucose tolerance. However, Exendin-4 treatment prevented hyperglycaemia (fasting: 6.1+/-1.0 mmol/l, p<0.01), with reduced plasma insulin concentrations ( p<0.001) and improved glucose tolerance ( p<0.05). Peripheral insulin sensitivity was not affected. However, insulin release in vivo and in vitro from the perfused pancreas was improved by Exendin-4, as were pancreatic insulin concentrations (0.54+/-0.02 vs 0.32+/-0.01 micro g/mg protein, p<0.05). These changes occurred in conjunction with increased beta-cell mass (3.01+/-0.31 vs 2.22+/-0.22 mg, p<0.05) and proliferation (BrdU(+) beta-cells: 1.08+/-0.20 vs 0.47+/-0.11%, p<0.05), as well as decreased apoptosis (Tunel (+) beta-cells: 0.37+/-0.06 vs 1.20+/-0.21%). Western blot demonstrated increased expression of Akt1 (by fivefold, p<0.01) and p44 MAP kinase (by sixfold, p<0.01), and decreased activation of caspase-3 (by 30%, p<0.05). CONCLUSION/INTERPRETATION: Our results suggest that Ex4 treatment delays the onset of diabetes in 6-8 week old db/db mice, through a mechanism involving Akt1 and expansion of the functional beta-cell mass."
"Glucagon-like peptide-1 (7-36)amide and glucose-dependent insulinotropic polypeptide secretion in response to nutrient ingestion in man: acute post-prandial and 24-h secretion patterns.The acute effects of different macronutrients on the secretion of glucagon-like peptide-1(7-36)amide (GLP-1(7-36)amide) and glucose-dependent insulinotropic polypeptide (GIP) were compared in healthy human subjects. Circulating levels of the two hormones were measured over a 24-h period during which subjects consumed a mixed diet. In the first study, eight subjects consumed three equicaloric (375 kcal) test meals of carbohydrate, fat and protein. Small increases in plasma GLP-1(7-36) amide were found after all meals. Levels reached a maximum 30 min after the carbohydrate and 150 min after the fat load. Ingestion of both carbohydrate and fat induced substantial rises in GIP secretion, but the protein meal had no effect. In a second study, eight subjects consumed 75 g glucose or the equivalent portion of complex carbohydrate as boiled brown rice or barley. Plasma GIP, insulin and glucose levels increased after all three meals, the largest increase being observed following glucose and the smallest following the barley meal. Plasma GLP-1(7-36)amide levels rose only following the glucose meal. In the 24-h study, plasma GLP-1(7-36)amide and GIP concentrations were increased following every meal and remained elevated throughout the day, only falling to fasting levels at night. The increases in circulating GLP-1(7-36)amide and GIP levels following carbohydrate or a mixed meal are consistent with their role as incretins. The more sustained rises observed in the daytime during the 24-h study are consistent with an anabolic role in lipid metabolism."
"Expression cloning of the pancreatic beta cell receptor for the gluco-incretin hormone glucagon-like peptide 1. Glucagon-like peptide 1 (GLP-1) is a hormone derived from the preproglucagon molecule and is secreted by intestinal L cells. It is the most potent stimulator of glucose-induced insulin secretion and also suppresses in vivo acid secretion by gastric glands. A cDNA for the GLP-1 receptor was isolated by transient expression of a rat pancreatic islet cDNA library into COS cells; this was followed by binding of radiolabeled GLP-1 and screening by photographic emulsion autoradiography. The receptor transfected into COS cells binds GLP-1 with high affinity and is coupled to activation of adenylate cyclase. The receptor binds specifically GLP-1 and does not bind peptides of related structure and similar function, such as glucagon, gastric inhibitory peptide, vasoactive intestinal peptide, or secretin. The receptor is 463 amino acids long and contains seven transmembrane domains. Sequence homology is found only with the receptors for secretin, calcitonin, and parathyroid hormone, which form a newly characterized family of G-coupled receptors. "
"Enhancing incretin action for the treatment of type 2 diabetes.OBJECTIVE: To examine the mechanisms of action, therapeutic potential, and challenges inherent in the use of incretin peptides and dipeptidyl peptidase-IV (DPP-IV) inhibitors for the treatment of type 2 diabetes. RESEARCH DESIGN AND METHODS: The scientific literature describing the biological importance of incretin peptides and DPP-IV inhibitors in the control of glucose homeostasis has been reviewed, with an emphasis on mechanisms of action, experimental diabetes, human physiological experiments, and short-term clinical studies in normal and diabetic human subjects. RESULTS: Glucagon-like peptide 1 (GLP-1) and glucose-dependent insulinotropic peptide (GIP) exert important effects on beta-cells to stimulate glucose-dependent insulin secretion. Both peptides also regulate beta-cell proliferation and cytoprotection. GLP-1, but not GIP, inhibits gastric emptying, glucagon secretion, and food intake. The glucose-lowering actions of GLP-1, but not GIP, are preserved in subjects with type 2 diabetes. However, native GLP-1 is rapidly degraded by DPP-IV after parenteral administration; hence, degradation-resistant, long-acting GLP-1 receptor (GLP-1R) agonists are preferable agents for the chronic treatment of human diabetes. Alternatively, inhibition of DPP-IV-mediated incretin degradation represents a complementary therapeutic approach, as orally available DPP-IV inhibitors have been shown to lower glucose in experimental diabetic models and human subjects with type 2 diabetes. CONCLUSIONS: GLP-1R agonists and DPP-IV inhibitors have shown promising results in clinical trials for the treatment of type 2 diabetes. The need for daily injections of potentially immunogenic GLP-1-derived peptides and the potential for unanticipated side effects with chronic use of DPP-IV inhibitors will require ongoing scrutiny of the risk-benefit ratio for these new therapies as they are evaluated in the clinic."
Stimulation of release of insulin by an extract of intestinal mucosa.
"Role of apoptosis in failure of beta-cell mass compensation for insulin resistance and beta-cell defects in the male Zucker diabetic fatty rat. To define the mechanisms involved in the evolution of diabetes in the Zucker diabetic fatty (ZDF) rat, beta-cell mass and replication rates were determined by immunochemistry, point-counting morphometry, and 6-h 5-bromo-2'-deoxyuridine (BrdU) incorporation. The beta-cell mass in 5- to 7-week-old prediabetic ZDF rats (4.3 +/- 0.06 mg) was similar to age-matched insulin-resistant Zucker fatty (ZF) rats (3.7 +/- 0.05 mg) and greater than that in Zucker lean control (ZLC) rats (1.9 +/- 0.3, P < 0.05). At 12 weeks (after diabetes onset), beta-cell mass in the ZDF rats (8.1 +/- 1.7 mg) was significantly lower than the ZF rats (15.7 +/- 1.8 mg). The mass in the ZF rats was significantly greater than in the ZLC rats (4.3 +/- 0.8 mg, P < 0.05). The beta-cell proliferation rate (mean of both time points) was significantly greater in the ZDF rats (0.88 +/- 0.1%) compared with the ZF and ZLC rats (0.53 +/- 0.07%, 0.62 +/- 0.07%, respectively, P < 0.05), yet ZDF rats have a lower beta-cell mass than the ZF rats despite a higher proliferative rate. Morphological evidence of neogenesis and apoptosis is evident in the ZF and ZDF rats. In addition, even at 5-7 weeks a modest defect in insulin secretion per beta-cell unit was found by pancreas perfusion. These studies provide evidence that the expansion of beta-cell mass in response to insulin resistance and insulin secretory defects in diabetic ZDF rats is inadequate. This failure of beta-cell mass expansion in the ZDF rat does not appear to be from a reduction in the rate of beta-cell proliferation or neogenesis, suggesting an increased rate of cell death by apoptosis. "
"Malonyl-CoA signaling, lipid partitioning, and glucolipotoxicity: role in beta-cell adaptation and failure in the etiology of diabetes.Beta-cells possess inherent mechanisms to adapt to overnutrition and the prevailing concentrations of glucose, fatty acids, and other fuels to maintain glucose homeostasis. However, this is balanced by potentially harmful actions of the same nutrients. Both glucose and fatty acids may cause good/adaptive or evil/toxic actions on the beta-cell, depending on their concentrations and the time during which they are elevated. Chronic high glucose dramatically influences beta-cell lipid metabolism via substrate availability, changes in the activity and expression of enzymes of glucose and lipid metabolism, and modifications in the expression level of key transcription factors. We discuss here the emerging view that beta-cell ""glucotoxicity"" is in part indirectly caused by ""lipotoxicity,"" and that beta-cell abnormalities will become particularly apparent when both glucose and circulating fatty acids are high. We support the concept that elevated glucose and fatty acids synergize in causing toxicity in islets and other organs, a process that may be instrumental in the pleiotropic defects associated with the metabolic syndrome and type 1 and type 2 diabetes. The mechanisms by which hyperglycemia and hyperlipidemia alter insulin secretion are discussed and a model of beta-cell ""glucolipotoxicity"" that implicates alterations in beta-cell malonyl-CoA concentrations; peroxisome proliferator-activated receptor-alpha and -gamma and sterol regulatory element binding protein-1c expression; and lipid partitioning is proposed."
"Inhibition of mast cells by interleukin-10 gene transfer contributes to protection against acute myocarditis in rats.Progression of acute myocarditis involves a variety of inflammatory events. Mast cells have been implicated as the source of various cytokines, chemokines and histamine in acute inflammation and fibrosis. Interleukin (IL)-10 has well-known immunomodulatory actions that are exerted during the recovery phase of myocarditis. In this study, 9-week-old male Lewis rats were immunized with cardiac myosin. A plasmid vector expressing mouse IL-10 cDNA (800 mug per rat) was then transferred three times (7, 12 and 17 days after immunization) into the tibialis anterior muscles of the rats by electroporation. Microscopic examination of mast cells was carried out on toluidine blue-stained transverse sections of the mid ventricles. Mouse IL-10 gene transfer significantly reduced mast cell density, cardiac histamine concentration and mast cell growth, and prevented mast cell degranulation. Furthermore, improvement in both myocardial function and the overall condition of the rats was evident from the reduction in the heart weight-to-body weight ratio and inflammatory infiltration as well as improvement in hemodynamic and echocardiographic parameters. These findings suggest that IL-10 gene transfer by electroporation protected against myocarditis via mast cell inhibition."
"Glucagon-like peptide 1 inhibits cell apoptosis and improves glucose responsiveness of freshly isolated human islets.The peptide hormone, glucagon-like peptide 1 (GLP-1), has been shown to increase glucose-dependent insulin secretion, enhance insulin gene transcription, expand islet cell mass, and inhibit beta-cell apoptosis in animal models of diabetes. The aim of the present study was to evaluate whether GLP-1 could improve function and inhibit apoptosis in freshly isolated human islets. Human islets were cultured for 5 d in the presence, or absence, of GLP-1 (10 nm, added every 12 h) and studied for viability and expression of proapoptotic (caspase-3) and antiapoptotic factors (bcl-2) as well as glucose-dependent insulin production. We observed better-preserved three-dimensional islet morphology in the GLP-1-treated islets, compared with controls. Nuclear condensation, a feature of cell apoptosis, was inhibited by GLP-1. The reduction in the number of apoptotic cells in GLP-1-treated islets was particularly evident at d 3 (6.1% apoptotic nuclei in treated cultures vs. 15.5% in controls; P < 0.01) and at d 5 (8.9 vs. 18.9%; P < 0.01). The antiapoptotic effect of GLP-1 was associated with the down-regulation of active caspase-3 (P < 0.001) and the up-regulation of bcl-2 (P < 0.01). The effect of GLP-1 on the intracellular levels of bcl-2 and caspase-3 was observed at the mRNA and protein levels. Intracellular insulin content was markedly enhanced in islets cultured with GLP-1 vs. control (P < 0.001, at d 5), and there was a parallel GLP-1-dependent potentiation of glucose-dependent insulin secretion (P < 0.01 at d 3; P < 0.05 at d 5). Our findings provide evidence that GLP-1 added to freshly isolated human islets preserves morphology and function and inhibits cell apoptosis."
Sex-Crime and its Socio-Historical Background
Referral Web: Combining Social Networks and Collaborative Filtering
Differential diffusion: an oceanographic primer
"What makes biochemical networks tick?In view of the increasing number of reported concentration oscillations in living cells, methods are needed that can identify the causes of these oscillations. These causes always derive from the influences that concentrations have on reaction rates. The influences reach over many molecular reaction steps and are defined by the detailed molecular topology of the network. So-called ‘autoinfluence paths’, which quantify the influence of one molecular species upon itself through a particular path through the network, can have positive or negative values. The former bring a tendency towards instability. In this molecular context a new graphical approach is presented that enables the classification of network topologies into oscillophoretic and nonoscillophoretic, i.e. into ones that can and ones that cannot induce concentration oscillations. The network topologies are formulated in terms of a set of uni-molecular and bi-molecular reactions, organized into branched cycles of directed reactions, and presented as graphs. Subgraphs of the network topologies are then classified as negative ones (which can) and positive ones (which cannot) give rise to oscillations. A subgraph is oscillophoretic (negative) when it contains more positive than negative autoinfluence paths. Whether the former generates oscillations depends on the values of the other subgraphs, which again depend on the kinetic parameters. An example shows how this can be established. By following the rules of our new approach, various oscillatory kinetic models can be constructed and analyzed, starting from the classified simplest topologies and then working towards desirable complications. Realistic biochemical examples are analyzed with the new method, illustrating two new main classes of oscillophore topologies."
"Searching in small-world networks.We study the average time it takes to find a desired node in the Watts-Strogatz family of networks. We consider the case when the look-up time can be neglected and when it is important, where the look-up time is the time needed to choose one among all the neighboring nodes of a node at each step in the search. We show that in both cases, the search time is minimum in the small-world regime, when an appropriate distance between the nodes is defined. Through an analytical model, we show that the search time scales as N(1/D(D+1)) for small-world networks, where N is the number of nodes and D is the dimension of the underlying lattice. This model is shown to be in agreement with numerical simulations."
Defining statistical ensembles of random graphsThe problem of defining a statistical ensemble of random graphs with an arbitrary connectivity distribution is discussed. Introducing such an ensemble is a step towards uderstanding the geometry of wide classes of graphs independently of any specific model. This research was triggered by the recent interest in the so-called scale-free networks.
"Nonlinear Barabasi-Albert networkIn recent years there has been considerable interest in the structure and dynamics of complex networks. One of the most studied networks is the linear Barabasi-Albert model. Here we investigate the nonlinear Barabasi-Albert growing network. In this model, a new node connects to a vertex of degree k with a probability proportional to k[alpha] ([alpha] real). Each vertex adds m new edges to the network. We derive an analytic expression for the degree distribution P(k) which is valid for all values of m and [alpha][les]1. In the limit [alpha]->-[infin] the network is homogeneous. If [alpha]>1 there is a gel phase with m super-connected nodes. It is proposed a formula for the clustering coefficient which is in good agreement with numerical simulations. The assortativity coefficient r is determined and it is shown that the nonlinear Barabasi-Albert network is assortative (disassortative) if [alpha]1) and no assortative only when [alpha]=1. In the limit [alpha]->-[infin] the assortativity coefficient can be exactly calculated. We find when m=2. Finally, the minimum average shortest path length lmin is numerically evaluated. Increasing the network size, lmin diverges for [alpha][les]1 and it is equal to 1 when [alpha]>1."
"Strong links are important, but weak links stabilize them."
"Critical brain networks*1Highly correlated brain dynamics produces synchronized states with no behavioral value, while weakly correlated dynamics prevents information flow. We discuss the idea put forward by Per Bak that the working brain stays at an intermediate (critical) regime characterized by power-law correlations."
"Robustness of Cellular FunctionsRobustness, the ability to maintain performance in the face of perturbations and uncertainty, is a long-recognized key property of living systems. Owing to intimate links to cellular complexity, however, its molecular and cellular basis has only recently begun to be understood. Theoretical approaches to complex engineered systems can provide guidelines for investigating cellular robustness because biology and engineering employ a common set of basic mechanisms in different combinations. Robustness may be a key to understanding cellular complexity, elucidating design principles, and fostering closer interactions between experimentation and theory."
"The Protein Folding NetworkThe conformation space of a 20 residue antiparallel β-sheet peptide, sampled by molecular dynamics simulations, is mapped to a network. Snapshots saved along the trajectory are grouped according to secondary structure into nodes of the network and the transitions between them are links. The conformation space network describes the significant free energy minima and their dynamic connectivity without requiring arbitrarily chosen reaction coordinates. As previously found for the Internet and the World-Wide Web as well as for social and biological networks, the conformation space network is scale-free and contains highly connected hubs like the native state which is the most populated free energy basin. Furthermore, the native basin exhibits a hierarchical organization, which is not found for a random heteropolymer lacking a predominant free-energy minimum. The network topology is used to identify conformations in the folding transition state (TS) ensemble, and provides a basis for understanding the heterogeneity of the TS and denatured state ensemble as well as the existence of multiple pathways."
"Efficient sampling algorithm for estimating subgraph concentrations and detecting network motifsSummary: Biological and engineered networks have recently been shown to display network motifs: a small set of characteristic patterns that occur much more frequently than in randomized networks with the same degree sequence. Network motifs were demonstrated to play key information processing roles in biological regulation networks. Existing algorithms for detecting network motifs act by exhaustively enumerating all subgraphs with a given number of nodes in the network. The runtime of such algorithms increases strongly with network size. Here, we present a novel algorithm that allows estimation of subgraph concentrations and detection of network motifs at a runtime that is asymptotically independent of the network size. This algorithm is based on random sampling of subgraphs. Network motifs are detected with a surprisingly small number of samples in a wide variety of networks. Our method can be applied to estimate the concentrations of larger subgraphs in larger networks than was previously possible with exhaustive enumeration algorithms. We present results for high-order motifs in several biological networks and discuss their possible functions.Availability: A software tool for estimating subgraph concentrations and detecting network motifs (mfinder 1.1) and further information is available at http://www.weizmann.ac.il/mcb/UriAlon/"
"Path finding strategies in scale-free networks.We numerically investigate the scale-free network model of Barabási and Albert [A. L. Barabási and R. Albert, Science 286, 509 (1999)] through the use of various path finding strategies. In real networks, global network information is not accessible to each vertex, and the actual path connecting two vertices can sometimes be much longer than the shortest one. A generalized diameter depending on the actual path finding strategy is introduced, and a simple strategy, which utilizes only local information on the connectivity, is suggested and shown to yield small-world behavior: the diameter D of the network increases logarithmically with the network size N, the same as is found with global strategy. If paths are sought at random, D is equivalent to N(0.5) is found."
"Groupware adoption in a distributed organization: transporting and transforming technology through social worldsIn this paper, we draw on theory from social worlds to analyze how different organizational contexts affect groupware adoption. We report on a study of the adoption of data conferencing in a large distributed organization. Our data show that the diffusion process, which was driven by the users, was a result of communication and transformation of the technology across different social worlds. We also discovered that membership in multiple social worlds in an organization creates a tension for the potential adopter who is in a distributed team. To function effectively, team members must uniformly adopt the technology, yet some may face resistance from other social worlds to which they belong. Our study showed that adoption was affected by organizational sites having conflicting views of the value of collaboration, different amounts and needs for resources, and different acceptance of technology standards. Potential technology adopters on distributed teams are faced with conflicting loyalties, constraints, and requirements between their distributed collaborations and organizational homes."
"Is designing mysterious? challenging the dual knowledge thesisThe hermeneutical philosophy of Gadamer and Heidegger and the pragmatism of Dewey are brought to bear in arguing against the view that designing involves a special kind of knowledge that is fundamentally difficult to grasp and therefore mysterious. The hermeneutical thesis maintains that understanding is acquired in a manner best described in terms of bringing expectations to bear on a situation. These expectations are derived from our effective historical consciousness and are constantly being renewed as we respond to situations. This mode of thinking is the only way of thinking, whether we are solving a mathematical problem or creating a work of art. Not withstanding this 'common sense' understanding, claims for the mystery of designing persist. These claims are examined in turn in the light of a hermeneutical understanding of thought. They include the dual knowledge thesis, the more fundamental notion of the thinking subject isolated from the world of objects, and the subjectivism of the Romantic movement that is evident in writings about the genius loci. There is then a consideration of the sense in which it is appropriate to talk about designing as being different to other activities and how this impinges on design teaching and practice. The argument is presented that when mystery is removed then effective dialogue, and hence learning, can ensue."
"Discourse, organizations and national culturesThe article explores the complex and multi-dimensional relationship between organization and discourse, using interview data and written documents collected within banks in Sweden, Germany and Britain. The first part of the analysis, which examines the extent to which the organizations studied can be said to form discourse units in their own right, shows that management ideas, norms and values seem to have a considerable impact on bank discourse. Although the discourse found in different banks naturally has many features in common, each organization is found to be created at least partly differently by its discourse. Analyses of sender markings, expressive illocutions and expressions of thanks to the staff show how discourse is part of the construction of an organizational culture in relation to ideas concerning leadership, hierarchy, centralization etc. The second part of the analysis focuses on the role of the national community in the formation of an organization. An analysis of the bank images disseminated in spoken discourse and documents points to differences which could be attributed to national cultural patterns. The interview data further show how much effort is devoted to internally and externally disseminated images; this could be seen as a sign of an awareness among management of the decisive role of the spoken and written word for their company."
"Design as bricolage: anthropology meets design thinkingWe identify a metaphor for the design activity: we view design as bricolage. We start from describing bricolage, and we proceed to the relationship of design to art. We obtain a characterisation of design that enables us to show that both traditional and contemporary design are forms of bricolage. We examine the consequences of `design as bricolage' for the relationship between design and science and for the extent of the design activity."
Footprints: History-Rich Tools for Information Foraging
"Roles of Mesoscale Eddies in the Kuroshio PathsA high-resolution ocean general circulation model is developed to simulate connections between the Kuroshio path variations and mesoscale eddy activities as realistically as possible. The climatological mean of the modeled Kuroshio takes a nearshore nonlarge meander path. It is found that the model is capable of simulating two types of nonlarge meander state and a possible version of the large meander state. The offshore nonlarge meander is generated through interaction between the Kuroshio and an anticyclonic eddy. The large meander occurs just after significant intensification of the anticyclonic Kuroshio recirculation; successive intrusion of anticyclonic eddies from the upstream region is responsible for this process. Those anticyclonic eddies are advected by the Kuroshio from the region northeast of Luzon Island and increase the upstream Kuroshio volume transport on an interannual time scale. The cyclonic eddies propagating from the Kuroshio Extension region, on the other hand, weaken the Kuroshio meander after the merger. The Kuroshio path variations south of Japan thus seem to be closely related to eddy activities in the subtropical gyre system."
"Large-Scale Variability in the Midlatitude Subtropical and Subpolar North Pacific Ocean: Observations and CausesAltimetric data from the 8-yr TOPEX/Poseidon (T/P) mission (Oct 1992–Jul 2000) are used to investigate large-scale circulation changes in the three current systems of the midlatitude North Pacific Ocean: the North Pacific Current (NPC), the Alaska gyre, and the western subarctic gyre (WSG). To facilitate the understanding of the observed changes, a two-layer ocean model was adopted that includes first-mode baroclinic Rossby wave dynamics and barotropic Sverdrup dynamics. The NPC intensified steadily over the T/P period from 1992 to 1998. Much of this intensification is due to the persistent sea surface height (SSH) drop on the northern side of the NPC. A similar SSH trend is also found in the interior of the Alaska gyre. Both of these SSH changes are shown to be the result of surface wind stress curl forcing accumulated along the baroclinic Rossby wave characteristics initiated from the eastern boundary. In addition to the interior SSH signals, the intensity of the Alaska gyre is shown to depend also on the SSH anomalies along the Canada/Alaska coast, and these anomalies are shown to be jointly determined by the signals propagating from lower latitudes and those forced locally by the alongshore surface winds. The WSG changed interannually from a zonally elongated gyre in 1993–95 to a zonally more contracted gyre in 1997–99. This structural change is due to the interannual SSH anomalies within the WSG as a result of the baroclinic Rossby wave adjustment attenuated by eddy dissipation. Along the western boundary of the subpolar North Pacific, variability of the East Kamchatka Current (EKC) and Oyashio is in balance with that of the interior Sverdrup flow on the annual and year-to-year timescales. On the multiyear timescales, the EKC/Oyashio variability is shown to be determined by the baroclinic SSH signals."
"Seasonal Eddy Field Modulation of the North Pacific Subtropical Countercurrent: TOPEX/Poseidon Observations and TheoryAltimetry data from the first 5¼-yr TOPEX/Poseidon mission (October 1992–December 1997) are analyzed focusing on the North Pacific Subtropical Countercurrent (STCC) near the center of the Pacific’s western subtropical gyre. The multiyear altimetry data reveal that the eastward-flowing STCC is a highly variable zonal current, whose area-averaged eddy kinetic energy level (338 cm"
"Interannual Variability of the Kuroshio Extension System and Its Impact on the Wintertime SST FieldAltimetry data from the first 7-yr TOPEX/Poseidon (T/P) mission (October 1992–September 1999) are analyzed to investigate the interannual variability in regions of the Kuroshio Extension and its southern recirculation gyre. Large-scale, interannual changes of the Kuroshio Extension system are characterized by the oscillation between an elongated state and a contracted state. In the elongated state, the Kuroshio Extension has a larger eastward surface transport, a greater zonal penetration, and a more northerly zonal-mean path. All these characteristics are closely connected to the presence of an intense, zonally elongated southern recirculation gyre. In its contracted state, the Kuroshio Extension has a smaller eastward surface transport, a more southerly mean path, and is accompanied by a weaker southern recirculation gyre. During the T/P period, the Kuroshio Extension changed from the elongated state in 1992–93 to the contracted state in 1996–97, and back to the elongated state since late 1997."
"Upper-Ocean Heat Balance in the Kuroshio Extension RegionA horizontally two-dimensional mixed-layer model is used to study the upper-ocean heat balance in the Kuroshio Extension region (30°–40°N, 141°–175°E). Horizontal dependency is emphasized because, in addition to vertical entrainment and surface thermal forcing, horizontal advection and eddy diffusion make substantial contributions to changes in the upper-ocean thermal structure in this region. By forcing the model using the wind and heat flux data from ECMWF and the absolute sea surface height data deduced from the Geosat ERM, the mixed-layer depth ("
"Biharmonic Friction with a Smagorinsky-Like Viscosity for Use in Large-Scale Eddy-Permitting Ocean ModelsThis paper discusses a numerical closure, motivated from the ideas of Smagorinsky, for use with a biharmonic operator. The result is a highly scale-selective, state-dependent friction operator for use in eddy-permitting geophysical fluid models. This friction should prove most useful for large-scale ocean models in which there are multiple regimes of geostrophic turbulence. Examples are provided from primitive equation geopotential and isopycnal-coordinate ocean models."
Kuroshio Extension Variability and Forcing of the Pacific Decadal Oscillations: Responses and Potential FeedbackA forcing mechanism is sought for the large-scale circulation changes in the Kuroshio Extension region of the western North Pacific Ocean as inferred by TOPEX/Poseidon sea surface height (SSH) data. The low-frequency signal of the Kuroshio Extension over the last decade was characterized by a modulation in its zonal mean flow intensity: the mean Kuroshio Extension jet weakened progressively from 1993 to 1996 and this trend reversed after 1997. The ability to simulate the major trends in the observed SSH signals with linear vorticity dynamics leads the authors to conclude that the modulation in the zonal mean jet was remotely forced by wind stress curl anomalies in the 
"Coupling of Extratropical Mesoscale Eddies in the Ocean to Westerly Winds in the Atmospheric Boundary LayerThe sea surface temperature (SST) signature in mesoscale eddies in the western boundary current extensions around the globe and in the Antarctic Circumpolar Current are found to alter the surface stress associated with background westerly winds, producing wind stress curl (WSC) residuals of eddy scale that are capable of modifying the eddy dynamics. This is revealed by examining satellite-derived mesoscale sea level height (SLH), SST, and neutrally stable zonal surface wind (ZSW) residuals together for 18 months. In the presence of background westerly winds on basin scales, warm mesoscale eddies reduce the stability of the marine atmospheric boundary layer, increasing the zonal air–sea momentum flux measured by satellite scatterometry. Warm SST residuals of "
"Nigella sativa seed extracts enhance glucose-induced insulin release from rat-isolated Langerhans islets.Nigella sativa L. 'Black cumin' (Ranunculaceae) is one of the plants commonly used in Moroccan folk medicine for treatment of various ailments including diabetes mellitus. The present study was undertaken to investigate the effect of different N. sativa seed extracts on insulin secretion. Different fractions of the seed were prepared: the defatted fraction (HR II), which was divided into two subfractions: the first (HR III) containing acidic and neutral compounds and the second (HR IV) containing basic compounds. The insulin secretory effects of these extracts were evaluated individually at different concentrations (0.01, 0.1, 1 and 5 mg/mL), in vitro in isolated rat pancreatic islets in the presence of 8.3 mmol/L glucose. The results show that addition of the defatted whole extract or of the basic subfraction of the seed in the incubation medium significantly increased glucose-induced insulin release from the islets. In the case of the acidic and neutral subfraction, the stimulatory effect was observed only for the higher concentration (5 mg/mL). However, a clear concentration-dependent increase in insulin release from isolated pancreatic islets was observed for the basic subfraction. Our data show that the antidiabetic properties of N. sativa seeds may be, at least partly, mediated by stimulated insulin release, and that the basic subfraction largely contributes to this stimulatory effect. Further phytochemical studies are underway in order to isolate the pharmacological compound(s) responsible for the insulinotropic effect of N. sativa seeds."
"Nigellamines A3, A4, A5, and C, new dolabellane-type diterpene alkaloids, with lipid metabolism-promoting activities from the Egyptian medicinal food black cumin.New dolabellane-type diterpene alkaloids, nigellamines A(3), A(4), A(5), and C, were isolated from the methanolic extract of an Egyptian medicinal food, black cumin (the seeds of Nigella sativa). Their absolute configurations were determined on the basis of chemical and physicochemical evidence. Nigellamines were found to lower triglyceride levels in primary cultured mouse hepatocytes, and in particular, the activity of nigellamine A(5) was equivalent to that of the hypolipidemic agent, clofibrate."
"Partial regeneration/proliferation of the beta-cells in the islets of Langerhans by Nigella sativa L. in streptozotocin-induced diabetic rats.This experiment was carried out to investigate the effect of N. sativa L. on histopathology of pancreatic beta-cells, and blood insulin and glucose concentrations in streptozotocin-induced diabetic rats. Fifty male Wistar rats (200-250 g) were divided into two experimental groups (diabetics with no treatment and diabetics with N. sativa L. treatment), each containing twenty-five rats. Diabetes was induced in both groups by a single intraperitoneal injection of streptozotocin (STZ) (50 mg/kg). The experimental animals in both groups became diabetic within 24 hours after the administration of STZ. The rats in N. sativa L.-treated group were given the daily intraperitoneal injection of 0.20 ml/kg of N. sativa L. volatile oil for 30 days starting the day after STZ injection. Control rats received only the same amount of normal saline solution. The rats in both groups received the last injection 24 hours before the sacrification and 5 randomly-selected rats in each group were sacrificed before, and the 1, 10, 20 and 30 days after the STZ injection to collect blood and pancreatic tissue samples. The N. sativa L. treatment caused a decrease in the elevated serum glucose, an increase in the lowered serum insulin concentrations and partial regeneration/ proliferation of pancreatic beta-cells in STZ-induced diabetic rats with the elapse of the experiment. It is concluded that the hypoglycaemic action of N. sativa L. could be partly due to amelioration in the beta-cells of pancreatic islets causing an increase in insulin secretion. More studies are needed to demonstrate the exact mechanism of action of N. sativa L. on ameliorated blood glucose concentration in STZ-induced diabetes."
"Protection against diethylnitrosoamine-induced hepatocarcinogenesis by an indigenous medicine comprised of Nigella sativa, Hemidesmus indicus and Smilax glabra: a preliminary study.BACKGROUND: A decoction comprised of Nigella sativa seeds, Hemidesmus indicus root and Smilax glabra rhizome is used to treat cancer patients in Sri Lanka. However, the anti-carcinogenic properties of this decoction have not been experimentally confirmed. The purpose of this study was to determine whether the above decoction could protect against chemically induce hepatocarcinogenesis. METHODS: The effects of this decoction on diethylnitrosamine (DEN) induced hepatocarcinogenesis were examined in male Wistar rats using the medium term bioassay system of Ito, based on a 2-step model of hepatocarcinogenesis. Rats were randomly divided into 6 groups of 10 each. Groups 1 to 4 were injected with DEN (200 mg/kg) to initiate carcinogenesis. Twenty-four hours later groups 1 and 2 were administered the decoction at 4 g/kg body weight/day (dose 1) and 6 g/kg body weight/day (dose 2), respectively. Group 3 and group 4 were given distilled water instead of the decoction and a suspension of garlic powder (20 g/kg body weight/day) in distilled water (positive control), respectively. Group 5 and 6 were injected with normal saline and twenty-four hours later group 5 was given distilled water (normal control) while group 6 was given decoction dose 2 (decoction control). Oral feeding continued for two weeks after which all rats were subjected to 2/3 partial hepatectomy to promote carcinogenesis. Oral feeding continued for eight more weeks. At the end of the 10th week, rats were sacrificed and samples of livers taken for immunohistochemical studies.Carcinogenic potential was scored by comparing the number, area and staining intensity of glutathione S-transferase placental form (GST-P) positive foci and the number of cells/cm2 of the positive foci in the livers of the six groups of rats. RESULTS: The number and area of DEN-mediated GST-P positive foci, number of cells/cm2 of foci and staining intensity of the foci were significantly (P > 0.001) reduced by the decoction and garlic in the order dose 2 = garlic >dose 1. CONCLUSION: Overall results indicate that the decoction comprised of N. sativa, S. glabra and H. indicus has the potential to protect rat liver against DEN induced hepatocarcinogenesis"
"Possible mechanism(s) for relaxant effect of aqueous and macerated extracts from Nigella sativa on tracheal chains of guinea pig.BACKGROUND: In previous studies, the relaxant, anticholinergic (functional antagonism) and antihistaminic effects of Nigella sativa have been demonstrated on guinea pig tracheal chains. To elucidate the other mechanisms responsible for the relaxant effect of this plant, its inhibitory effect on the calcium channel was examined in this study. RESULTS: The inhibitory effects of both concentrations of diltiazem in all three groups of experiments were significantly greater than those of saline (p < 0.01 to P < 0.001). The inhibitory of two larger concentrations of aqueous extracts in group 1 and 2 were significantly greater than those of saline (p < 0.01 to P < 0.001). The effect of two larger concentrations of macerated extract in group 1 and all concentrations of this extract in group 2 were also significantly greater than those of saline (p < 0.01 to P < 0.001). However, the extract of Nigella sativa did not show any inhibitory effect in group 3. There was a significant correlation between inhibitory effect and increasing concentrations for both extracts and diltiazem in groups 1 and 2 (p < 0.05 to p < 0.005). CONCLUSION: Although the extracts of Nigella sativa showed inhibitory effects on pre-contracted tracheal chains in the presence of both ordinary and calcium free Krebs solution, the absence of inhibitory effects of the extracts on KCl induced contraction of tracheal chains suggest that the calcium channel blocking effect of this plant dose not contribute to the relaxant effect of this plant on the tracheal chains of guinea pigs."
"Recent advances in the development of HIV-1 Tat-based vaccines.Over the last two decades most of the efforts in HIV vaccine development have been based on the use of the HIV Env with the goal to induce sterilizing immunity. However, as a result of Env variability disappointing results have been obtained in preclinical and phase III clinical trials. Although the objective of a preventive immunity still remains a priority, secondary endpoints (e.g. block of virus replication and disease onset) are being considered at the present as more achievable end-points in HIV vaccine development. This is based on accumulating evidence indicating that low viral load correlates with maintenance of immune functions and slow progression to disease, and that cell-mediated immunity plays a major protective role in the absence of sterilizing immunity. The promising results obtained in non-human primates with a vaccine based on a native Tat protein (B-clade), which is an early regulatory protein key for HIV replication and AIDS pathogenesis, highlights the importance of targeting the virus very early after infection. In particular, the immune response against Tat appears to modify the virus-host interactions at the very beginning of infection, thus containing the depletion of critical immune cells and the progression of infection. Moreover, since Tat targets and induces maturation of dendritic cells, has immunomodulatory activities and drives Th-1 and CTL responses, immunization with Tat may drive or increase these immune responses also against other HIV antigens to support an effective, long-lasting and hopefully even sterilizing antiviral immunity. Finally, Tat B-clade is similarly recognized by sera from individuals infected by different virus clades (A, B, C, D) supporting the concept of a cross-clade vaccine. Therefore, the Tat-vaccine should contain virus replication protecting from disease progression (non-sterilizing immunity) or even favoring an abortive infection. Although only a phase III clinical trial will establish the efficacy of this vaccine strategy, the Tat-vaccine has recently entered preventive and therapeutic phase I clinical testing in Italy to establish safety (primary-end-point) and immunogenicity (secondary end-point) and phase II studies are being prepared."
"The anatomy of a large-scale hypertextual Web search engineIn this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at"
"Searching the workplace webThe social impact from the World Wide Web cannot be underestimated, but technologies used to build the Web are also revolutionizing the sharing of business and government information within intranets. In many ways the lessons learned from the Internet carry over directly to intranets, but others do not apply. In particular, the social forces that guide the development of intranets are quite di#erent, and the determination of a ""good answer"" for intranet search is quite di#erent than on the..."
"Insulin resistance, defective insulin receptor substrate 2-associated phosphatidylinositol-3' kinase activation, and impaired atypical protein kinase C (zeta/lambda) activation in myotubes from obese patients with impaired glucose tolerance.Impaired glucose tolerance (IGT) is characterized by insulin resistance. Recently, defects in the insulin-signaling cascade have been implicated in the pathogenesis of insulin resistance. To study insulin signaling in IGT, we used human skeletal muscle cells in primary culture from patients with IGT and control subjects. In these cultured myotubes, we assessed insulin-induced 2-deoxyglucose uptake and early steps of the metabolic insulin-signaling cascade. Myotubes in culture from patients with IGT had insulin-induced glucose uptake that was roughly 30-50% less than that from control subjects. This insulin resistance was associated with impaired insulin receptor substrate (IRS)-2-associated phosphatidylinositol 3' (PI3) kinase activation and IRS-2 tyrosine phosphorylation as well as significantly decreased protein kinase C (PKC)-zeta/lambda activation in response to insulin. IRS-1- associated PI3 kinase activation and insulin receptor autophosphorylation were comparable in the two groups. Protein expression levels for the insulin receptor, IRS-1, IRS-2, the p85 regulatory subunit of PI3 kinase, Akt, PKC-zeta/lambda, GLUT1, and GLUT4 were also similar in the two groups. In conclusion, myotubes from patients with IGT have impaired insulin-induced glucose uptake. This is associated with impaired IRS-2-associated PI3 kinase activation and PKC-zeta/lambda activation. Our results suggest that these defects may contribute to insulin resistance in IGT patients."
Pathogenesis of type 2 (non-insulin dependent) diabetes mellitus: a balanced overview.
Cellular mechanisms of insulin resistance.
"Fatty acids decrease IDX-1 expression in rat pancreatic islets and reduce GLUT2, glucokinase, insulin, and somatostatin levels.IDX-1 (islet/duodenum homeobox-1) is a transcription factor expressed in the duodenum and pancreatic beta and delta cells. It is required for embryonic development of the pancreas and transactivates the Glut2, glucokinase, insulin, and somatostatin genes. Here we show that exposure of isolated rat pancreatic islets to palmitic acid induced a approximately 70% decrease in IDX-1 mRNA and protein expression as well as 40 and 65% decreases in the binding activity of IDX-1 for its cognate cis-regulatory elements of the Glut2 and insulin promoters, respectively. The inhibitory effect of palmitic acid required its mitochondrial oxidation since it was prevented by the carnitine palmitoyltransferase I inhibitor bromopalmitic acid. The palmitic acid effect on IDX-1 was correlated with decreases in GLUT2 and glucokinase expression of 40 and 25%, respectively, at both the mRNA and protein levels. Insulin and somatostatin mRNA expression was also decreased by 40 and 60%, whereas glucagon mRNA expression was not modified. After 48 h of exposure to fatty acids, total islet insulin, somatostatin, and glucagon contents were decreased by 85, 55, and 65%, respectively. At the same time, total hormone release was strongly stimulated (13-fold) for glucagon, whereas its was only marginally increased for insulin and somatostatin (1.5- and 1.7-fold, respectively). These results indicate that elevated fatty acid levels 1) negatively regulate Idx-1 expression; 2) decrease the expression of genes transactivated by IDX-1 such as those for GLUT2, glucokinase, insulin, and somatostatin; and 3) lead to an important increase in glucagon synthesis and secretion. Fatty acids thus have pleiotropic effects on pancreatic islet gene expression, and the negative control of Idx-1 expression may be an initial event in the development of these multiple defects."
"Inhibition of insulin gene expression by long-term exposure of pancreatic beta cells to palmitate is dependent on the presence of a stimulatory glucose concentration.Long-term exposure of pancreatic beta cells to elevated levels of fatty acids (FAs) impairs glucose-induced insulin secretion. However, the effects of FAs on insulin gene expression are controversial. We hypothesized that FAs adversely affect insulin gene expression only in the presence of elevated glucose concentrations. To test this hypothesis, isolated rat islets were cultured for up to 1 week in the presence of 2.8 or 16.7 mmol/L glucose with or without 0.5 mmol/L palmitate. Insulin release, insulin content, and insulin mRNA levels were determined at the end of each culture period. Palmitate increased insulin release at each time point independently of the glucose concentration. In contrast, insulin content was unchanged in the presence of palmitate at 2.8 mmol/L glucose, but was markedly decreased in the presence of 0.5 mmol/L palmitate and 16.7 mmol/L glucose after 2, 3, and 7 days of culture. In the presence of a basal concentration of glucose, insulin mRNA levels were transiently increased by palmitate at 24 hours but were unchanged thereafter. In contrast, palmitate significantly inhibited the stimulatory effects of 16.7 mmol/L glucose on insulin mRNA levels after 2, 3, and 7 days. To determine whether the inhibitory effect of palmitate on glucose-stimulated insulin mRNA levels was associated with decreased insulin promoter activity, HIT-T15 cells were cultured for 24 hours in 11.1 mmol/L glucose in the presence or absence of palmitate, and insulin gene promoter activity was measured in transient transfection experiments using the insulin promoter-reporter construct INSLUC. INSLUC activity was decreased more than 2-fold after 24 hours of exposure to 0.5 mmol/L palmitate. We conclude that long-term exposure of pancreatic beta cells to palmitate decreases insulin gene expression only in the presence of elevated glucose concentrations, in part through inhibition of insulin gene promoter activity."
"Glucose-induced preproinsulin gene expression is inhibited by the free fatty acid palmitate.Prolonged exposure to elevated FFA levels has been shown to induce peripheral insulin resistance and to alter the beta-cell secretory response to glucose. To investigate the effects of FFAs on preproinsulin gene expression, we measured insulin release, cell content, and messenger RNA (mRNA) levels in rat islets after a 24-h exposure to 1 mM palmitate. Insulin release increased at all glucose concentrations studied; in contrast, preproinsulin mRNA levels were specifically reduced by palmitate at high glucose with a decrease in insulin stores, suggesting that palmitate inhibits the glucose-stimulated increase in preproinsulin gene expression. The mechanisms by which palmitate affects preproinsulin gene expression implicate both preproinsulin mRNA stability and transcription, as suggested by an actinomycin D decay assay, quantification of primary preproinsulin transcripts, and transient transfection experiments in Min6 cells. Metabolism of palmitate is not required to obtain these effects, inasmuch as they can be reproduced by 2-bromopalmitate. However, oleate and linoleate did not significantly influence preproinsulin mRNA levels. We conclude that insulin release and preproinsulin gene expression are not coordinately regulated by palmitate and that chronically elevated FFA levels may interfere with beta-cell function and be implicated in the development of noninsulin-dependent diabetes."
The Faulty Three-Legged-Stool Model of Sustainable Development
How fast is too fast?: evaluating fast forward surrogates for digital video
A briefing on the evolution and status of the Open Video digital library
The relative effectiveness of concept-based versus content-based video retrieval
Semantic blogging and decentralized knowledge managementTapping into the structured metadata in snippets of information gives communities of interest effective access to their collective knowledge.
Restrictive clustering and metaclustering for self-organizing document collections
"Wire Segmenting for Improved Buffer InsertionBuffer insertion seeks to place buffers on the wires of a signal net to minimize delay. Van Ginneken [14] proposed an optimal dynamic programming solution (with extensions proposed by [7] [8] [9] [12]) such that at most one buffer can be placed on a single wire. This constraint can hurt solution quality, but it may be circumvented by dividing each wire into multiple smaller segments. This work studies the problem of finding the correct number of segments for each wire in the routing tree. Too..."
Gate Sizing: A General Purpose Optimization Approach
New algorithms for gate sizing: a comparative study
"Serendipity and information seeking: an empirical study""Serendipity"" has both a classical origin in literature and a more modern manifestation where it is found in the descriptions of the problem solving and knowledge acquisition of humanities and science scholars. Studies of information retrieval and information seeking have also discussed the utility of the notion of serendipity. Some have implied that it may be stimulated, or that certain people may ""encounter"" serendipitous information more than others. All to some extent accept the classical definition of serendipity as a ""fortuitous"" accident. The analysis presented here is part of a larger study concerning the information-seeking behaviour of interdisciplinary scholars. This paper considers the nature of serendipity in information-seeking contexts, and reinterprets the notion of serendipity as a phenomenon arising from both conditions and strategies - as both a purposive and a non-purposive component of information seeking and related knowledge acquisition."
The gap between cryptography and information security: has it narrowed?
"Re-appraising information seeking behaviour in a digital environment: Bouncers, checkers, returnees and the likeCollating data from a number of log and questionnaire studies conducted largely into the use of a range of consumer health digital information platforms, Centre for Information Behaviour and the Evaluation of Research (Ciber) researchers describe some new thoughts on characterising (and naming) information seeking behaviour in the digital environment, and in so doing, suggest a new typology of digital users. The characteristic behaviour found is one of bouncing in which users seldom penetrate a site to any depth, tend to visit a number of sites for any given information need and seldom return to sites they once visited. They tend to ""feed"" for information horizontally, and whether they search a site of not depends heavily on ""digital visibility"", which in turn creates all the conditions for ""bouncing"". The question whether this type of information seeking represents a form of ""dumbing down or up"", and what it all means for publishers, librarians and information providers, who might be working on other, possible outdated usage paradigms, is discussed."
"Detection of multistability, bifurcations, and hysteresis in a large class of biological positive-feedback systemsIt is becoming increasingly clear that bistability (or, more generally, multistability) is an important recurring theme in cell signaling. Bistability may be of particular relevance to biological systems that switch between discrete states, generate oscillatory responses, or “remember” transitory stimuli. Standard mathematical methods allow the detection of bistability in some very simple feedback systems (systems with one or two proteins or genes that either activate each other or inhibit each other), but realistic depictions of signal transduction networks are invariably much more complex. Here, we show that for a class of feedback systems of arbitrary order the stability properties of the system can be deduced mathematically from how the system behaves when feedback is blocked. Provided that this open-loop, feedback-blocked system is monotone and possesses a sigmoidal characteristic, the system is guaranteed to be bistable for some range of feedback strengths. We present a simple graphical method for deducing the stability behavior and bifurcation diagrams for such systems and illustrate the method with two examples taken from recent experimental studies of bistable systems: a two-variable Cdc2/Wee1 system and a more complicated five-variable mitogen-activated protein kinase cascade."
"Efficient low-molecule phosphorescent organic light-emitting diodes fabricated by wet-processingWe demonstrate high efficiency electrophosphorescence in organic light-emitting devices employing a phosphorescent dye doped into a low-molecule material. Methoxy-substituted 1,3,5-tris[4-(diphenylamino)phenyl]benzene (TDAPB) was selected as the host material for the phosphorescent dopant fac-tris(2-phenylpyridine) iridium(III) [Ir(ppy)3], and organic films were fabricated by spin-coating. A peak external quantum efficiency of 8.2% (29 cd/A), luminous power efficiency of 17.3 lm/W, and luminance of 33,000 cd/m2 were achieved at 9.4 V with a 90 nm-thick emitting layer. Emission from the host TDAPB material was not observed in the electroluminescence (EL) and photoluminescence (PL) spectra. The decrease in efficiencies at a high current is analyzed using the triplet-triplet annihilation model. The high performance for the simple device structure in this study is attributed to excellent film forming properties of the material and efficient energy transfer from the host to dopants."
Genomics in target and drug discovery.Genomics-based discovery of novel therapeutic drug targets requires the design of well-controlled biological or pharmacological experiments with experimental questions and hypotheses that relate to the therapeutic area of interest. This will aid the validation level of differentially expressed genes and hence facilitate the de-selection of the genes that are identified in microarray experiments. We here provide an example of how this approach is followed in the manipulation of human macrophage foam cells towards the discovery of novel drug targets for treatment of atherosclerosis.
"Thematic review series: The Pathogenesis of Atherosclerosis. Toward a biological network for atherosclerosisThe goal of systems biology is to define all of the elements present in a given system and to create an interaction network between these components so that the behavior of the system, as a whole and in parts, can be explained under specified conditions. The elements constituting the network that influences the development of atherosclerosis could be genes, pathways, transcript levels, proteins, or physiologic traits. In this review, we discuss how the integration of genetics and technologies such as transcriptomics and proteomics, combined with mathematical modeling, may lead to an understanding of such networks."
"Representations for Rigid Solids: Theory, Methods, and Systems"
"Scalable XSLT EvaluationXSLT is an increasingly popular language for processing XML data. It is widely supported by application platform software. However, little optimization effort has been made inside the current XSLT processing engines. Evaluating a very simple XSLT program on a large XML document with a simple schema may result in extensive usage of memory. In this paper, we present a novel notion of "
"Automatic Keyword Extraction UsingDocuments can be assigned keywords by frequency analysis of the terms found in the document text, which arguably is the primary source of knowledge about the document itself. By including a hierarchically organised domain specific thesaurus as a second knowledge source the quality of such keywords was improved considerably, as measured by match to previously manually assigned keywords."
"Wayfinding Strategies and Behaviors in Large Virtual WorldsThe spatial nature of large-scale virtual worlds introduces wayfinding problems which are often overlooked in the design process. In order to design and build useful virtual worlds in which real work can take place, these issues must be addressed. The research described here is a study of human wayfinding in virtual worlds and how real world solutions can be applied to virtual world design. The objective of this work is to develop design principles which will lead to a design methodology for..."
"Building a Funky Interface to a Web Search EngineThe project presents different views of information seeking models intended for the representation of how people carry out their search in traditional interactive Information Retrieval systems. The aim is to facilitate the understanding of information seeking within the Internet environment by integrating all aspects of information seeking. In detail, a number of characteristics of information seeking on the Web can be drawn, relating to the research of browsing strategies and..."
"Orientation and wayfinding: A reviewSpatial orientation can take place in three separate scales: scenes within an individual's visual field, surrounds including information to the front, side, and rear, and neighborhoods, that contain points not visible from the current location. When asked to orient in a surround people are especially sensitive to information to their fronts and backs. However if the surround has been experienced by viewing a map time to access information about a point increases with the angle between the..."
"Securing Data in Storage: A Review of Current ResearchProtecting data from malicious computer users continues to grow in importance. Whether preventing unauthorized access to personal photographs, ensuring compliance with federal regulations, or ensuring the integrity of corporate secrets, all applications require increased security to protect data from talented intruders. Specifically, as more and more files are preserved on disk the requirement to provide secure storage has increased in importance. This paper presents a survey of techniques for securely storing data, including theoretical approaches, prototype systems, and existing systems currently available. Due to the wide variety of potential solutions available and the variety of techniques to arrive at a particular solution, it is important to review the entire field prior to selecting an implementation that satisfies particular requirements. This paper provides an overview of the prominent characteristics of several systems to provide a foundation for making an informed decision. Initially, the paper establishes a set of criteria for evaluating a storage solution based on confidentiality, integrity, availability, and performance. Then, using these criteria, the paper explains the relevant characteristics of select storage systems and provides a comparison of the major differences."
"Unintentional injury in Ireland: a comparison of mortality and morbidity data. The aim of this study was to examine the relationship between mortality and hospital admission data for the leading causes of unintentional injury in Ireland. Mortality data were obtained from the Central Statistics Office for the years 1980-1996. Information on hospital admissions was obtained from the Hospital In-Patient Enquiry system for the years 1993-1997. Motor vehicle traffic accidents were the leading cause of unintentional injury death. Falls were the most common cause of unintentional injury hospital admission. Drowning and suffocation had high ratios of deaths to admissions, 2:1 and 1:3, respectively. The ratio of deaths to admissions was 1:39 for all unintentional injuries. Neither mortality data nor admissions data alone give an adequate guide to the impact of injuries, but together the two provide a reasonable basis on which to establish policy. "
"The North Dublin randomized controlled trial of structured diabetes shared care. A new diabetes shared care service was introduced in North Dublin. It was designed as a randomized controlled trial with a complex intervention comprising education of participating practitioners, the introduction of a community-based diabetes nurse specialist, local agreement on clinical protocols and structured communication across the primary-secondary care interface. Our aim was to assess the feasibility and effectiveness of a structured diabetes shared care service in a mixed health care system and to analyse the impact on total patient care. A Cluster randomized controlled trial lasting 18 months was carried out in 183 patients with type 2 diabetes from 30 general practices in North Dublin. Biophysical outcomes (HbA1c, blood pressure, body mass index), psychosocial measures (smoking status and Diabetes Clinic Treatment Satisfaction and Diabetes Well-being scores) and process outcomes were collected. There were significant improvements in diabetes care delivery and in psychosocial outcomes, but no significant improvements in biomedical outcomes. Process data collection revealed a significant increase in diabetes care-related activity for participating patients with an increase in structured annual reviews and fewer patients defaulting from care. There were also significant improvements in information exchange between primary and secondary care. Structured diabetes shared care, in a mixed health care system, can produce significant improvements in diabetes care delivery and in psychosocial outcomes for patients, with improved information exchange across the primary-secondary care interface. "
"A qualitative investigation of the views and health beliefs of patients with Type 2 diabetes following the introduction of a diabetes shared care service. A qualitative research approach was adopted in order to explore the views and health beliefs of patients with Type 2 diabetes who had experienced a new structured diabetes shared care service. Patients from 15 general practices were randomly selected and invited to attend three focus groups. Two independent researchers adopted the ""Framework"" technique to analyse the transcribed data and identify key themes expressed by patients. Themes relating to diabetes included frustration, victimization and powerlessness in relation to living with diabetes, controlling blood sugar, medication and economic barriers to care. Differences in emphases between patients and healthcare providers emerged. Patients were generally positive about shared care and largely identified it with the nurses involved. This research highlights the importance of an in-depth exploration of patients' views during changes in diabetes care delivery to identify service delivery failures and gaps in patient knowledge such as lack of awareness of the extent of macrovascular risk. "
"Nursing staff knowledge of the hepatitis B virus including attitudes and acceptance of hepatitis B vaccination: development of an effective program. Data for this study in a large tertiary referral teaching hospital in Dublin, Ireland were collected by anonymous self administered questionnaires. A total of 137 questionnaires were distributed to nurses working in five wards with a response rate of 88% (120). Objectives included identifying levels of awareness of the infectivity of the hepatitis B virus, ascertaining levels of knowledge of hepatitis B vaccination, and identifying attitudes resulting in acceptance of hepatitis B vaccine. Ninety seven respondents (82%) knew hepatitis B was 100 times more infective than HIV. Ninety eight respondents (83%) had completed a full course of hepatitis B immunizations. Ninety six respondents (93%) reported a hepatitis B antibody level on completion of the immunizations, 13 (14%) knew their actual titer, and 49 of 63 respondents (78%) reported immunity. Factors influencing decisions to accept vaccination included information related to the benefits of the vaccine from an occupational health physician or nurse and the vaccine being provided free of charge. Nurses in this study had an understanding of the hepatitis B infection. The number of nurses choosing to be vaccinated and having an antibody level test performed postvaccination was high in this group. Most nurses in this study believed they were immune to hepatitis B even though a significant number did not know their hepatitis B antibody level. "
"Carbon monoxide poisoning in the Republic of Ireland. Carbon monoxide (CO) poisoning remains a common preventable cause of morbidity and mortality from poisoning worldwide. Common environmental sources include motor vehicle exhaust, faulty kerosene or gas heaters used in unventilated rooms, and fireplaces with blocked flues. This paper describes the epidemiology of CO poisoning in Ireland, using Hospital Inpatient Enquiry (HIPE) data, Mortality data and data from the National Poisons Information Centre (NPIC). CO poisoning is responsible for over 40 deaths per year in Ireland. Many occur at home as a result of house-fires. Incomplete combustion of domestic fuels is responsible for many cases of non-fatal unintentional CO poisoning. In comparison, most intentional poisonings are caused by motor vehicle exhaust, representing approximately 6.4% of successful suicides. The advent of catalytic converters in cars may lead to a decline in the effectiveness of this method of suicide. This study illustrates the hidden impact of CO poisoning. Most deaths occur at home and thus do not come to the attention of the health services. Those admitted to hospital represent the milder end of the spectrum and generally recover after a short stay. It is important that the public be aware of the risks of CO poisoning and that Public Health action be taken. "
"Bone adaptation to load: microdamage as a stimulus for bone remodelling. Mechanical loading in the proximal radius was increased by ulnar osteotomy (Group O), altered by Steinmann pinning (Group P) or unaltered in sham operated controls (Group C) in skeletally mature female sheep, aged 2-4 years. A series of intravenous fluorochromes were given to label bone formation and fuchsin-stained microdamage assessed at intervals of up to 24 weeks. Microcracks were present in all groups and were found in the original cortex near the periosteal surface. No microcracks were found in the new, fibrolamellar bone laid down at periosteal or endosteal surfaces. Mean microcrack length (49 microm, SD 10 microm) did not differ between groups or overtime. Microcrack numerical and surface densities and resorption cavity density peaked in all groups at 6 weeks, consistent with a regional acceleratory phenomenon (RAP), but the peaks were significantly greater in Group O. The density of refilling or secondary osteons peaked at 10 weeks and the mean time required for the formation of an osteon was 7.51 +/- 0.59 weeks. Fatigue-induced microdamage is normally present in bone and is increased due to repetitive loading of the mechanically overloaded radius. The location and timing of microcracks, resorption cavities and secondary osteons are consistent with the activation-resorption-formation remodelling cycle and suggest that microdamage is a stimulus for bone remodelling. "
"Degree-dependent intervertex separation in complex networks We find the mean length $\ell(k)$ of the shortest paths between a vertex of degree $k$ and other vertices in growing networks. In scale-free networks, we obtain a power-law correction to a logarithmic dependence, $\ell(k) = A\ln [N/k^(γ-1)/2] - C k^γ-1/N$. Here $N$ is the number of vertices in the network, $γ$ is the degree distribution exponent, and the coefficients $A$ and $C$ depend on a network. We obtain this result for a number of growing deterministic graphs but believe that it holds for a wide class of evolving scale-free networks. In contrast, in stochastic and deterministic growing trees with an exponential degree distribution, we find a linear dependence on degree, $\ell(k) ≅ A\ln N - C k$. We compare our results for growing networks with those for uncorrelated graphs."
"Memory is relevant in the symmetric phase of the minority game Minority game is a simple-mined econophysical model capturing the cooperative behavior among selfish players. Previous investigations, which were based on numerical simulations up to about 100 players for a certain parameter $α$ in the range $0.1 ≤sssim α ≤sssim 1$, suggested that memory is irrelevant to the cooperative behavior of the minority game in the so-called symmetric phase. Here using a large scale numerical simulation up to about 3000 players in the parameter range $0.01 ≤sssim α ≤sssim 1$, we show that the mean variance of the attendance in the minority game actually depends on the memory in the symmetric phase. We also explain such dependence in the framework of crowd-anticrowd theory."
"Emergence of Complex Dynamics in a Simple Model of Signaling Networks A variety of physical, social and biological systems generate complex fluctuations with correlations across multiple time scales. In physiologic systems, these long-range correlations are altered with disease and aging. Such correlated fluctuations in living systems have been attributed to the interaction of multiple control systems; however, the mechanisms underlying this behavior remain unknown. Here, we show that a number of distinct classes of dynamical behaviors, including correlated fluctuations characterized by $1/f$-scaling of their power spectra, can emerge in networks of simple signaling units. We find that under general conditions, complex dynamics can be generated by systems fulfilling two requirements: i) a “small-world” topology and ii) the presence of noise. Our findings support two notable conclusions: first, complex physiologic-like signals can be modeled with a minimal set of components; and second, systems fulfilling conditions (i) and (ii) are robust to some degree of degradation, i.e., they will still be able to generate $1/f$-dynamics."
Incomplete information in scale-free networksI investigate the effect of incomplete information on the growth process of scale-free networks - a situation that occurs frequently in real existing citation networks. I propose two mathematical models and solve those analytically for the scaling behavior of the connectivity distribution. I compare to results from computer simulations and discuss the relevance for known data of real networks.
"Mechanism in homogeneous catalysis; NMR as a prime moverAn overview of the contribution of NMR to the development of our understanding of homogeneous catalysis is presented, with an emphasis on work from the author's research group."
Studies on some mixed pyrido-phenol donor ligands as sensitisers for terbium (III)Incorporation of the 2-(2-hydroxyphenyl)-pyridine system into aza-crown systems produces novel ligands for lanthanide ions and can act as sensitising antennae for terbium (III) ions.
"Laparoscopic procedures as a risk factor of deep venous thrombosis, superficial ascending thrombophlebitis and pulmonary embolism - case report and review of the literature.Since its introduction laparoscopic surgery has been used for many indications, e.g., cholecystolithiasis, hernia, appendicitis, fundoplication, benign large bowel disease and gynaecological disorders. It has been considered as safe and efficient procedure for most patients with only few contraindications, mostly heart-lung disease. - When the initial enthusiasm has been replaced by a more critical observation, more complications of laparoscopy or laparoscopic surgery were not only discovered but also reported. In laparoscopic hernia repair there is a tendency for severe complications when compared to open surgery. - There is a controversy on possible side-effects of laparoscopic surgery, e.g., thrombosis, and the increased necessity of prophylaxis for thromboembolic events. Recently a growing number of reports on thromboembolic complications in association with laparoscopic surgery were published. Thrombosis may be caused by detrimental effects of pneumoperitoneum on venous flow (increased abdominal pressure and negative Trendelenburg position) and activation of the haemostatic system. Further risk factors may contribute to the risk to develop venous thrombosis. It is well accepted that varicose veins are associated with an increased risk for the thrombosis. However, the association of varicose veins with complications of laparoscopic surgery is unclear. The possible impact of thrombotic complications makes an analysis of the association of varicose veins or a history of deep vein thrombosis on the development of thrombosis after laparoscopic surgery mandatory. Although this is the first report on ascending thrombophlebitis and thrombosis of the sapheno-femoral junction after laparoscopic surgery, the incidence of deep vein thrombosis or superficial thrombophlebitis after laparoscopic surgery or laparoscopy may be much higher according to the pathophysiological changes during and after these procedures. In many patients venous thrombosis may not be recognized or it appears when the patient is already discharged. - Conclusion: Laparoscopy and laparoscopic procedures may have an increased risk for the development of thrombosis due to increased abdominal pressure and negative Trendelenburg position. Patients with varicose veins and a history of thromboembolism may aggravate laparoscopy associated risks for the development of thromboembolic complications. Superficial thrombophlebitis in the thigh is not a benign disease entity and may lead to deep vein thrombosis (DVT) and pulmonary embolism (PE). Urgent surgical treatment (high ligation) may be warranted together with low-molecular weight heparin (LMWH) and compressions therapy. Patients with varicose veins and a history of venous thrombosis may not be suitable candidates for laparoscopic surgery. Family practitioners may be confronted with this complication more often since patients are discharged earlier from hospital after laparoscopic interventions due to legislative regulations."
"Ecological diversity and adaptive tendencies in the tropical fern Trichomanes L. (Hymenophyllaceae) with special reference to climbing and epiphytic habitsAmong the basal fern families, the Hymenophyllaceae, with more than 600 species, display a high diversity in terms of their morphology and the habitats that they occupy. We have chosen to focus on Trichomanes L., a clearly defined genus for which a phylogeny is presently being developed, to investigate the appearance of the climbing and epiphytic habits, as well as the related supposed adaptive characters. In this study we present the first review of the different ecological types within the genus: terrestrial, climbing (divided into hemi-epiphytic forms and true lianas), and epiphytic types. The study of several features concerning stem morphology and leaf size allows a proposal on relationships between ecology and plant morphology. Terrestrial species display a thick monocaulous rhizome with robust roots and short internodes. Climbing species are characterized by a branched, thick, creeping rhizome with long internodes. Epiphytic species also exhibit long, creeping and branching stems with long internodes but the rhizome is fine to filiform. Under these circumstances, there is a reduction of root system and frond size leading to dwarfism in numerous instances. This may be related to an extreme hygrophilous epiphytic strategy. Finally, hypotheses on the evolution of these habits and hence on the evolutionary relationships between ecology and characters are presented and discussed. © 2003 The Linnean Society of London, Botanical Journal of the Linnean Society, 2003, 142, 4163."
"Econstruct: Expectations, Solutions And Resultsthis paper. 2.# ECONSTRUCT PROPOSAL The next generation XML-based Internet provides a new opportunity for the Building and Construction industry to improve its ability to communicate project information over the Internet. Unlike earlier projects like ATLAS (Ep 7280), CONCUR (Be 96-3016) and others that mainly focused on meaningful communication of design information, eConstruct focuses on eCommerce/eBusiness for a more powerful drive. The aim of the project can best be illustrated by..."
"Semantic Web serviceshose properties, capabilities, interfaces, and effects are encoded in an unambiguous, machine-understandable form. The realization of the Semantic Web is underway with the development of new AI-inspired content markup languages, such as OIL, 3 DAML+OIL ("
"Chemopreventive potential of volatile oil from black cumin (Nigella sativa L.) seeds against rat colon carcinogenesis.Chemopreventive effects of orally administered Nigella sativa oil on the induction and development of 1,2-dimethylhydrazine-induced aberrant crypt foci (ACF), putative preneoplastic lesions for colon cancer, were investigated in Fischer 344 rats. Starting at 6 wk of age, 45 male rats (groups 1-3) were subcutaneously injected with DMH once a week for 3 wk. Group 1 (15 rats) served as a carcinogen control group without N. sativa administration. Group 2 or 3 (15 rats each) were given the oil in the postinitiation stage or in the initiation stage, respectively. Animals of group 4 (11 rats) were injected with 0.9% saline and received N. sativa oil from the beginning until the termination. At sacrifice, 14 wk after the start, the total numbers of ACF as well as those with at least four crypts were significantly reduced in group 2 (P < 0.01). However, treatment with N. sativa oil in the initiation stage (group 3) did not exhibit significant inhibitory effects except on foci with only one aberrant crypt. Immunohistochemical analysis of 5-bromo-2'.-deoxyuridine labeling in colonic crypts revealed the N. sativa oil to have significant antiproliferative activity in both initiation and postinitiation stages and especially in the latter. Histological examination revealed no pathological changes in the liver, kidneys, spleen, or other organs of rats treated with N. sativa. In addition, biochemical parameters of blood and urine as well as body weight gain were not affected. These findings demonstrate that the volatile oil of N. sativa has the ability to inhibit colon carcinogenesis of rats in the postinitiation stage, with no evident adverse side effects, and that the inhibition may be associated, in part, with suppression of cell proliferation in the colonic mucosa."
"Effect of Nigella sativa (N. sativa L.) and oxidative stress on the survival pattern of MCF-7 breast cancer cells.N. Sativa L., an oriental spice, has long been used as a natural medicine for treatment of many acute as well as chronic conditions. It has been used in the treatment of diabetes, hypertension, and dermatological conditions. There has been very few studies on the effects of N. Sativa as cancer prevention/therapy. Our objective therefore, was to expose MCF-7 breast cancer cells to aqueous and alcohol extracts and in combination with H2O2 as an oxidative stressor. Measurement of cell survival under various concentrations and combinations was conducted using standard cell culture techniques, exposure protocols in 96 well plates and Fluoro-spectrosphotometry. Following cellular growth to 90% confluency, exposure to water (WE) and ethanol (AE) extracts of N. sativa and H2O2 was performed. Toxicity index (LC50) was calculated from percent survival using regression analysis. Results showed that the alcohol extract and its combinations were able to completely inactivate the MCF-7 cells (LC50 ranged from 377.16-573.79 in descending potency for H2O2 + AE, AE and Mix of WE and AE). H2O2 alone effectively inactivated MCF-7 cells (LC50 = 460.94). The least effective combinations in descending potency were WE + H2O2, WE + AE + H2O2, and WE (LC50 were 725.79, 765.94, and 940.5 respectively. Combinations other than AE + H2O2 showed possible interactions, which lead to reduction in their potency. In conclusion, N. Sativa alone or in combination with oxidative stress were found to be effective in vitro in inactivating MCF-7 breast cancer cells, unveiling opportunities for promising results in the field of prevention and treatment of cancer."
"The in vivo antifungal activity of the aqueous extract from Nigella sativa seeds.The effect of an aqueous extract of Nigella sativa seeds was studied on candidiasis in mice. An intravenous inoculum of Candida albicans produced colonies of the organism in the liver, spleen and kidneys. Treatment of mice with the plant extract (6.6 mL/kg equivalent to 5 mg of estimated protein, once daily for 3 days) 24 h after the inoculation caused a considerable inhibitory effect on the growth of the organism in all organs studied. A 5-fold decrease in Candida in kidneys, 8-fold in liver and 11-fold in spleen was observed in the groups of animals post-treated with the plant extract. Histopathological examination of the respective organs confirmed these findings. These results indicate that the aqueous extract of Nigella sativa seeds exhibits inhibitory effect against candidiasis and this study validates the traditional use of the plant in fungal infections."
"Delayed apoptosis upon the treatment of Hep-2 cells with black seed.Nigella sativa (Black seed, BS) has been used to promote health and fight disease for centuries. The objectives of this investigation were: (1) to study whether agents such as cortisol and LPS alone or in combination induce cellular (Hep-2, laryngeal carcinoma) damage with time in culture (24, 48, and 72 hours) using apoptosis as a marker, (2) to determine if an immune stimulant such as BS, can protect Hep-2 cells from insult and ultimately thwart the programmed cells death mechanism. A total of 54 Hep-2 cell/tubes (50,000 cells per tube) were divided into six equal groups. Group one served as untreated control, while groups 2-6 were treated with either cortisol (10 ng/ml), LPS (10 micrograms/ml), BS (25 micrograms/ml), or a combination of LPS and cortisol and cortisol plus LPS plus BS, respectively. At the end of each phase the cells were harvested, heat fixed and stained with H&E to evaluate morphological changes. Immunohistochemistry, using antibodies against caspace-3 to evaluate cells undergoing apoptosis was conducted in all groups. The results of this study showed evidence of cells undergoing apoptosis at different magnitudes in all groups. However, the most dramatic change was seen in groups containing cortisol and LPS alone or in combination. This was supported by the fact that there were several adaptive responses observed in all phases. In addition, the exposure of BS to cells pretreated with cortisol and LPS showed evidence of protection against the progressive apoptosis."
"Nigella sativa (black cumin) ameliorates potassium bromate-induced early events of carcinogenesis: diminution of oxidative stress.Potassium bromate (KBrO3) is a potent nephrotoxic agent. In this paper, we report the chemopreventive effect of Nigella sativa (black cumin) on KBrO3-mediated renal oxidative stress, toxicity and tumor promotion response in rats. KBrO3 (125 mg/kg body weight, intraperitoneally) enhances lipid peroxidation, gamma-glutamyl transpeptidase, hydrogen peroxide and xanthine oxidase with reduction in the activities of renal antioxidant enzymes and renal glutathione content. A marked increase in blood urea nitrogen and serum creatinine has also been observed. KBrO3 treatment also enhances ornithine decarboxylase (ODC) activity and [3H] thymidine incorporation into renal DNA. Prophylaxis of rats orally with Nigella sativa extract (50 mg/kg body weight and 100 mg/kg body weight) resulted in a significant decrease in renal microsomal lipid peroxidation (P < 0.001), gamma-glutamyl transpeptidase (P < 0.001), H2O2 (P < 0.001) and xanthine oxidase (P < 0.05). There was significant recovery of renal glutathione content (P < 0.01) and antioxidant enzymes (P < 0.001). There was also reversal in the enhancement of blood urea nitrogen, serum creatinine, renal ODC activity and DNA synthesis (P < 0.001). Data suggest that Nigella sativa is a potent chemopreventive agent and may suppress KBrO3-mediated renal oxidative stress, toxicity and tumour promotion response in rats."
"Immunosuppressive and cytotoxic properties of Nigella sativa.In this study the volatile oil of Nigella sativa seeds (NSVO) was investigated for its immunomodulating and cytotoxic properties. A rat model was designed to examine the effect of NSVO on selected immune components. Long-Evans rats were challenged with a specific antigen (typhoid TH) and treated with NSVO; and the changes produced in their serum antibody titre along with the splenocytes and peripheral immune cells were analysed. Antibody titre for the experimental animal was found to be 1280 as compared to the 2560 in the control rats. There was a significant (p < 0.05) decrease in splenocytes and neutrophils counts, but a rise in peripheral lymphocytes and monocytes in the experimental animals. To test the cytotoxicity of NSVO, a panel of five human cancer cell lines and a fibroblast line was used. The MTT assay was employed to estimate the cell mortality. Vinblastine sulphate and mitomycin C were used as the positive control. LC(50) values for NSVO were 155.02 +/- 10.4, 185.77 +/- 2.9, 120.40 +/- 20.5, 384.53 +/- 12.1 and 286.83 +/- 23.3 micro g/ml respectively against the SCL, SCL-6, SCL-37'6, NUGC-4 cancer lines and 3T6 fibroblast line. Results indicate that the NSVO could be considered as a potential immunosuppressive cytotoxic agent."
"Thymoquinone extracted from black seed triggers apoptotic cell death in human colorectal cancer cells via a p53-dependent mechanism.For centuries, the black seed (Nigella sativa) herb and oil have been used in Asia, Middle East and Africa to promote health and fight disease. Thymoquinone (TQ), the most abundant constituent present in black seed, is a promising dietary chemopreventive agent. We investigated the effects of thymoquinone (TQ) against HCT-116 human colon cancer cells and attempted to identify its potential molecular mechanisms of action. We report that TQ inhibits the growth of colon cancer cells which was correlated with G1 phase arrest of the cell cycle. Furthermore, TUNEL staining and flow cytometry analysis indicate that TQ triggers apoptosis in a dose- and time-dependent manner. Apoptosis induction by TQ was associated with a 2.5-4.5-fold increase in mRNA expression of p53 and the downstream p53 target gene, p21WAF1. Simultaneously, we found a marked increase in p53 and p21WAF1 protein levels but a significant inhibition of anti-apoptotic Bcl-2 protein. Co-incubation with pifithrin-alpha (PFT-alpha), a specific inhibitor of p53, restored Bcl-2, p53 and p21WAF1 levels to the untreated control and suppressed TQ-induced cell cycle arrest and apoptosis. p53-null HCT-116 cells were less sensitive to TQ-induced growth arrest and apoptosis. These results indicate that TQ is antineoplastic and pro-apoptotic against colon cancer cell line HCT116. The apoptotic effects of TQ are modulated by Bcl-2 protein and are linked to and dependent on p53. Our data support the potential for using the agent TQ for the treatment of colon cancer."
"Maintaining wildlife habitat in southeastern Alaska: implications of new knowledge for forest management and researchWe review results and implications from recent wildlife studies that followed from the 1997 Tongass Land Management Plan (TLMP) and identify information needs and directions for research, development, and application. Sustained population viability of wildlife species was identified as a major issue in the TLMP planning process. Several species were identified as management indicator species, and research was conducted to determine their potential sensitivity to forest management. Southeastern Alaska was found to be a region with an especially high degree of endemism in its small mammal fauna, principally because of the combination of its archipelago geography combined with highly dynamic glacial history. Two species of endemic small mammals selected for demographic study, however, appeared to be less dependent on old-growth forests than had been suspected at the time TLMP was written: the northern flying squirrel (Glaucomys sabrinus) because of relatively high suitability of noncommercial, low-volume, mixed-conifer forest; and the southern red-backed vole (Clethrionomys gapperi) because of relatively high suitability of precommercially thinned young-growth forest. The northern goshawk (Accipiter gentilis) was found to be problematic for ""management indicator"" status because of logistical difficulties involved in monitoring this relatively rare, highly mobile species that frequently changes nest sites. Sampling protocols were developed for marbled murrelet (Brachyramphus marmoratus), although murrelet populations do not appear to be in trouble on the Tongass. The conservation strategy of TLMP for American marten (Martes americana) appeared to be sound on Chichagof Island where marten have been studied intensively, but implications for the rest of southeastern Alaska were unclear without further work. Studies of the Alexander Archipelago wolf (Canis lupus ligoni) indicated that population density of black-tailed deer (Odocoileus hemionus) and road access (to wolf hunters) were the predominant factors affecting wolf productivity and mortality, respectively. Finally, studies of bird community response to timber-harvest alternatives to clearcutting indicated that although creation of forest ""edge"" may increase nest predation rates, the actual response depends on a broad array of factors and is highly variable.We suggest that research, development, and application focus on plant and animal communities and management of vegetation to achieve specific objectives for wildlife habitat. We suggest that such efforts emphasize silviculture of second-growth forests, understanding old-growth reserves, distribution of endemic small mammals, and alternatives to clearcutting. Models for evaluating black-tailed deer habitat and populations are needed for subsistence-hunting management, and some work needs to be directed at interactions between tourism and selected wildlife species."
"Predicting the location of northern goshawk nests: modeling the spatial dependency between nest locations and forest structureNorthern goshawks interact with each other and their environment in a spatially dependent manner. However, finding the location of active goshawk nests (e.g. where eggs are laid) in a given year is difficult due to the secretive nature of the hawks in their forest environment, their annually variable attempts at nesting, and the extent of the area within a home range where they will nest. We used a Gibbsian pairwise potential model to describe the spatial dependency (1) among nest locations influenced by territoriality and (2) between nest locations and the environment for a large population of goshawks on the Kaibab National Forest's (NNF) North Kaibab Ranger District (NKRD). Nest locations in a given year were regularly distributed at a minimum distance of 1.6 km between active nests; however, as the spatial scale increased (i.e. as distance between the nests increased), the degree of regularity decreased. Important forest predictors for nest locations included canopy closure, total basal area, proportion of basal area in ponderosa pine, spruce, fir, and aspen, maximum height of the understory vegetation, and presence/absence of seedlings and saplings. The probability of an occurrence of an active nest within a 10-m x 10-m area was modeled using logistic regression. Spatial analysis, using nest spacing and habitat variables, indicated that potential active nest locations were abundant and randomly distributed throughout the NKRD. This supports the supposition that the availability of locations with high potential for nests is not limiting the goshawk population on the study area. Instead, territoriality, and what appear to be non-compressible territories, sets the upper limit to the nesting population. Ultimate choice of nest location was probably constrained by the availability of high potential locations within spaces defined by neighboring territories. Overall territory density, on the other hand, may reflect the abundance, quality, and accessibility of prey on the study area. This model can be used to evaluate the influence of forest management activities on the nesting goshawk population on the NKRD. The modeling technique described in this paper may be applied to other study areas, where vertebrate densities and the spatial resolution of habitat data may be less or greater than on this study, provided that new point process and pairwise potential models are developed for each area."
"Predation of red squirrels by northern goshawks in a conifer forest in northern England: can this limit squirrel numbers and create a conservation dilemma?Red squirrels (Sciurus vulgaris) have been lost from most broadleaved habitats in England due to the range expansion of grey squirrels (S. carolinensis). Currently, the main refugia for red squirrels in England are the extensive exotic conifer forests in the north. These forests are also home to an expanding population of northern goshawks (Accipiter gentilis) that were re-established in the 1970s. During the breeding season (March - August), goshawks feed mainly on birds, with species of Columbidae, Corvidae and Phasianidae/Tetraonidae comprising 79% of 5445 prey items collected during 1973-1996. Only 97 red squirrels were recorded in this sample. We estimated that ca. 79 red squirrels were removed by goshawks each breeding season in Kielder Forest, but there was much annual variation (8-261 squirrels predated) that appeared to be related to the masting frequency of Norway spruce (Picea abies). Goshawks were likely to remove fewer squirrels outside the breeding season (September-February) because only adult males overwintered in the study area. Based on the area of conifers of a cone-bearing age and known densities of squirrels, we estimated that 1294-5556 adult squirrels produced 2135-9167 offspring annually in Kielder. For goshawks to reduce the population growth rate of squirrels to zero, predation would have to exceed 50% of the population. Clearly, this does not appear to be the case. This conclusion is in broad agreement with other studies indicating that food availability (conifer seed) is the main factor limiting numbers of tree squirrels, not predation. Thus, existing conservation management for sympatric populations of red squirrels and goshawks are compatible."
"Why good engineers (sometimes) create bad interfacesThis paper presents a view of system design that shows how good engineering practice can lead to poor user interfaces. From the engineer's perspective, the ideal interface reflects the underlying mechanism and affords direct access to the control points of the mechanism. The designer of the user interface is often also the designer of the mechanism (or at least is very familiar with the mechanism), and thus has a strong bias toward basing the interface on the engineering model. The user, however, wants to complete a task, and an interface that is based on the task is often more appropriate than one based on the system mechanism. We discuss these issues, and also discuss where to position the user interface between the poles of the engineering model and the task model."
"Effects of harvesting timber stands on goshawk nesting in two European areasWe evaluated the effects of harvesting timber stands on goshawk (Accipiter gentilis) nesting in two European areas (central Italy and eastern France), by studying their occupancy and reproductive performance. We found no difference in the productivity of goshawk pairs reproducing in unlogged vs. logged stands. When considering the same nesting stand, before and after timber harvesting, we noted no differences in the number of young per breeding pair nor a year effect. We observed that 87.5% of goshawk pairs nesting in logged stands moved away only when the original stand structure was altered by >30%, and then only to the nearest neighbouring mature stand (maximum distance ca. 1.5 km). The results of our study suggest that goshawks can tolerate some levels of timber harvesting within the nesting stand, as long as the cover reduction does not exceed the threshold of about 30%."
"Long-term exposure of rat pancreatic islets to fatty acids inhibits glucose-induced insulin secretion and biosynthesis through a glucose fatty acid cycle.We tested effects of long-term exposure of pancreatic islets to free fatty acids (FFA) in vitro on B cell function. Islets isolated from male Sprague-Dawley rats were exposed to palmitate (0.125 or 0.25 mM), oleate (0.125 mM), or octanoate (2.0 mM) during culture. Insulin responses were subsequently tested in the absence of FFA. After a 48-h exposure to FFA, insulin secretion during basal glucose (3.3 mM) was several-fold increased. However, during stimulation with 27 mM glucose, secretion was inhibited by 30-50% and proinsulin biosynthesis by 30-40%. Total protein synthesis was similarly affected. Conversely, previous palmitate did not impair alpha-ketoisocaproic acid (5 mM)-induced insulin release. Induction and reversibility of the inhibitory effect on glucose-induced insulin secretion required between 6 and 24 h. Addition of the carnitine palmitoyltransferase I inhibitor etomoxir (1 microM) partially reversed (by > 50%) FFA-associated decrease in secretory as well as proinsulin biosynthetic responses to 27 mM glucose. The inhibitory effect of previous palmitate was similar when co-culture was performed with 5.5, 11, or 27 mM glucose. Exposure to palmitate or oleate reduced the production of 14CO2 from D-[U-14C]glucose, and of 14CO2 from D-[3,4-14C]-glucose, both effects being reversed by etomoxir. Conclusions: long-term exposure to FFA inhibits glucose-induced insulin secretion and biosynthesis probably through a glucose fatty acid cycle."
"A Machine Learning Strategy to Identity Exonic Splice Enhancers in Human Protein-coding SequenceBackground: Exonic splice enhancers are sequences embedded within exons which promote and regulate the splicing of the transcript in which they are located. A class of exonic splice enhancers are the SR proteins, which are thought to mediate interactions between splicing factors bound to the 5' and 3' splice sites. Method and results: We present a novel strategy for analysing protein-coding sequence by first randomizing the codons used at each position within the coding sequence, then applying a motif-based machine learning algorithm to compare the true and randomized sequences. This strategy identified a collection of motifs which can successfully discriminate between real and randomized coding sequence, including -- but not restricted to -- several previously reported splice enhancer elements. As well as successfully distinguishing coding exons from randomized sequences, we show that our model is able to recognize non-coding exons. Conclusions: Our strategy succeeded in detecting signals in coding exons which seem to be orthogonal to the sequences' primary function of coding for proteins. We believe that many of the motifs detected here may represent binding sites for previously unrecognized proteins which influence RNA splicing. We hope that this development will lead to improved knowledge of exonic splice enhancers, and new developments in the field of computational gene prediction."
"Categorization and characterization of transcript-confirmed constitutively and alternatively spliced introns and exons from humanBy spliced alignment of human DNA and transcript sequence data we constructed a data set of transcript-confirmed exons and introns from 2793 genes, 796 of which (28%) were seen to have multiple isoforms. We find that over one-third of human exons can translate in more than one frame, and that this is highly correlated with G+C content. Introns containing adenosine at donor site position +3 (A3), rather than guanosine (G3), are more common in low G+C regions, while the converse is true in high G+C regions. These two classes of introns are shown to have distinct lengths, consensus sequences and correlations among splice signals, leading to the hypothesis that A3 donor sites are associated with exon definition, and G3 donor sites with intron definition. Minor classes of introns, including GC-AG, U12-type GT-AG, weak, and putative AG-dependant introns are identified and characterized. Cassette exons are more prevalent in low G+C regions, while exon isoforms are more prevalent in high G+C regions. Cassette exon events outnumber other alternative events, while exon isoform events involve truncation twice as often as extension, and occur at acceptor sites twice as often as at donor sites. Alternative splicing is usually associated with weak splice signals, and in a majority of cases, preserves the coding frame. The reported characteristics of constitutive and alternative splice signals, and the hypotheses offered regarding alternative splicing and genome organization, have important implications for experimental research into RNA processing. The ‘AltExtron’ data sets are available at http://www.bit.uq.edu.au/altExtron/ and http://www.ebi.ac.uk/~thanaraj/altExtron/."
"Genomeâwide detection of tissueâspecific alternative splicing in the human transcriptomeWe have developed an automated method for discovering tissueâspecific regulation of alternative splicing through a genomeâwide analysis of expressed sequence tags (ESTs). Using this approach, we have identified 667 tissueâspecific alternative splice forms of human genes. We validated our muscleâspecific and brainâspecific splice forms for known genes. A high fraction (8/10) were reported to have a matching tissue specificity by independent studies in the published literature. The number of tissueâspecific alternative splice forms is highest in brain, while eye_retina, muscle, skin, testis and lymph have the greatest enrichment of tissueâspecific splicing. Overall, 10â30% of human alternatively spliced genes in our data show evidence of tissueâspecific splice forms. Seventyâeight percent of our tissueâspecific alternative splices appear to be novel discoveries. We present bioinformatics analysis of several tissueâspecific splice forms, including automated protein isoform sequence and domain prediction, showing how our data can provide valuable insights into gene function in different tissues. For example, we have discovered a novel kidneyâspecific alternative splice form of the WNK1 gene, which appears to specifically disrupt its Nâterminal kinase domain and may play a role in PHAII hypertension. Our database greatly expands knowledge of tissueâspecific alternative splicing and provides a comprehensive dataset for investigating its functional roles and regulation in different human tissues."
"Extensive search for discriminative features of alternative splicing.Alternative pre-mRNA splicing events can be classified into various types, including cassette, mutually exclusive, alternative 3' splice site, alternative 5' splice site, retained intron. The detection of features of a particular type of alternative splicing events is an important and challenging problem in understanding the mechanism of alternative splicing. In this paper, we consider the problem of finding regulatory sequence patterns, which are specific to a particular type of alternative splicing events, on alternative exons and their flanking introns. For this problem, we have designed various pattern features and evaluated them on the alternative splicing data compiled in Lee's ASAP (Alternative Splicing Annotation Project) database. Through our work, we have succeeded in finding features with practically high accuracies."
"Computational analysis of candidate intron regulatory elements for tissue-specific alternative pre-mRNA splicing.Alternative pre-mRNA splicing is a major cellular process by which functionally diverse proteins can be generated from the primary transcript of a single gene, often in tissue-specific patterns. The current study investigates the hypothesis that splicing of tissue-specific alternative exons is regulated in part by control sequences in adjacent introns and that such elements may be recognized via computational analysis of exons sharing a highly specific expression pattern. We have identified 25 brain-specific alternative cassette exons, compiled a dataset of genomic sequences encompassing these exons and their adjacent introns and used word contrast algorithms to analyze key features of these nucleotide sequences. By comparison to a control group of constitutive exons, brain-specific exons were often found to possess the following: divergent 5' splice sites; highly pyrimidine-rich upstream introns; a paucity of GGG motifs in the downstream intron; a highly statistically significant over-representation of the hexanucleotide UGCAUG in the proximal downstream intron. UGCAUG was also found at a high frequency downstream of a smaller group of muscle-specific exons. Intriguingly, UGCAUG has been identified previously in a few intron splicing enhancers. Our results indicate that this element plays a much wider role than previously appreciated in the regulated tissue-specific splicing of many alternative exons."
"Finding signals that regulate alternative splicing in the post-genomic era.Alternative splicing of pre-mRNAs is central to the generation of diversity from the relatively small number of genes in metazoan genomes. Auxiliary cis elements and trans-acting factors are required for the recognition of constitutive and alternatively spliced exons and their inclusion in pre-mRNA. Here, we discuss the regulatory elements that direct alternative splicing and how genome-wide analyses can aid in their identification."
"The case against user interface consistencyDesigners striving for user interface consistency can resemble Supreme Court justices trying to define pornography: each of us feels we know it when we see it, but people often disagree and a precise definition remains elusive. A close examination suggests that consistency is an unreliable guide and that designers would often do better to focus on users' work environments."
"Beta-cell hypersensitivity to glucose following 24-h exposure of rat islets to fatty acids.Prolonged exposure of islets to fatty acids results in a lowered glucose set-point for insulin secretion. We examined the mechanism in islets cultured for 24 h with 0.25 mmol/l palmitate. As expected, insulin secretion at 2.8 and 8.3 mmol/l glucose was increased in the palmitate-treated islets as opposed to no change at 27.7 mmol/l glucose. Co-culturing with 0.05 microgram/ml Triacsin C, an inhibitor of long chain acyl-CoA synthetase, blocked this effect. Glucose utilization and oxidation showed the same pattern as insulin secretion, with the step-up for both measurements being fully manifest at 2.8 mmol/l glucose. Glucokinase Km and Vmax measured in islet extracts were unaffected by the palmitate. In contrast, hexokinase Vmax was increased by 25-35% in both the cytoplasmic and mitochondrial-bound pools. Our data suggest prolonged exposure to fatty acids increased beta-cell hexokinase activity, thereby modifying the kinetics of glucose entry into the metabolic pathway and glucose-induced insulin secretion. The cellular mediator is likely an increased level of long chain fatty acyl-CoA esters."
"Inferring quantitative models of regulatory networks from expression data.MOTIVATION: Genetic networks regulate key processes in living cells. Various methods have been suggested to reconstruct network architecture from gene expression data. However, most approaches are based on qualitative models that provide only rough approximations of the underlying events, and lack the quantitative aspects that are critical for understanding the proper function of biomolecular systems. RESULTS: We present fine-grained dynamical models of gene transcription and develop methods for reconstructing them from gene expression data within the framework of a generative probabilistic model. Unlike previous works, we employ quantitative transcription rates, and simultaneously estimate both the kinetic parameters that govern these rates, and the activity levels of unobserved regulators that control them. We apply our approach to expression datasets from yeast and show that we can learn the unknown regulator activity profiles, as well as the binding affinity parameters. We also introduce a novel structure learning algorithm, and demonstrate its power to accurately reconstruct the regulatory network from those datasets."
"Pancreatic beta-cells in obesity. Evidence for induction of functional, morphologic, and metabolic abnormalities by increased long chain fatty acids.To elucidate the mechanism of the basal hyperinsulinemia of obesity, we perfused pancreata from obese Zucker and lean Wistar rats with substimulatory concentrations of glucose. Insulin secretion at 4.2 and 5.6 mM glucose was approximately 10 times that of controls, whereas beta-cell volume fraction was increased only 4-fold and DNA per islet 3.5-fold. We therefore compared glucose usage at 1.4, 2.8, and 5.6 mM. Usage was 8-11.4 times greater in Zucker islets at 1.4 and 2.8 mM and 4 times greater at 5.6 mM; glucose oxidation at 2.8 and 5.6 mM glucose was > 12 times lean controls. To determine if the high free fatty acid (FFA) levels of obesity induce these abnormalities, normal Wistar islets were cultured with 0, 1, or 2 mM long chain FFA for 7 days. Compared to islets cultured without FFA insulin secretion by FFA-cultured islets (2 mM) perifused with 1.4, 3, or 5.6 mM glucose was increased more than 2-fold, bromodeoxyuridine incorporation was increased 3-fold, and glucose usage at 2.8 and 5.6 mM glucose was increased approximately 2-fold (1 mM FFA) and 3-fold (2 mM FFA). We conclude that hypersecretion of insulin by islets of obese Zucker fatty rats is associated with, and probably caused by, enhanced low Km glucose metabolism and beta-cell hyperplasia, abnormalities that can be induced in normal islets by increased FFA."
"Using Bayesian Networks to Analyze Expression DataDNA hybridization arrays simultaneously measure the expression level for thousands of genes. These measurements provide a ""snapshot"" of transcription levels within the cell. A major challenge in computational biology is to uncover, from such measurements, gene/protein interactions and key biological features of cellular systems. In this paper, we propose a new framework for discovering interactions between genes based on multiple expression measurements. This framework builds on the use of Bayesian networks for representing statistical dependencies. A Bayesian network is a graph-based model of joint multivariate probability distributions that captures properties of conditional independence between variables. Such models are attractive for their ability to describe complex stochastic processes and because they provide a clear methodology for learning from (noisy) observations. We start by showing how Bayesian networks can describe interactions between genes. We then describe a method for recovering gene interactions from microarray data using tools for learning Bayesian networks. Finally, we demonstrate this method on the S. cerevisiae cell-cycle measurements of Spellman et al. (1998)."
"Combining location and expression data for principled discovery of genetic regulatory network models.We develop principled methods for the automatic induction (discovery) of genetic regulatory network models from multiple data sources and data modalities. Models of regulatory networks are represented as Bayesian networks, allowing the models to compactly and robustly capture probabilistic multivariate statistical dependencies between the various cellular factors in these networks. We build on previous Bayesian network validation results by extending the validation framework to the context of model induction, leveraging heuristic simulated annealing search algorithms and posterior model averaging. Using expression data in isolation yields results inconsistent with location data so we incorporate genomic location data to guide the model induction process. We combine these two data modalities by allowing location data to influence the model prior and expression data to influence the model likelihood. We demonstrate the utility of this approach by discovering genetic regulatory models of thirty-three variables involved in S. cerevisiae pheromone response. The models we automatically generate are consistent with the current understanding regarding this regulatory network, but also suggest new directions for future experimental investigation."
"Using graphical models and genomic expression data to statistically validate models of genetic regulatory networks.We propose a model-driven approach for analyzing genomic expression data that permits genetic regulatory networks to be represented in a biologically interpretable computational form. Our models permit latent variables capturing unobserved factors, describe arbitrarily complex (more than pair-wise) relationships at varying levels of refinement, and can be scored rigorously against observational data. The models that we use are based on Bayesian networks and their extensions. As a demonstration of this approach, we utilize 52 genomes worth of Affymetrix GeneChip expression data to correctly differentiate between alternative hypotheses of the galactose regulatory network in S. cerevisiae. When we extend the graph semantics to permit annotated edges, we are able to score models describing relationships at a finer degree of specification."
"Advances to Bayesian network inference for generating causal networks from observational biological dataMotivation: Network inference algorithms are powerful computational tools for identifying putative causal interactions among variables from observational data. Bayesian network inference algorithms hold particular promise in that they can capture linear, non-linear, combinatorial, stochastic and other types of relationships among variables across multiple levels of biological organization. However, challenges remain when applying these algorithms to limited quantities of experimental data collected from biological systems. Here, we use a simulation approach to make advances in our dynamic Bayesian network (DBN) inference algorithm, especially in the context of limited quantities of biological data."
"Improved routing strategies for Internet traffic deliveryWe analyze different strategies aimed at optimizing routing policies in the Internet. We first show that for a simple deterministic algorithm the local properties of the network deeply influence the time needed for packet delivery between two arbitrarily chosen nodes. We next rely on a real Internet map at the autonomous system level and introduce a score function that allows us to examine different routing protocols and their efficiency in traffic handling and packet delivery. Our results suggest that actual mechanisms are not the most efficient and that they can be integrated in a more general, though not too complex, scheme."
"Self-Organized Criticality and Stock Market Dynamics: an Empirical StudyThe Stock Market is a complex self-interacting system, characterized by an intermittent behaviour. Periods of high activity alternate with periods of relative calm. In the present work we investigate empirically about the possibility that the market is in a self-organized critical state (SOC). A wavelet transform method is used in order to separate high activity periods, related to the avalanches of sandpile models, from quiescent. A statistical analysis of the filtered data show a power law behaviour in the avalanche size, duration and laminar times. The memory process, implied by the power law distribution, of the laminar times is not consistent with classical conservative models for self-organized criticality. We argue that a “near-SOC” state or a time dependence in the driver, which may be chaotic, can explain this behaviour."
Stationary States of a Random Copying Mechanism over a Complex NetworksAn analytical approach to network dynamics is used to show that when agents copy their state randomly the network arrives to a stationary status in which the distribution of states is independent of the agents degree. The effects of network topology on the process are characterized introducing a quantity called influence and studying its behavior for scale-free and random networks. We show that for this model degree averaged means are constant in time regardless of the number of states involved.
"Epidemics and Dimensionality in Hierarchical Networks Epidemiological processes are studied within a recently proposed hierarchical network model using the susceptible-infected-refractory dynamics of an epidemic. Within the network model, a population may be characterized by $H$ independent hierarchies or dimensions, each of which consists of groupings of individuals into layers of subgroups. Detailed numerical simulations reveal that for $H>1$, global spreading results regardless of the degree of homophily of the individuals forming a social circle. For H=1, a transition from global to local spread occurs as the population becomes decomposed into increasingly homophilous groups. Multiple dimensions in classifying individuals (nodes) thus make a society (computer network) highly susceptible to large scale outbreaks of infectious diseases (viruses)."
"Stability and Diversity in Collective AdaptationWe derive a class of macroscopic differential equations that describe collective adaptation, starting from a discrete-time stochastic microscopic model. The behavior of each agent is a dynamic balance between adaptation that locally achieves the best action and memory loss that leads to randomized behavior. We show that, although individual agents interact with their environment and other agents in a purely self-interested way, macroscopic behavior can be interpreted as game dynamics. Application to several familiar, explicit game interactions shows that the adaptation dynamics exhibits a diversity of collective behaviors. The simplicity of the assumptions underlying the macroscopic equations suggests that these behaviors should be expected broadly in collective adaptation. We also analyze the adaptation dynamics from an information-theoretic viewpoint and discuss self-organization induced by information flux between agents, giving a novel view of collective adaptation."
"Utilizing Reconfigurable Hardware Processors via Grid ServicesComputational grids typically consist of nodes utilizing ordinary processors such as the Intel Pentium. Field Programmable Gate Arrays (FPGAs) are able to perform certain compute-intensive tasks very well due to their inherent parallel architecture, often resulting in orders of magnitude speedups. This paper explores how FPGAs can be transparently exposed for remote use via grid services, by integrating the Proteus Software Platform with the Globus Toolkit 3.0."
"A robust speaker clustering algorithmIn this paper, we present a novel speaker segmentation and clustering algorithm. The algorithm automatically performs both speaker segmentation and clustering without any prior knowledge of the identities or the number of speakers. Our algorithm uses ""standard"" speech processing components and techniques such as HMMs, agglomerative clustering, and the Bayesian Information Criterion. However, we have combined and modied these so as to produce an algorithm with the following advantages: . No..."
"Time-space modeling of journey-time exposure to traffic-related air pollution using GISJourney-time exposures represent an important, though as yet little-studied, component of human exposure to traffic-related air pollution, potentially with important health effects. Methods for assessing journey-time exposures, either as part of epidemiological studies or for policy assessment, are, however, poorly developed. This paper describes the development and testing of a GIS-based system for modeling human journey-time exposures to traffic-related air pollution: STEMS (Space-Time Exposure Modeling System). The model integrates data on source activity, pollutant dispersion, and travel behavior to derive individual- or group-level exposure measures to atmospheric pollution. The model, which is designed to simulate exposures of people as they move through a changing air pollution field, was developed, validated, and trialed in Northampton, UK. The system currently uses ArcInfo to couple four separate submodels: a source activity/emission model (SATURN), a proprietary atmospheric dispersion model (ADMS-Urban), an empirically derived background air pollution model, and a purposely designed time-activity-based exposure model (TOTEM). This paper describes the structure of the modeling system; presents results of field calibration, validation, and sensitivity analysis; and illustrates the use of the model to analyze journey-time exposures of schoolchildren."
"Coping with Consistency under Multiple Design Constraints: The Case of the Nokia 9000 WWW BrowserConsistency is a commonly accepted but sometimes problematic design goal. External and internal consistency may conflict, and sometimes the best solution is inconsistent in both respects. We describe user interface design issues and several usability studies for the Nokia 9000 Communicator WWW browser and for WWW pages optimized for the browser. The results show how within the same, restricted design domain, various forms of consistency have to be favored over others in solving various design..."
"A Real World Implementation of Answer ExtractionIn this paper we describe ExtrAns, an answer extraction system. Answer extraction (AE) aims at retrieving those exact passages of a document that directly answer a given user question. AE is more ambitious than information retrieval and information extraction in that the retrieval results are phrases, not entire documents, and in that the queries may be arbitrarily specific. It is less ambitious than full-fledged question answering in that the answers are not generated from a knowledge base but ..."
"Systematic and Metasystematic Reasoning: A Case for Levels of Reasoning beyond Piaget's Stage of Formal OperationsModes of cognition are postulated consisting of third- and fourth-order operations; they are hypothesized to be qualitatively distinct from, and hierarchically related to, the form of reasoning characterized as formal operational by Inhelder and Piaget. An instrument was developed to assess these modes of cognition, labeled systematic and metasystematic reasoning, and was administered to 110 undergraduate and graduate students. The results support the assertion that systematic and metasystematic reasoning exist as modes of cognition discrete from, and more complex and powerful than, formal operational reasoning."
"[Hypercholesterolemia and hypertension in Mexico: urban conjunctive consolidation with obesity, diabetes and smoking]AIMS: To know the prevalence and the interaction among the principal cardiovascular risk factors such as hypercholesterolemia (HCL), hypertension (HTA), overweight, carbohydrates metabolism disturbances, and smoking, an urban survey was performed in the six Mexican Republic states, where the national population is more concentrated. METHODS: This survey was transversally designed using the WHO type-III model in 120,005 adults from 6 highly populated urban centers (Mexico City, Guadalajara, León, Puebla, Monterrey andTijuana) were included. A blood sample from each person was obtained to quantify fasting glucose and cholesterol. Blood pressure, height and weight were measured using daily validated systems. Data were analyzed by a multicategorical conjunctive consolidation model and by multiple regression models. RESULTS: HCL global prevalence showed to be 43.3% for a population with an average age of 44.1 years. Female gender showed a slightly but statistically significant greater prevalence of HCL than male gender (44% vs 42.2%). From whole women population 33.2% declared to be in menopause, and 59.7% of them had HCL. In addition, HCL was directly related to body mass index (BMI). Thus, in those subjects with BMI < 25 showed a HCL prevalence 34.1%; while those with BMI was between 25 and 29.9, the HCL prevalence was 45.9%, and in those subjects with BMI > or = 30 Kg/m2, ranked a HCL prevalence of 47.3%. The prevalence of hypertension was 30.2% and 52.5% of them had HCL prevalence. Type-2 diabetes mellitus prevalence (DM-2) was 10.7%, 55.2% of them had HCL. In the group aged between 20 to 34 years old, the obesity was the principal determinant for higher HCL prevalence. The HCL prevalence showed to be quite similar in population with and without smoking. In conclusion, HCL prevalence shows 4 progressively increasing gradients associated with age, HTA, DM-2 and BMI."
"A survey of approaches to automatic schema matchingSchema matching is a basic problem in many database application domains, such as data integration, E-business, data warehousing, and semantic query processing. In current implementations, schema matching is typically performed manually, which has significant limitations. On the other hand, previous research papers have proposed many techniques to achieve a partial automation of the match operation for specific application domains. We present a taxonomy that covers many of these existing..."
"Pulmonary pathology.Common causes of neonatal respiratory distress include meconium aspiration, pneumonia, persistent pulmonary hypertension of the newborn, pneumothorax and cystic adenomatoid malformation. Genomics and proteomics have enabled the recent recognition of several additional disorders that lead to neonatal death from respiratory disease. These are broadly classified as disorders of lung homeostasis and have pathological features of proteinosis, interstitial pneumonitis or lipidosis. These pathological changes result from inherited disorders of surfactant proteins or granulocyte-macrophage colony stimulating factor. Abnormal lung vascular development is the basis for another cause of fatal neonatal respiratory distress, alveolar capillary dysplasia with or without associated misalignment of veins. Diagnosis of these genetically transmitted disorders is important because of the serious implications for future siblings. There is also a critical need for establishing an archival tissue bank to permit future molecular biological studies."
Second generation web services-oriented architecture in production in the finance industry
"Service Chart Diagrams - Description & ApplicationThis paper presents an approach for the design and development of service-driven applications. These applications rely on the collaboration of multiple services that businesses offer to the external community. To ensure that the collaboration of services takes place effectively, service chart diagrams are proposed as a specification technique. These diagrams leverage the traditional state chart diagrams of UML. Furthermore, in service chart diagrams it is advocated that services do not invoke..."
"C-OWL: Contextualizing ontologiesOntologics are shared models of a domain that encode a view which is common to a set of different parties. Contexts are local models that encode a party's subjective view of a domain. In this paper we show how ontologics can be contcxtualizcd, thus acquiring certain useful properties that a pure shared approach cannot provide. We say that an ontology is contcxtualizcd or, also, that it is a contextual ontology, when its contents are kept local, and therefore not shared with other..."
"Software Agent-Oriented Frameworks for Heterogeneous Information AccessIn this paper we propose an approach used to design an interoperable environment for distributed and heterogeneous systems. To overcome such constraints, we suggest to develop software agent-oriented frameworks which provide users with relevant and up-todate data from such systems. We present an application of this approach to the SIGAL project in which we are developing an interoperable environment for georeferenced digital libraries. 1 Introduction With the growing number of information..."
"Towards a Composition Framework for E-/M-ServicesWe present a framework that enables the composition of services for the benefit of users. Two types of services exist: E-services and M-services. Moreover, two types of users exist: static and mobile. The composition framework, software agents and workflows are used."
"Interleaving Web Services Composition and Exectution using Software Agents and DelegationThe paper presents a software agent-based approach that supports the interleaving of Web services composition and execution. A Web service is an accessible application that other applications and humans as well can automatically discover and invoke. Interleaving stands for carrying out the composition and execution of Web services in parallel. This allows handling the execution context of the Web services. Dynamic information that change overtime can feature such a context and require thus, a..."
Agent technologies for m-servicesThe purpose of the Software Agents for MObile Services (SAMOS) project is to understand the role of m-services in the wireless world. M-services are an extension to the paradigm of Web/e-services.
"A Specification Approach to Compose Mobile WebWe present our work on composing mobile Web services, denoted by M-services, in the wireless world. The wireless world has its own features that make it completely different from the wired world. For instance, new communication means need to be deployed, new user-friendly services need to be offered, and new types of specification techniques need to be provided. One of these techniques consists of using service chart diagrams in the specification of a composition process of M-services. A..."
"Enabling Personalized Composition and Adaptive Provisioning of Web ServicesThe proliferation of interconnected computing devices is fostering the emergence of environments where Web services made available to mobile users are a commodity. Unfortunately, inherent limitations of mobile devices still hinder the seamless access to Web services, and their use in supporting complex user activities. In this paper, we describe the design and implementation of a distributed, adaptive, and context-aware framework for personalized service composition and provisioning..."
"International Workshop on Electronic Commerce,State Machines (ASMs) [3] to model business processes is being analyzed, as they present several interesting properties, namely: express functionally complete but abstract description that can be understood by a human reader, define every system features as far as it is semantically relevant for the required functionality and contain only what the logic of the problem requires for the system behavior. Furthermore, the grounding model is implemented following a refinement process, trough ..."
"Selection of Web Services for Composition Using Location of Provider Hosts CriterionWe present a Web service composition approach that relies on three selection criteria: execution cost, execution time, and location of provider hosts. A Web service is an accessible application that can be automatically discovered and invoked by other applications and humans."
"Efficient Peer-to-Peer Keyword SearchingToday, exponential growth in network content makes it difficult to build and maintain a complete document index to support efficient search. Centralized search services must actively and repeatedly probe the network for new or changed content. The scope and rapid evolution of the Internet means that even the best pull-based search services will always be incomplete and inaccurate."
"Adding Relevance to XMLXML query languages proposed so far are limited to Boolean retrieval in the sense that query results are sets of qualifying XML elements or subgraphs. This search paradigm is intriguing for ""closed"" collections of XML documents such as e-commerce catalogs, but we argue that it is inadequate for searching the Web where we would prefer ranked lists of results based on relevance estimation. IR-style Web search engines, on the other hand, are incapable of exploiting the additional information made ..."
"Relevance ranking for One- to Three-Term QueriesWe investigate the application of a novel relevance ranking technique, cover density ranking, to the requirements of Web-based information retrieval, where a typical query consists of a few search terms and a typical result consists of a page indicating several potentially relevant documents. Traditional ranking methods for information retrieval, based on term and inverse document frequencies, have been found to work poorly in this context. Under the cover density measure, ranking is based on..."
"Palmitate-induced Ca2+-signaling in pancreatic beta-cells.Free fatty acids (FFA) have been proposed to participate in the regulation of insulin release from pancreatic beta-cells (beta-cells). As a rise in cytosolic free Ca2+ ([Ca(2+)]i) is a key event for the stimulation of insulin secretion, the effects of saturated FFA on [Ca2+]i were investigated. Palmitate was used as a reference compound and [Ca2+]i was measured in single fura-2 loaded HIT-T15 and in primary mouse beta-cells. Stimulation of single beta-cells with palmitate (100 microM) caused either repetitive Ca2+ transients or a plateau-like rise in [Ca2+]i. In HIT-T15 and in mouse beta-cells, the number of palmitate-responsive cells, and the amplitude of the palmitate-induced Ca2+-signals were dependent on the extracellular glucose concentration. In Ca2+-free medium palmitate (100 microM) caused only 1 or 2 Ca2+ transients indicating mobilization of Ca2+ from internal stores. Withdrawal of external Ca2+, the addition of voltage-sensitive Ca2+ channel (VSCC) blockers, as well as the K(ATP)-channel opener diazoxide (100 microM) reversibly blocked the palmitate-induced cytosolic Ca2+ responses. This demonstrates that Ca2+ influx through VSCC of the L-type coupled to membrane depolarization through closure of K(ATP)-channels are crucial for a sustained Ca2+-signal in response to palmitate. Methyl palmoxirate (100 microM) and 2-bromopalmitate (100 microM), which both inhibit transport of acyl-CoA into the mitochondria, reversibly blocked the palmitate-induced Ca2+-signals in HIT-T15 as well as in primary mouse beta-cells. By contrast, cerulenin (100 microM), an inhibitor of protein acylation, had no effect on the palmitate-induced changes in [Ca2+]i, which suggests that mitochondrial palmitate metabolism is required for eliciting the Ca2+-signals. Simultaneous measurement of [Ca2+]i and the mitochondrial membrane potential (DeltaPsi) revealed palmitate-induced depolarization of DeltaPsi which demonstrates that palmitate does not enhance mitochondrial ATP production. Therefore mitochondrial signals other than ATP appear to be generated from palmitate metabolism that underly the palmitate-induced Ca2+-signals in pancreatic beta-cells."
"Acute and chronic effects of different concentrations of free fatty acids on the insulin secreting function of islets.INTRODUCTION: Lipotoxic effects of free fatty acids (FFAs) on insulin secreting function of islet beta-cells have been demonstrated in recent studies. This toxic effect is especially prominent on postprandial hypertriglyceridemic period. Hypertriglyceridemia and high FFAs levels are the most common metabolic disturbances seen in diabetes mellitus (DM), in particular in uncontrolled cases. AIM OF STUDY: To investigate acute and chronic effects of different concentrations of FFAs on insulin secreting function of pancreas islet beta-cells. MATERIAL AND METHOD: We determined the acute and chronic effects of FFAs on insulin secretion dynamics of isolated rat islets. The insulinotropic effects of four D-glucose concentrations (Nil, 5.6, 8.3 and 27.7 mM) were studied in freshly isolated and perifused islets in the presence of two different concentrations (250 micromol/l and 1,250 micromol/l) of three FFAs (palmitate, stearate and oleate) to determine the acute effects. Chronic effects were investigated similarly on islet cells incubated for 72 hours in the presence of nil, 250 micromol/l and 1,250 micromol/l concentrations of FFAs. RESULTS: There was only a slight increase in insulin secretion at both concentrations of FFAs in freshly isolated islets, and the recovery was complete with a slight decrease in pathologic FFA channel. However, after 72 hour incubation at physiological or higher concentrations of FFAs, insulin secretion was significantly lower, even in the presence of high levels of D-glucose when compared to either nil channel results, or results of the fresh samples. Insulin levels of recovery phase were slightly but significantly lower in physiological and pathologically high FFA conditions when compared to nil condition. In addition, first phase insulin release response was lost in these islets. CONCLUSION: FFAs slightly increased the insulin output of normal fresh pancreas beta-cells. However, chronic exposure to FFAs resulted in loss of first phase insulin release and blunted insulin secretion response to various levels of D-glucose stimulation."
"Pleiotropic effects of fatty acids on pancreatic beta-cells.Hyperlipidemia is frequently associated with insulin resistance states as found in type 2 diabetes and obesity. Effects of free fatty acids (FFA) on pancreatic beta-cells have long been recognized. Acute exposure of the pancreatic beta-cell to FFA results in an increase of insulin release, whereas a chronic exposure results in desensitization and suppression of secretion. We recently showed that palmitate augments insulin release in the presence of non-stimulatory concentrations of glucose. Reduction of plasma FFA levels in fasted rats or humans severely impairs glucose-induced insulin release. These results imply that physiological plasma levels of FFA are important for beta-cell function. Although, it has been accepted that fatty acid oxidation is necessary for its stimulation of insulin secretion, the possible mechanisms by which fatty acids (FA) affect insulin secretion are discussed in this review. Long-chain acyl-CoA (LC-CoA) controls several aspects of the beta-cell function including activation of certain types of protein kinase C (PKC), modulation of ion channels, protein acylation, ceramide- and/or nitric oxide (NO)-mediated apoptosis, and binding to nuclear transcriptional factors. The present review also describes the possible effects of FA on insulin signaling. We showed for the first time that acute exposure of islets to palmitate upregulates the intracellular insulin-signaling pathway in pancreatic islets. Another aspect considered in this review is the source of FA for pancreatic islets. In addition to be exported to the medium, lipids can be transferred from leukocytes (macrophages) to pancreatic islets in co-culture. This process consists an additional source of FA that may plays a significant role to regulate insulin secretion."
"Prolonged exposure to free fatty acids has cytostatic and pro-apoptotic effects on human pancreatic islets: evidence that beta-cell death is caspase mediated, partially dependent on ceramide pathway, and Bcl-2 regulated. In an effort to better understand the phenomenon of lipotoxicity in human beta-cells, we evaluated the effects of 48-h preculture with 1.0 or 2.0 mmol/l free fatty acid (FFA) (2:1 oleate to palmitate) on the function and survival of isolated human islets and investigated some of the possible mechanisms. Compared with control islets, triglyceride content was significantly increased and insulin content and glucose-stimulated insulin release were significantly reduced in islets precultured with increased FFA concentrations. These changes were accompanied by a significant reduction of glucose utilization and oxidation. By cell death detection techniques, it was observed that exposure to FFAs induced a significant increase of the amount of dead cells. Electron microscopy showed the involvement of beta-cells, with morphological appearance compatible with the presence of apoptotic phenomena. FFA-induced islet cell death was blocked by inhibition of upstream caspases and partially prevented by inhibiton of ceramide synthesis or serine protease activity, whereas inhibition of nitric oxide synthesis had no effect. RT-PCR studies revealed no major change of iNOS and Bax mRNA expression and a marked decrease of Bcl-2 mRNA expression in the islets cultured with FFA. Thus, prolonged exposure to FFAs has cytostatic and pro-apoptotic effects on human pancreatic beta-cells. The cytostatic action is likely to be due to the FFA-induced reduction of intraislet glucose metabolism, and the proapoptotic effects are mostly caspase mediated, partially dependent on ceramide pathway, and possibly Bcl-2 regulated. "
"Lipotoxicity in human pancreatic islets and the protective effect of metformin.Human pancreatic islets from eight donors were incubated for 48 h in the presence of 2.0 mmol/l free fatty acid (FFA) (oleate to palmitate, 2 to 1). Insulin secretion was then assessed in response to glucose (16.7 mmol/l), arginine (20 mmol/l), and glyburide (200 micromol/l) during static incubation or by perifusion. Glucose oxidation and utilization and intra-islet triglyceride content were measured. The effect of metformin (2.4 microg/ml) was studied because it protects rat islets from lipotoxicity. Glucose-stimulated but not arginine- or glyburide-stimulated insulin release was significantly lower from FFA-exposed islets. Impairment of insulin secretion after exposure to FFAs was mainly accounted for by defective early-phase release. In control islets, increasing glucose concentration was associated with an increase in glucose utilization and oxidation. FFA incubation reduced both glucose utilization and oxidation at maximal glucose concentration. Islet triglyceride content increased significantly after FFA exposure. Addition of metformin to high-FFA media prevented impairment in glucose-mediated insulin release, decline of first-phase insulin secretion, and reduction of glucose utilization and oxidation without significantly affecting islet triglyceride accumulation. These results show that lipotoxicity in human islets is characterized by selective loss of glucose responsiveness and impaired glucose metabolism, with a clear defect in early-phase insulin release. Metformin prevents these deleterious effects, supporting a direct protective action on human beta-cells."
"Effect of high dietary fat on insulin secretion in genetically diabetic Goto-Kakizaki rats.INTRODUCTION AND AIM: To clarify the effects of a high fat-diet on insulin secretion from genetically diabetic beta cells, Goto-Kakizaki rats and Wistar rats were subjected to oral glucose tolerance test (OGTT) after 12-week high-fat feeding. METHODOLOGY: We compared Wistar and Goto-Kakizaki (GK) rats fed a high-fat diet (45% fat content) for 12 weeks, measuring insulin secretion and insulin release. RESULTS: Insulin secretion during oral glucose tolerance test (OGTT) was enhanced in high-fat diet-fed Wistar rats (WF) with normal glucose tolerance. Insulin secretion in high-fat diet-fed GK rats (GF) during OGTT also was enhanced together with deteriorated glucose tolerance. Basal insulin release from the isolated perfused pancreas at 3.3 m glucose in WF was comparable to that in normal chow-fed Wistar rats (WN), but basal insulin release in GF was remarkably higher than in normal chow-fed GK rats (GN). Stimulated insulin release induced by 16.7 m glucose was remarkably increased in WF compared with WN. Total insulin release at 16.7 m glucose in both GK rat groups was similar and minimal. CONCLUSION: These results indicate that normal pancreatic beta-cells have the ability to secrete sufficient insulin to compensate for the insulin resistance induced by a high-fat diet. In contrast, glucose metabolism in diabetic rats after high-fat diet deteriorated partly because of insufficient insulin secretion caused by genetic defects and lipotoxicity due to chronically high FFA levels."
Open Publishing: How publishers are reacting
"Integrated Semantic-Syntactic Video Modeling for Search and BrowsingVideo processing and computer vision communities usually employ shot-based or object-based structural video models and associate low-level (color, texture, shape, and motion) and semantic descriptions (textual annotations) with these structural (syntactic) elements. Database and information retrieval communities, on the other hand, employ entity-relation (ER) or object-oriented models to model the semantics of multimedia documents. This paper proposes a new generic integrated semantic-syntactic ..."
"New versions of PageRank employing alternative Web document modelsIntroduces several new versions of PageRank (the link based Web page ranking algorithm), based on an information science perspective on the concept of the Web document. Although the Web page is the typical indivisible unit of information in search engine results and most Web information retrieval algorithms, other research has suggested that aggregating pages based on directories and domains gives promising alternatives, particularly when Web links are the object of study. The new algorithms introduced based on these alternatives were used to rank four sets of Web pages. The ranking results were compared with human subjects' rankings. The results of the tests were somewhat inconclusive: the new approach worked well for the set that includes pages from different Web sites; however, it does not work well in ranking pages that are from the same site. It seems that the new algorithms may be effective for some tasks but not for others, especially when only low numbers of links are involved or the pages to be ranked are from the same site or directory."
"How can we understand the construction of an organism?Since a dozen years, biology is in a state of permanent technical and conceptual excitement. The pendulum is swinging back from the selectionist populationist biology of Darwin - the organism is a black box: viewed from the outside - to the mechanistic embryology of Aristotle - viewed from the inside of the organism - leading to a new interpretation of old concepts. This short text tries to get to the meaning of these events by putting them in historical and epistemological perspectives, through such concepts as teleology and differentiation, on the way describing several paradoxes: experimental results yield a detailed description of purposeless mechanical devices, explaining Nature, which, to us, appears purposeful. To cite this article: A. Weydert, C. R. Biologies 327 (2004)."
"Mobile Mapping and Geographic Information SystemsMobile mapping and geographic information systems may represent a new paradigm for cartography and GIScience. This short foreword to the special issue introduces the three papers that follow, briefly surveys the growing literature of field and mobile GIS, and discusses the emerging literature surrounding wearable GIS and their augmented reality display systems. The UCGIS research agenda for mobile and distributed computing is presented, as are the calls for additional research in the papers of the special issue. Calls for a comprehensive review article of the field from a cartography/GIScience perspective, and for involvement in the research agenda of mobile systems, are made."
"Extracting and Visualizing Individual Space-Time Paths: An integration of GIS and KDD in Transport Demand ModelingThe disaggregate activity-based approach for transport demand modeling requires the acquisition, management, analysis, and visualization of very large, multivariate spatial datasets in order to capture and extract meaningful spatio-temporal patterns and relationships. Knowledge Discovery in Databases (KDD) is a conceptual and methodological framework that was developed in the last decade to address the issue of transforming large amounts of raw geographic data into knowledge. Based on the KDD framework, this paper describes the steps involved to build individual space-time paths from an origin-destination survey and presents the functionalities of an object-oriented GIS prototype to extract and dynamically visualize individual space-time paths. The prototype sustains seamless spatio-temporal queries to the database and provides cast-based animation that mimics continuous individual movement on the street network."
"Coherent control with broadband squeezed vacuumWe report the experimental demonstration of coherent control with high power, broadband squeezed vacuum. Although incoherent and exhibiting the statistics of a thermal noise, broadband squeezed vacuum is shown to induce certain two-photon interactions as a coherent ultrashort pulse with the same spectral bandwidth. Utilizing pulse-shaping techniques we coherently control the sum-frequency generation of broadband squeezed vacuum over a range of two orders of magnitude. Coherent control of two-photon interactions with broadband squeezed vacuum can potentially obtain spectral resolutions and extinction ratios that are practically unattainable with coherent pulses."
"Nonlinear interactions with an ultrahigh flux of broadband entangled photonsWe experimentally demonstrate sum-frequency generation (SFG) with entangled photon-pairs, generating as many as 40,000 SFG photons per second, visible even to the naked eye. The nonclassical nature of the interaction is exhibited by a linear intensity-dependence of the nonlinear process. The key element in our scheme is the generation of an ultrahigh flux of entangled photons while maintaining their nonclassical properties. This is made possible by generating the down-converted photons as broadband as possible, orders of magnitude wider than the pump. This approach is readily applicable for other nonlinear interactions, and may be applicable for various quantum-measurement tasks."
"Temporal shaping of entangled photonsWe experimentally demonstrate shaping of the two-photon wavefunction of entangled photon-pairs, utilizing coherent pulse-shaping techniques. By performing spectral-phase manipulations we tailor the two-photon wavefunction exactly like a coherent ultrashort pulse. To observe the shaping we perform sum-frequency generation (SFG) with an ultrahigh flux of entangled photons. At the appropriate conditions, SFG performs as a coincidence detector with an ultrashort response time (~100 fs), enabling a direct observation of the two-photon wavefunction. This property also enables us to demonstrate background-free, high-visibility two-photon interference oscillations."
Inhibition of Decoherence due to Decay in a Continuum We propose a scheme for slowing down decay into a continuum. We make use of a sequence of ultrashort $2π$-pulses applied on an auxiliary transition of the system so that there is a destructive interference between the two transition amplitudes - one before the application of the pulse and the other after the application of the pulse. We give explicit results for a structured continuum. Our scheme can also inhibit unwanted transitions.
"Geodesic active regions and level set methods for motion estimation and trackingMotion analysis in computer vision is a well-studied problem with numerous applications. In particular, the tasks of optical flow estimation and tracking are of increasing interest. In this paper, we propose a level set approach to address both aspects of motion analysis. Our approach relies on the propagation of smooth interfaces to perform tracking while using an incremental estimation of the motion models. Implicit representations are used to represent moving objects, and capture their motion parameters. Information from different sources like a boundary attraction term, a background subtraction component and a visual consistency constraint are considered. The Euler-Lagrange equations within a gradient descent method lead to a flow that deforms a set of initial curve towards the object boundaries as well an incremental robust estimator of their apparent motion. Partial extension of the proposed framework to address dense motion estimation and the case of moving observer is also presented. Promising results demonstrate the performance of the method."
"Organometallic alkane CH activationThe title topic is reviewed with emphasis on catalysis and on recent advances. Alkane Ï complexes, Shilov chemistry and oxidative addition routes are covered. Attention is also given to Ï bond metathesis, surface-bound organometallics and CH activation involving carbene complexes. Closely related reactions of non-alkane substrates such as the Murai reaction are also discussed. The title topic is reviewed with emphasis on catalysis and on recent advances. Alkane Ï complexes, Shilov chemistry and oxidative addition routes are covered. Attention is also given to Ï bond metathesis, surface-bound organometallics and CH activation involving carbene complexes. Closely related reactions of non-alkane substrates such as the Murai reaction are also discussed."
"Progressive TGF-beta1-induced Lung Fibrosis is Blocked by an Orally Active ALK5 Kinase Inhibitor.Pulmonary fibrosis is characterized by chronic scar formation and deposition of extracellular matrix resulting in impaired lung function and respiratory failure. Idiopathic pulmonary fibrosis is associated with pronounced morbidity and mortality, responds poorly to known therapeutic interventions, and there are no known drugs that effectively block or reverse progressive fibrosis. Transforming growth factor beta (TGFbeta) is known to mediate extracellular matrix gene regulation and appears a major player in both the initiation and progression of IPF. TGFbeta mediates its biologic effects through members of a family of activin receptor-like kinases (ALK). We have used a gene transfer model of progressive TGFbeta1 induced pulmonary fibrosis in rats to study a newly described orally active small molecular weight drug that is a potent and selective inhibitor of the kinase activity of ALK5, the specific TGFbeta receptor. We show that the drug inhibits the induction of fibrosis when administered at the time of initiation of fibrogenesis and, most importantly, blocks progressive fibrosis when administered transiently to animals with established fibrosis. These data show promise of the development of an effective therapeutic intervention for Idiopathic Pulmonary Fibrosis and that inhibition of chronic progressive fibrosis may be achieved by blocking TGFbeta receptor activation."
"The Politics of Emerson's Man-Making WordsEmerson's prose speaks to American expectations for becoming a man. His most forceful rhetoric unmans the manly types, particularly his censorious father, with an imperious nonchalance. Emerson's ""man-making words"" also transform the class conflicts that intensified the ideology of manhood from 1825 to 1850. Dreaming of a new elite, Emerson challenges social definitions of manhood and power. He does not, however, question the code that joins manhood with power at the expense of intimacy. When power fails him, as ""Experience"" recounts, his seeming candor masks an evasive note of depressive accusation directed at the women who take care of him. To emphasize Emerson's class and gender politics deflates his reputation somewhat. As ""representative man"" he represents only a liberal tradition that mystifies conflicts. Yet we can see him more clearly as a man, struggling with himself as well as with his time."
"Antimicrobial effect of crude extracts of Nigella sativa on multiple antibiotics-resistant bacteria.Different crude extracts of Nigella sativa were tested for antimicrobial effectiveness against different bacterial isolates. These isolates comprised 16 gramnegative and 6 grampositive representatives. They showed multiple resistance against antibiotics, specially the gramnegative ones. Crude extracts of Nigella saliva showed a promising effect against some of the test organisms. The most effective extracts were the crude alkaloid and water extracts. Gramnegative isolates were affected more than the grampositive ones."
"Cosmic MagnificationI present the current status of the cosmic magnification produced by systematic amplification of background sources by large-scale structures. After introducing its principle, I focus on its interests for cosmology and underline its complementary aspect to cosmic shear and galaxy auto-correlations. I finally discuss recent investigations using higher-order statistics."
"How different is Venus from Mars? The genetics of germ-line stem cells in Drosophila females and males.In the fruit fly Drosophila melanogaster, both spermatogenesis and oogenesis rely on germ-line stem cells (GSCs). Intensive research has revealed many of the molecules and pathways that underlie GSC maintenance and differentiation in males and females. In this review, we discuss new studies that, some differences notwithstanding, highlight the similarities in the structural and molecular strategies used by the two sexes in GSC maintenance and differentiation. These include the tight control that somatic support cells exert on every aspect of GSC function and the similar molecular mechanisms for physical attachment, cell-cell signaling and gap-junction communication. Some common principles underlying GSC biology in the fly may be applied to stem cells in other organisms."
"Toward a comprehensive genetic analysis of male fertility in Drosophila melanogaster.Drosophila melanogaster is a widely used model organism for genetic dissection of developmental processes. To exploit its full potential for studying the genetic basis of male fertility, we performed a large-scale screen for male-sterile (ms) mutations. From a collection of 12,326 strains carrying ethyl-methanesulfonate-treated, homozygous viable second or third chromosomes, 2216 ms lines were identified, constituting the largest collection of ms mutations described to date for any organism. Over 2000 lines were cytologically characterized and, of these, 81% failed during spermatogenesis while 19% manifested postspermatogenic processes. Of the phenotypic categories used to classify the mutants, the largest groups were those that showed visible defects in meiotic chromosome segregation or cytokinesis and those that failed in sperm individualization. We also identified 62 fertile or subfertile lines that showed high levels of chromosome loss due to abnormal mitotic or meiotic chromosome transmission in the male germ line or due to paternal chromosome loss in the early embryo. We argue that the majority of autosomal genes that function in male fertility in Drosophila are represented by one or more alleles in the ms collection. Given the conservation of molecular mechanisms underlying important cellular processes, analysis of these mutations should provide insight into the genetic networks that control male fertility in Drosophila and other organisms, including humans."
"Time as essence for photo browsing through personal digital librariesWe developed two photo browsers for collections with thousands of time-stamped digital images. Modern digital cameras record photo shoot times, and semantically related photos tend to occur in bursts. Our browsers exploit the timing information to structure the collections and to automatically generate meaningful summaries. The browsers differ in how users navigate and view the structured collections. We conducted user studies to compare the two browsers and an un-summarized image browser. Our results show that exploiting the time dimension and appropriately summarizing collections can lead to significant improvements. For example, for one task category, one of our browsers enabled a 33% improvement in speed of finding given images compared to the commercial browser. Similarly, users were able to complete 29% more tasks when using this same browser."
"Understanding and Using ContextContext is a poorly used source of information in our computing environments. As a result, we have an impoverished understanding of what context is and how it can be used. In this paper, we provide an operational definition of context and discuss the different ways in which context can be used by context-aware applications. We also present the Context Toolkit, an architecture that supports the building of these context-aware applications. We discuss the features and abstractions in the toolkit that make the task of building applications easier. Finally, we introduce a new abstraction, a situation which we believe will provide additional support to application designers."
Automatic organization for digital photographs with geographic coordinates
"Translational control of maternal glp-1 mRNA by POS-1 and its interacting protein SPN-4 in Caenorhabditis elegans.The translation of maternal glp-1 mRNAs is regulated temporally and spatially in C. elegans embryos. The 3' UTR (untranslated region) of the maternal glp-1 mRNA is important for both kinds of regulation. The spatial control region is required to suppress translation in the posterior blastomeres. The temporal one is required to suppress translation in oocytes and one-cell stage embryos. We show that a CCCH zinc-finger protein, POS-1, represses glp-1 mRNA translation by binding to the spatial control region. We identified an RNP-type RNA-binding protein, SPN-4, as a POS-1-interacting protein. SPN-4 is present developmentally from the oocyte to the early embryo and its distribution overlaps with that of POS-1 in the cytoplasm and P granules of the posterior blastomeres. SPN-4 binds to a subregion of the temporal control region in the 3' UTR and is required for the translation of glp-1 mRNA in the anterior blastomeres. We propose that the balance between POS-1 and SPN-4 controls the translation of maternal glp-1 mRNA."
"Ramanujan Graphs and the Random Reducibility of Discrete Log on Isogenous Elliptic CurvesCryptographic applications using an elliptic curve over a finite field filter curves for suitability using their order as the primary criterion: e.g. checking that their order has a large prime divisor before accepting it. It is therefore natural to ask whether the discrete log problem (DLOG) has the same difficulty for all curves with the same order; if so it would justify the above practice. We prove that this is essentially true by showing random reducibility of dlog among such curves, assuming the Generalized Riemann Hypothesis (GRH). Our reduction proof works for curves with (nearly) the same endomorphism rings, but it is unclear if such a reduction exists in general. This suggests that in addition to the order, the conductor of its endomorphism ring may play a role. The random self-reducibility for DLOG over finite fields is well known; the non-trivial part here is that one must relate non-isomorphic algebraic groups of two isogenous curves. We construct certain expander graphs with elliptic curves as nodes and low degree isogenies as edges, and utilize the rapid mixing of random walks on this graph. We also briefly look at some recommended curves, compare ""random"" type NIST FIPS 186-2 curves to other special curves from this standpoint, and suggest a parameter to measure how generic a given curve is."
"Quantum strategiesWe consider game theory from the perspective of quantum algorithms. Strategies in classical game theory are either pure (deterministic) or mixed (probabilistic). While not every two-person zero-sum finite game has an equilibrium in the set of pure strategies, von Neumann showed that there is always an equilibrium at which each player follows a mixed strategy. A mixed strategy deviating from the equilibrium strategy cannot increase a player's expected payoff. We show by example, however, that a..."
"Evolution of a Subsumption Architecture NeurocontrollerAn approach to robotics called layered evolution and merging features from the subsumption architecture into evolutionary robotics is presented, and its advantages are discussed. This approach is used to construct a layered controller for a simulated robot that learns which light source to approach in an environment with obstacles. The evolvability and performance of layered evolution on this task is compared to (standard) monolithic evolution, incremental and modularised evolution. To corroborate the hypothesis that a layered controller performs at least as well as an integrated one, the evolved layers are merged back into a single network. On the grounds of the test results, it is argued that layered evolution provides a superior approach for many tasks, and it is suggested that this approach may be the key to scaling up evolutionary robotics."
"Online Interactive Neuro-evolutionIn standard neuro-evolution, a population of networks is evolved in a task, and the network that best solves the task is found. This network is then fixed and used to solve future instances of the problem. Networks evolved in this way do not handle real-time interaction very well. It is hard to evolve a solution ahead of time that can cope effectively with all the possible environments that might arise in the future and with all the possible ways someone may interact with it. This paper..."
"Checkpoints: controls that ensure the order of cell cycle events.The events of the cell cycle of most organisms are ordered into dependent pathways in which the initiation of late events is dependent on the completion of early events. In eukaryotes, for example, mitosis is dependent on the completion of DNA synthesis. Some dependencies can be relieved by mutation (mitosis may then occur before completion of DNA synthesis), suggesting that the dependency is due to a control mechanism and not an intrinsic feature of the events themselves. Control mechanisms enforcing dependency in the cell cycle are here called checkpoints. Elimination of checkpoints may result in cell death, infidelity in the distribution of chromosomes or other organelles, or increased susceptibility to environmental perturbations such as DNA damaging agents. It appears that some checkpoints are eliminated during the early embryonic development of some organisms; this fact may pose special problems for the fidelity of embryonic cell division."
"Toward an Understanding of the Motivation of Open Source Software DevelopersAn Open Source Software (OSS) project is unlikely to be successful unless there is an accompanied community that provides the platform for developers and users to collaborate. Members of such communities are volunteers whose motivation to participate and contribute is of essential importance to the success of OSS projects. In this paper, we aim to create an understanding of what motivates people to participate in OSS communities. We theorize that learning is one of the motivational forces. Our..."
Two supervised learning approaches for name disambiguation in author citations
"Dynamic instability of microtubules as an efficient way to search in spaceDuring the formation of the mitotic spindle, dynamic microtubules search for chromosomes in the surrounding cytosol. The average time required to reach such ""targets"" is calculated within a simple model of dynamic instability. The values of the dynamic parameters that minimize this search time are also obtained. The results approximate well observations of the capture of chromosomes in prometaphase cells. Compared to usual reversible polymerization, dynamic instability reduces the time required to find a target by several orders of magnitude. [Journal Article; In English; United States]"
"Molecular ""vitalism""."
"EvolvabilityEvolvability is an organism’s capacity to generate heritable phenotypic variation. Metazoan evolution is marked by great morphological and physiological diversification, although the core genetic, cell biological, and developmental processes are largely conserved. Metazoan diversification has entailed the evolution of various regulatory processes controlling the time, place, and conditions of use of the conserved core processes. These regulatory processes, and certain of the core processes, have special properties relevant to evolutionary change. The properties of versatile protein elements, weak linkage, compartmentation, redundancy, and exploratory behavior reduce the interdependence of components and confer robustness and flexibility on processes during embryonic development and in adult physiology. They also confer evolvability on the organism by reducing constraints on change and allowing the accumulation of nonlethal variation. Evolvability may have been generally selected in the course of selection for robust, flexible processes suitable for complex development and physiology and specifically selected in lineages undergoing repeated radiations."
"Bibliometrics and beyond: some thoughts on web-based citation analysisThe idea of a unified citation index to the literature of science was first outlined by Eugene Garfield [1] in 1955 in the journal Science. Science Citation Index has since established itself as the gold standard for scientific information retrieval. It has also become the database of choice for citation analysts and evaluative bibliometricians worldwide. As scientific publication moves to the web, and novel approaches to scholarly communication and peer review establish themselves, new methods of citation and link analysis will emerge to capture often liminal expressions of peer esteem, influence and approbation. The web thus affords bibliometricians rich opportunities to apply and adapt their techniques to new contexts and content: the age of bibliometric spectroscopy [2] is dawning."
"Architectures for Java-based bioinformatics applicationsBioinformatics projects are currently under way at numerous universities and in industry. These projects typically involve processing large amounts of biological data and comparison of biological signals or sequences. Much of the existing work in bioinformatics software is based on such languages and platforms as Perl and Unix. This paper, proposes software architectures in Java to support biological applications allowing access of biological data using server-side Java programs on the Internet. The architecture follows the standards of unified modeling language (UML). UML architecture diagrams are presented for the Java-based bioinformatics applications. In addition, an overview of the Bio-Soft project under way at The Biomedical Research Institute (BRI) of the University of Wisconsin-Parkside is provided, which includes research and instructional software for bioinformatics applications."
"Authoritative sources in a hyperlinked environment. The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of contexts on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics,..."
"Trustworthy 100-Year Digital Objects: Durable Encoding for When It's Too Late to AskHow can an author store digital information so that it will be reliably useful, even years later when he is no longer available to answer questions? Methods that might work are not good enough; what is preserved today should be reliably useful whenever someone wants it. Prior proposals fail because they confound saved data with irrelevant details of today's information technology--details that are difficult to define, extract, and save completely and accurately. We use a virtual machine to represent and eventually to render any data whatsoever. We focus on a case of intermediate difficulty--an executable procedure--and identify a variant for every other data type. This solution might be more elaborate than needed to render some text, image, audio, or video data. Simple data can be preserved as representations using well-known standards. We sketch practical methods for files ranging from simple structures to those containing computer programs, treating simple cases here and deferring complex cases for future work. Enough of the complete solution is known to enable practical aggressive preservation programs today."
"How real are real numbers?We discuss mathematical and physical arguments against continuity and in favor of discreteness, with particular emphasis on the ideas of Emile Borel (1871-1956)."
"Network topology of a potential energy landscape: a static scale-free network.Here we analyze the topology of the network formed by the minima and transition states on the potential energy landscape of small clusters. We find that this network has both a small-world and scale-free character. In contrast to other scale-free networks, where the topology results from the dynamics of the network growth, the potential energy landscape is a static entity. Therefore, a fundamentally different organizing principle underlies this behavior: The potential energy landscape is highly heterogeneous with the low-energy minima having large basins of attraction and acting as the highly connected hubs in the network."
"Balance disorders in the elderly and the benefit of balance exercise.Symptoms of balance disorders including 'unsteadiness', 'dizziness and vertigo' are common in the elderly and commonly found in general practice in medicine. There are many causes of balance disorders and vary from one person to another. Disorder of the internal ear or vestibular end-organ type is one cause. Unsteadiness of somato-sensory or proprioception is common in the elderly so is degenerative disorder of central control in brain. The elderly are prone to many chronic illnesses or disorders which are causes of balance disorder or give rise to more rapid degeneration of the central nervous system i.e. high blood pressure, diabetes mellitus, heart disease, proprioception and joint problems, arthritis and muscular weakness due to lack of good health and exercise. The objectives of this research study were to find the etiologies of balance disorders and how Balance Exercises and the 'National Health Service' can be of benefit in helping to prevent them. 1565 elderly inhabitants (age > or = 60 years) of 20 communities adjacent to Siriraj Hospital were selected for study. Among these, 625 persons had a history of balance disorders. Among those, 256 had symptoms during the week selected for examination. The average age was 66 years old, women outnumbered men with a ratio of 2.4:1. The common underlying causes were hypertension in 32.4%, diabetes mellitus 13.8%, arthritis 8.1%, and heart disease 4.4% respectively. All are still taking one or more types of drug. The subjects were randomly divided into two groups for the study purpose of effectiveness of balance exercise. Group 1 did not perform the head balance exercise and Group 2 performed the head balance exercise. Audiometric testing showed impaired hearing in 90% of the subjects. The majority slowed hearing loss in high frequencies. Testing of middle ear function found 75% of Group 1 to have normal middle ear function 77% of Group 2. Brainstem Electrical Response Audiometry (BERA) showed normal response latencies of in 96% of group 1 and 94% of Group 2. Poor morphology of waveform was found in 12% of Group 1 and 16% of Group 2. Doppler sonography for intra-cranial blood flow measurement showed abnormal flow of the ICA in 17.6% of group 1 and 20.16% of group 2. Basilar arterial abnormal flow was found in 77.6% of Group 1 and 80.6% of Group 2 respectively. The flow of ICA was improved after 8 weeks in both groups. The measurement of balance by Posturography showed 86.7% abnormality in Group 1 and 83.5% abnormality in Group 2 (and the majority due to inner ear problems but many cases had a mixture of joints and CNS problems too). Results of the self-evaluation (by questionaires) showed the elderly to have symptoms of light headedness in 51% and loss of balance in 29%, Vertigo with rotation occurred in 23.6%. 49% of the symptoms were intermittent, 56.4% experienced a 'fall"". On questioning about the benefit and performance of Head and Neck Exercises, 82.8% found the exercises were easy to perform, 56.4% said the results were very beneficial."
"Classification of Kinase Inhibitors Using a Bayesian ModelThe use of Bayesian statistics to model both general (multifamily) and specific (single-target) kinase inhibitors is investigated. The approach demonstrates an alternative to current computational methods applied to heterogeneous structure/activity data sets. This approach operates rapidly and is readily modifiable as required. A generalized model generated using inhibitor data from multiple kinase classes shows meaningful enrichment for several specific kinase targets. Such an approach can be used to prioritize compounds for screening or to optimally select compounds from third-party data collections. The observed benefit of the approach is finding compounds that are not structurally related to known actives, or novel targets for which there is not enough information to build a specific kinase model. The general kinase model described was built from a basis of mostly tyrosine kinase inhibitors, with some serine/threonine inhibitors; all the test cases used in prediction were also on tyrosine kinase targets. Confirming the applicability of this technique to other kinase families will be determined once those biological assays become available."
"Similarity searching of chemical databases using atom environment descriptors (MOLPRINT 2D): evaluation of performance.A molecular similarity searching technique based on atom environments, information-gain-based feature selection, and the naive Bayesian classifier has been applied to a series of diverse datasets and its performance compared to those of alternative searching methods. Atom environments are count vectors of heavy atoms present at a topological distance from each heavy atom of a molecular structure. In this application, using a recently published dataset of more than 100000 molecules from the MDL Drug Data Report database, the atom environment approach appears to outperform fusion of ranking scores as well as binary kernel discrimination, which are both used in combination with Unity fingerprints. Overall retrieval rates among the top 5% of the sorted library are nearly 10% better (more than 14% better in relative numbers) than those of the second best method, Unity fingerprints and binary kernel discrimination. In 10 out of 11 sets of active compounds the combination of atom environments and the naive Bayesian classifier appears to be the superior method, while in the remaining dataset, data fusion and binary kernel discrimination in combination with Unity fingerprints is the method of choice. Binary kernel discrimination in combination with Unity fingerprints generally comes second in performance overall. The difference in performance can largely be attributed to the different molecular descriptors used. Atom environments outperform Unity fingerprints by a large margin if the combination of these descriptors with the Tanimoto coefficient is compared. The naive Bayesian classifier in combination with information-gain-based feature selection and selection of a sensible number of features performs about as well as binary kernel discrimination in experiments where these classification methods are compared. When used on a monoaminooxidase dataset, atom environments and the naive Bayesian classifier perform as well as binary kernel discrimination in the case of a 50/50 split of training and test compounds. In the case of sparse training data, binary kernel discrimination is found to be superior on this particular dataset. On a third dataset, the atom environment descriptor shows higher retrieval rates than other 2D fingerprints tested here when used in combination with the Tanimoto similarity coefficient. Feature selection is shown to be a crucial step in determining the performance of the algorithm. The representation of molecules by atom environments is found to be more effective than Unity fingerprints for the type of biological receptor similarity calculations examined here. Combining information prior to scoring and including information about inactive compounds, as in the Bayesian classifier and binary kernel discrimination, is found to be superior to posterior data fusion (in the datasets tested here)."
"Enrichment of Extremely Noisy High-Throughput Screening Data Using a Naive Bayes ClassifierThe noise level of a high-throughput screening (HTS) experiment depends on various factors such as the quality and robustness of the assay itself and the quality of the robotic platform. Screening of compound mixtures is noisier than screening single compounds per well. A classification model based on naive Bayes (NB) may be used to enrich such data. The authors studied the ability of the NB classifier to prioritize noisy primary HTS data of compound mixtures (5 compounds/well) in 4 campaigns in which the percentage of noise presumed to be inactive compounds ranged between 81% and 91%. The top 10% of the compounds suggested by the classifier captured between 26% and 45% of the active compounds. These results are reasonable and useful, considering the poor quality of the training set and the short computing time that is needed to build and deploy the classifier. (Journal of Biomolecular Screening 2004:32-36) 10.1177/1087057103260590"
"Adding semantics to web services standardsWith the increasing growth in popularity of Web services, discovery of relevant Web services becomes a significant challenge. One approach is to develop semantic Web services where by the Web services are annotated based on shared ontologies, and use these annotations for semantics-based discovery of relevant Web services. We discuss one such approach that involves adding semantics to WSDL using DAML+OIL ontologies. Our approach also uses UDDI to store these semantic annotations and search for..."
"Analysis of a Very Large Web Search Engine Query LogIn this paper we present an analysis of an AltaVista Search Engine query log consisting of approximately 1 billion entries for search requests over a period of six weeks. This represents almost 285 million user sessions, each an attempt to fill a single information need. We present an analysis of individual queries, query duplication, and query sessions. We also present results of a correlation analysis of the log entries, studying the interaction of terms within queries. Our data supports the conjecture that web users differ significantly from the user assumed in the standard information retrieval literature. Specifically, we show that web users type in short queries, mostly look at the first 10 results only, and seldom modify the query. This suggests that traditional information retrieval techniques may not work well for answering web search requests. The correlation analysis showed that the most highly correlated items are constituents of phrases. This result indicates it may be useful for search engines to consider search terms as parts of phrases even if the user did not explicitly specify them as such."
"Aspects of plant intelligence.Intelligence is not a term commonly used when plants are discussed. However, I believe that this is an omission based not on a true assessment of the ability of plants to compute complex aspects of their environment, but solely a reflection of a sessile lifestyle. This article, which is admittedly controversial, attempts to raise many issues that surround this area. To commence use of the term intelligence with regard to plant behaviour will lead to a better understanding of the complexity of plant signal transduction and the discrimination and sensitivity with which plants construct images of their environment, and raises critical questions concerning how plants compute responses at the whole-plant level. Approaches to investigating learning and memory in plants will also be considered."
Stereocontrolled total synthesis of (+)-leucascandrolide A.
"Overexpression of leptin receptors in pancreatic islets of Zucker diabetic fatty rats restores GLUT-2, glucokinase, and glucose-stimulated insulin secretion.The high-Km glucose transporter, GLUT-2, and the high-Km hexokinase of beta cells, glucokinase (GK), are required for glucose-stimulated insulin secretion (GSIS). GLUT-2 expression in beta cells of Zucker diabetic fatty (ZDF) rats is profoundly reduced at the onset of beta-cell dysfunction of diabetes. Because ZDF rats are homozygous for a mutation in their leptin receptor (OB-R) gene and are therefore leptin-insensitive, we expressed the wild-type OB-R gene in diabetic islets by infusing a recombinant adenovirus (AdCMV-OB-Rb) to determine whether this reversed the abnormalities. Leptin induced a rise in phosphorylated STAT3, indicating that the transferred wild-type OB-R was functional. GLUT-2 protein rose 17-fold in AdCMV-OB-Rb-treated ZDF islets without leptin, and leptin caused no further rise. GK protein rose 7-fold without and 12-fold with leptin. Preproinsulin mRNA increased 64% without leptin and rose no further with leptin, but leptin was required to restore GSIS. Clofibrate and 9-cis-retinoic acid, the partner ligands for binding to peroxisome proliferator-activator receptor alpha (PPARalpha) and retinoid X receptor, up-regulated GLUT-2 expression in islets of normal rats, but not in ZDF rats, in which PPARalpha is very low. Because the fat content of islets of diabetic ZDF rats remains high unless they are treated with leptin, it appears that restoration of GSIS requires normalization of intracellular nutrient homeostasis, whereas up-regulation of GLUT-2 and GK is leptin-independent, requiring only high expression of OB-Rb."
"Beta-cell lipotoxicity in the pathogenesis of non-insulin-dependent diabetes mellitus of obese rats: impairment in adipocyte-beta-cell relationships.Hyperinsulinemia, loss of glucose-stimulated insulin secretion (GSIS), and peripheral insulin resistance coexist in non-insulin-dependent diabetes mellitus (NIDDM). Because free fatty acids (FFA) can induce these same abnormalities, we studied their role in the pathogenesis of the NIDDM of obese Zucker diabetic fatty (ZDF-drt) rats from 5 weeks of age (before the onset of hyperglycemia) until 14 weeks. Two weeks prior to hyperglycemia, plasma FFA began to rise progressively, averaging 1.9 +/- 0.06 mM at the onset of hyperglycemia (P < 0.001 vs. controls). At this time GSIS was absent and beta-cell GLUT-2 glucose transporter was decreased. The triacylglycerol content of prediabetic islets rose to 10 times that of controls and was correlated with plasma FFA (r = 0.825; P < 0.001), which, in turn, was correlated with the plasma glucose concentration (r = 0.873; P < 0.001). Reduction of hyperlipacidemia to 1.3 +/- 0.07 mM by pair feeding with lean littermates reduced all beta-cell abnormalities and prevented hyperglycemia. Normal rat islets that had been cultured for 7 days in medium containing 2 mM FFA exhibited increased basal insulin secretion at 3 mM glucose, and first-phase GSIS was reduced by 68%; in prediabetic islets, first-phase GSIS was reduced by 69% by FFA. The results suggest a role for hyperlipacidemia in the pathogenesis of NIDDM; resistance to insulin-mediated antilipolysis is invoked to explain the high FFA despite hyperinsulinemia, and sensitivity of beta cells to hyperlipacedemia is invoked to explain the FFA-induced loss of GSIS."
"Relevant term suggestion in interactive web search based on contextual information in query session logsAbstract 10.1002/asi.10256.abs This paper proposes an effective term suggestion approach to interactive Web search. Conventional approaches to making term suggestions involve extracting co-occurring keyterms from highly ranked retrieved documents. Such approaches must deal with term extraction difficulties and interference from irrelevant documents, and, more importantly, have difficulty extracting terms that are conceptually related but do not frequently co-occur in documents. In this paper, we present a new, effective log-based approach to relevant term extraction and term suggestion. Using this approach, the relevant terms suggested for a user query are those that co-occur in similar query sessions from search engine logs, rather than in the retrieved documents. In addition, the suggested terms in each interactive search step can be organized according to its relevance to the entire query session, rather than to the most recent single query as in conventional approaches. The proposed approach was tested using a proxy server log containing about two million query transactions submitted to search engines in Taiwan. The obtained experimental results show that the proposed approach can provide organized and highly relevant terms, and can exploit the contextual information in a user's query session to make more effective suggestions."
A session-based search engine
Agglomerative clustering of a search engine query logAn abstract is not available.
"A hardware implementation of realloc functionThe memory intensive nature of object-oriented languages such as C++ and Java has created the need of a high-performance dynamic memory management. Object-oriented applications often generate higher memory intensity in the heap region. Thus, high-performance memory manager is needed to cope with such applications. As today's VLSI technology advances, it becomes more and more attractive to map basic software algorithms such as malloc( ), free( ), and realloc( ) into hardware. This paper presents a hardware design of realloc function that fully utilizes the advantage of combinational logic. There are two steps needed to complete a reallocation process: (a) try to reallocate on the original memory block and (b) if (a) failed, allocate another memory block and copy the contents of the original block to this new location. In our scheme, (a) can be done in constant time. For (b), the allocation of new memory block and the deallocation of original block are done in constant time. The hardware complexity of proposed scheme (i.e. X-unit, RS-unit, and ESG-unit) is O(n), where n represents the size of bit-map."
"Region-Based Memory ManagementThis paper describes a memory management discipline for programs that perform dynamic memory allocation and de-allocation. At runtime, all values are put into regions. The store consists of a stack of regions. All points of region allocation and deallocation are inferred automatically, using a type and effect based program analysis. The scheme does not assume the presence of a garbage collector. The scheme was first presented by Tofte and Talpin (1994); subsequently, it has been tested in The..."
"Memory Management with Explicit RegionsMuch research has been devoted to studies of and algorithms for memory management based on garbage collection or explicit allocation and deallocation. An alternative approach, region-based memory management, has been known for decades, but has not been wellstudied. In a region-based system each allocation specifies a region, and memory is reclaimed by destroying a region, freeing all the storage allocated therein. We show that on a suite of allocation-intensive C programs, regions are..."
"Language Support for RegionsRegion-based memory management systems structure memory by grouping objects in regions under program control. Memory is reclaimed by deleting regions, freeing all objects stored therein. Our compiler for C with regions, RC, prevents unsafe region deletions by keeping a count of references to each region. Using type annotations that make the structure of a program's regions more explicit, we reduce the overhead of reference counting from a maximum of 27% to a maximum of 11% on a suite of..."
"The role of lipids in the pathogenesis of muscle insulin resistance and beta cell failure in type II diabetes and obesity.This review considers evidence for, and putative mechanisms of, lipid-induced muscle insulin resistance. Acute free fatty acid elevation causes muscle insulin resistance in a few hours, with similar muscle lipid accumulation as accompanies more prolonged high fat diet-induced insulin resistance in rodents. Although causal relations are not as clearcut in chronic human insulin resistant states such as obesity and type 2 diabetes, it is now recognised that muscle lipids also accumulate in these states. The classic Randle glucose-fatty acid cycle is only one of a number of mechanisms by which fatty acids might influence muscle glucose metabolism and insulin action. A key factor is seen to be accumulation of muscle long chain acyl CoAs, which could alter insulin action via several mechanisms including chronic activation of protein kinase C isoforms or ceramide accumulation. These interactions are fundamental to understanding metabolic effects of new insulin ""sensitizers"", e.g. thiazolidinediones, which alter lipid metabolism and improve muscle insulin sensitivity in insulin resistant states. Recent work has also pointed to a possible role of lipids in beta cell deterioration (""lipotoxicity"") associated with type 2 diabetes."
"Reconsidering custom memory allocationProgrammers hoping to achieve performance improvements often use custom memory allocators. This in-depth study examines eight applications that use custom allocators. Surprisingly, for six of these applications, a state-of-the-art general-purpose allocator (the Lea allocator) performs as well as or better than the custom allocators. The two exceptions use regions, which deliver higher performance (improvements of up to 44%). Regions also reduce programmer burden and eliminate a source of memory leaks. However, we show that the inability of programmers to free individual objects within regions can lead to a substantial increase in memory consumption. Worse, this limitation precludes the use of regions for common programming idioms, reducing their usefulness.We present a generalization of general-purpose and region-based allocators that we call reaps. Reaps are a combination of regions and heaps, providing a full range of region semantics with the addition of individual object deletion. We show that our implementation of reaps provides high performance, outperforming other allocators with region-like semantics. We then use a case study to demonstrate the space advantages and software engineering benefits of reaps in practice. Our results indicate that programmers needing fast regions should use reaps, and that most programmers considering custom allocators should instead use the Lea allocator."
On Alternating Sounds
"Malonyl-CoA and long chain acyl-CoA esters as metabolic coupling factors in nutrient-induced insulin secretion.Several approaches were used to test the hypothesis proposing a role for acyl-CoA esters in nutrient-induced insulin release (Prentki, M., and Matschinsky, F. M. (1987) Physiol. Rev. 67, 1185-1248; Corkey, B. E., Glennon, M. C., Chen, K. S., Deeney, J. T., Matschinsky, F. M., and Prentki, M. (1989) J. Biol. Chem. 264, 21608-21612). Exogenous saturated long chain fatty acids markedly potentiated glucose-induced insulin release and elevated long chain acyl-CoA esters in the clonal beta-cell line (HIT). The secretory action depended on the fatty acid chain length, occurred in the range 3-20 microM (free concentration of palmitate), and was reversible and inhibitable by the neuromodulator somatostatin. 2-Bromopalmitate, an inhibitor of carnitine palmitoyl transferase I, suppressed the oxidation of endogenous fatty acids and promoted release of insulin. Only the nutrients or the combination of nutrients that caused secretion elevated malonyl-CoA. The short-chain acyl-CoA profile of HIT cells stimulated by various nutrients was determined in the presence of the nonstimulatory fuel glutamine. Glucose and leucine each provoked similar changes in acyl-CoA compounds. Both secretagogues elevated malonyl-CoA 3-6-fold, whereas succinyl-CoA, free CoASH, acetyl-CoA, and the free CoASH to acetyl-CoA ratio remained unaltered. Furthermore, only when inhibition of fatty acid oxidation was associated with a rise in malonyl-CoA did the total (mitochondrial plus cytoplasmic) content of long chain acyl-CoA esters correlate inversely with insulin release promoted by various nutrients. The results are consistent with the concept that fuel stimuli cause a rise in malonyl-CoA which by inhibiting fatty acid oxidation increase cytosolic long chain acyl-CoA esters. These data provide further support for a model in which malonyl-CoA and long chain acyl-CoAs esters serve as metabolic coupling factors when pancreatic beta-cells are stimulated with glucose and other nutrient secretagogues."
"SMILES, a chemical language and information system. 1. introduction to methodology and encoding rules"
"Uch2/Uch37 is the Major Deubiquitinating Enzyme Associated with the 26S Proteasome in Fission Yeast Conjugation of proteins to ubiquitin plays a central role for a number of cellular processes including endocytosis, DNA repair and degradation by the 26 S proteasome. However, ubiquitination is reversible as a number of deubiquitinating enzymes mediate the disassembly of ubiquitin–protein conjugates. Some deubiquitinating enzymes are associated with the 26 S proteasome contributing to and regulating the particle's activity.Here, we characterise fission yeast Uch2 and Ubp6, two proteasome associated deubiquitinating enzymes. The human orthologues of these enzymes are known as Uch37 and Usp14, respectively. We report that the subunit Uch2/Uch37 is the major deubiquitinating enzyme associated with the fission yeast 26 S proteasome. In contrast, the activity of Ubp6 appears to play a more regulatory and/or structural role involving the proteasome subunits Mts1/Rpn9, Mts2/Rpt2 and Mts3/Rpn12, as Ubp6 becomes essential when activity of these subunits is compromised by conditional mutations.Finally, when the genes encoding Uch2/Uch37 and Ubp6 are disrupted, the cells are viable without showing obvious signs of impaired ubiquitin-dependent proteolysis, indicating that other deubiquitinating enzymes may remedy for the redundancy of these enzymes. "
"Rad23 and Rpn10 serve as alternative ubiquitin receptors for the proteasome.The selective recognition of ubiquitin conjugates by proteasomes is a key step in protein degradation. The receptors that mediate this step have yet to be clearly defined although specific candidates exist. Here we show that the proteasome directly recognizes ubiquitin chains through a specific subunit, Rpn10, and also recognizes chains indirectly through Rad23, a reversibly bound proteasome cofactor. Both binding events can be observed in purified biochemical systems. A block substitution in the chain-binding ubiquitin interacting motif of RPN10 when combined with a null mutation in RAD23 results in a synthetic defect in protein degradation consistent with the view that the direct and indirect recognition modes function to some extent redundantly in vivo. Rad23 and the deubiquitinating enzyme Ubp6 both bind proteasome subunit Rpn1 through N-terminal ubiquitin-like domains. Surprisingly, Rad23 and Ubp6 do not compete with each other for proteasome binding. Thus, Rpn1 may act as a scaffold to assemble on the proteasome multiple proteins that act to either bind or hydrolyze multiubiquitin chains."
"Multiple associated proteins regulate proteasome structure and function.We have identified proteins that are abundant in affinity-purified proteasomes, but absent from proteasomes as previously defined because elevated salt concentrations dissociate them during purification. The major components are a deubiquitinating enzyme (Ubp6), a ubiquitin-ligase (Hul5), and an uncharacterized protein (Ecm29). Ecm29 tethers the proteasome core particle to the regulatory particle. Proteasome binding activates Ubp6 300-fold and is mediated by the ubiquitin-like domain of Ubp6, which is required for function in vivo. Ubp6 recognizes the proteasome base and its subunit Rpn1, suggesting that proteasome binding positions Ubp6 proximally to the substrate translocation channel. ubp6Delta mutants exhibit accelerated turnover of ubiquitin, indicating that deubiquitination events catalyzed by Ubp6 prevent translocation of ubiquitin into the proteolytic core particle."
"RPN4 is a ligand, substrate, and transcriptional regulator of the 26S proteasome: a negative feedback circuit. The RPN4 (SON1, UFD5) protein of the yeast Saccharomyces cerevisiae is required for normal levels of intracellular proteolysis. RPN4 is a transcriptional activator of genes encoding proteasomal subunits. Here we show that RPN4 is required for normal levels of these subunits. Further, we demonstrate that RPN4 is extremely short-lived (t(1/2) approximately 2 min), that it directly interacts with RPN2, a subunit of the 26S proteasome, and that rpn4Delta cells are perturbed in their cell cycle. The degradation signal of RPN4 was mapped to its N-terminal region, outside the transcription-activation domains of RPN4. The ability of RPN4 to augment the synthesis of proteasomal subunits while being metabolically unstable yields a negative feedback circuit in which the same protein up-regulates the proteasome production and is destroyed by the assembled active proteasome. "
"Using C-OWL for the Alignment and Merging of Medical OntologiesA number of sophisticated medical ontologies have been created over the past years. With their development the need for supporting the alignment of different ontologies is gaining importance. We proposed C-OWL, an extension of the Web Ontology Language OWL that supports alignment mappings between different, possibly incompatible ontologies on a semantic level. In this paper we report experiences from using C-OWL for the alignment of medical ontologies. We briefly review key concepts of the..."
"Lessons Learned from Aligning two Representations of AnatomyINTRODUCTION Anatomy is central to the biomedical domain. While macroscopic anatomy is required for the representation of diseases and procedures, subcellular anatomy has become increasingly important for molecular biology. Not only is a sound representation of anatomy fundamental to biomedicine, but the various representations of anatomy currently available also need to be aligned in order to ensure interoperability. This need inspired two groups of researchers to take up the challenge of..."
"The regulatory complex of Drosophila melanogaster 26S proteasomes. Subunit composition and localization of a deubiquitylating enzyme.Drosophila melanogaster embryos are a source for homogeneous and stable 26S proteasomes suitable for structural studies. For biochemical characterization, purified 26S proteasomes were resolved by two-dimensional (2D) gel electrophoresis and subunits composing the regulatory complex (RC) were identified by amino acid sequencing and immunoblotting, before corresponding cDNAs were sequenced. 17 subunits from Drosophila RCs were found to have homologues in the yeast and human RCs. An additional subunit, p37A, not yet described in RCs of other organisms, is a member of the ubiquitin COOH-terminal hydrolase family (UCH). Analysis of EM images of 26S proteasomes-UCH-inhibitor complexes allowed for the first time to localize one of the RC's specific functions, deubiquitylating activity.The masses of 26S proteasomes with either one or two attached RCs were determined by scanning transmission EM (STEM), yielding a mass of 894 kD for a single RC. This value is in good agreement with the summed masses of the 18 identified RC subunits (932 kD), indicating that the number of subunits is complete."
Eigen values and expanders
The Java syntactic extender (JSE)
"A Syntactic Approach to Type SoundnessWe present a new approach to proving type soundness for Hindley/Milner-style polymorphic type systems. The keys to our approach are (1) an adaptation of subject reduction theorems from combinatory logic to programming languages, and (2) the use of rewriting techniques for the specification of the language semantics. The approach easily extends from polymorphic functional languages to imperative languages that provide references, exceptions, continuations, and similar features. We illustrate the ..."
"P-element insertion alleles of essential genes on the third chromosome of Drosophila melanogaster: correlation of physical and cytogenetic maps in chromosomal region 86E-87F.We have established a collection of 2460 lethal or semi-lethal mutant lines using a procedure thought to insert single P elements into vital genes on the third chromosome of Drosophila melanogaster. More than 1200 randomly selected lines were examined by in situ hybridization and 90% found to contain single insertions at sites that mark 89% of all lettered subdivisions of the Bridges' map. A set of chromosomal deficiencies that collectively uncover approximately 25% of the euchromatin of chromosome 3 reveal lethal mutations in 468 lines corresponding to 145 complementation groups. We undertook a detailed analysis of the cytogenetic interval 86E-87F and identified 87 P-element-induced mutations falling into 38 complementation groups, 16 of which correspond to previously known genes. Twenty-one of these 38 complementation groups have at least one allele that has a P-element insertion at a position consistent with the cytogenetics of the locus. We have rescued P elements and flanking chromosomal sequences from the 86E-87F region in 35 lines with either lethal or genetically silent P insertions, and used these as probes to identify cosmids and P1 clones from the Drosophila genome projects. This has tied together the physical and genetic maps and has linked 44 previously identified cosmid contigs into seven ""super-contigs"" that span the interval. STS data for sequences flanking one side of the P-element insertions in 49 lines has identified insertions in the alphagamma element at 87C, two known transposable elements, and the open reading frames of seven putative single copy genes. These correspond to five known genes in this interval, and two genes identified by the homology of their predicted products to known proteins from other organisms."
"Expertise recommender: a flexible recommendation system and architectureLocating the expertise necessary to solve difficult problems is a nuanced social and collaborative problem. In organizations, some people assist others in locating expertise by making referrals. People who make referrals fill key organizational roles that have been identified by CSCW and affiliated research. Expertise locating systems are not designed to replace people who fill these key organizational roles. Instead, expertise locating systems attempt to decrease workload and support people who have no other options. Recommendation systems are collaborative software that can be applied to expertise locating. This work describes a general recommendation architecture that is grounded in a field study of expertise locating. Our expertise recommendation system details the work necessary to fit expertise recommendation to a work setting. The architecture and implementation begin to tease apart the technical aspects of providing good recommendations from social and collaborative concerns."
VideoMAP and VideoSpaceIcon: tools for anatomizing video content
FotoFile: a consumer multimedia organization and retrieval system
Object-oriented units of measurement
Macros that workAn abstract is not available.
"Composable and compilable macros:: you want it when?Many macro systems, especially for Lisp and Scheme, allow macro transformers to perform general computation. Moreover, the language for implementing compile-time macro transformers is usually the same as the language for implementing run-time functions. As a side effect of this sharing, implementations tend to allow the mingling of compile-time values and run-time values, as well as values from separate compilations. Such mingling breaks programming tools that must parse code without executing it. Macro implementors avoid harmful mingling by obeying certain macro-definition protocols and by inserting phase-distinguishing annotations into the code. However, the annotations are fragile, the protocols are not enforced, and programmers can only reason about the result in terms of the compiler's implementation. MzScheme---the language of the PLT Scheme tool suite---addresses the problem through a macro system that separates compilation without sacrificing the expressiveness of macros."
"Lambda, the ultimate label or a simple optimizing compiler for Scheme"
"Assessing Agreement on Classification Tasks: The Kappa StatisticIntroduction Computational linguistic and cognitive science work on discourse and dialogue relies on subjective judgments. For instance, much current research on discourse phenomena distinguishes between behaviours which tend to occur at or around discourse segment boundaries and those which do not (PL93; KID92; LH90; Cah92). Although in some cases discourse segments are defined automatically (e.g., Rodrigues and Lopes' (RL92) definition based on temporal relationships), more usually discourse ..."
"Next-Generation Content Representation, Creation and Searching for New-Media Applications in EducationContent creation, editing, and searching are extremely time consuming tasks that often require substantial training and experience, especially when high-quality audio and video are involved. ""New media"" represents a new paradigm for multimedia information representation and processing, in which the emphasis is placed on the actual content. It thus brings the tasks of content creation and searching much closer to actual users and enables them to be active producers of audiovisual information..."
"SILVER: Simplifying Video Editing With MetadataDigital video is becoming increasingly ubiquitous. However, editing video remains difficult for several reasons: it is a time-based medium, it has dual tracks of audio and video, and current tools force users to work at the smallest level of detail. Based on interviews with professional video editors, we developed a video editor, called Silver, that uses metadata to make digital video editing more accessible to novices. To help users visualize video, Silver provides multiple views with..."
"Automatic and dynamic identification of metadata in multimediaMultimedia data (video, audio, images) are now in widespread use and require radically new techniques for indexing and searching. Multimedia data consists of two components: the raw data itself and semantic information (metadata) contained in the data. Unfortunately, the metadata needed for indexing is not directly accessible, and must first be identified. Because of the voluminous amount of multimedia information, automated techniques must be used for semantic identification. Fortunately, ..."
"Deoxyribozyme-based half-adder.We have constructed a solution-phase array of three deoxyribozyme-based logic gates that behaves as a half-adder. Two deoxyribozymes mimic i(1)ANDNOTi(2) and i(2)ANDNOTi(1) gates that cleave a fluorogenic substrate, reporting through an increase in fluorescence emission at 570 nm. The third deoxyribozyme mimics an i(1)ANDi(2) gate and cleaves the other fluorogenic substrate, reporting through an increase in fluorescence emission at 520 nm. Together, this system represents the first example of a decision-making enzymatic network with two inputs and two outputs. Similar systems could be applied to control autonomous therapeutic and diagnostic devices."
"A deoxyribozyme-based molecular automatonWe describe a molecular automaton, called MAYA, which encodes a version of the game of tic-tac-toe and interactively competes against a human opponent. The automaton is a Boolean network of deoxyribozymes that incorporates 23 molecular-scale logic gates and one constitutively active deoxyribozyme arrayed in nine wells (3×3) corresponding to the game board. To make a move, MAYA carries out an analysis of the input oligonucleotide keyed to a particular move by the human opponent and indicates a move by fluorescence signaling in a response well. The cycle of human player input and automaton response continues until there is a draw or a victory for the automaton. The automaton cannot be defeated because it implements a perfect strategy."
"Microarrays of small molecules embedded in biodegradable polymers for use in mammalian cell-based screens.We developed a microarray-based system for screening small molecules in mammalian cells. This system is compatible with image-based screens and requires fewer than 100 cells per compound. Each compound is impregnated in a 200-microm-diameter disc composed of biodegradable poly-(D),(L)-lactide/glycolide copolymer. Cells are seeded on top of these discs, and compounds slowly diffuse out, affecting proximal cells. In contrast with microtiter-based screening, this system does not involve the use of wells or walls between each compound-treated group of cells. We demonstrate detection of the effects of a single compound in a large microarray, that diverse compounds can be released in this format, and that extended release over several days is feasible. We performed a small synthetic lethal screen and identified a compound (macbecin II) that has reduced activity in cells with RNA interference-mediated decrease in the expression of tuberous sclerosis 2. Thus, we have developed a microarray-based screening system for testing the effects of small molecules on mammalian cells by using an imaging-based readout. This method will be useful to those performing small-molecule screens to discover new chemical tools and potential therapeutic agents."
"Goodness-of-fit of the Heston modelAn analytical formula for the probability distribution of stock-market returns, derived from the Heston model assuming a mean-reverting stochastic volatility, was recently proposed by Dragulescu and Yakovenko in Quantitative Finance 2002. While replicating their results, we found two significant weaknesses in their method to pre-process the data, which cast a shadow over the effective goodness-of-fit of the model. We propose a new method, more truly capturing the market, and perform a Kolmogorov-Smirnov test and a Chi Square test on the resulting probability distribution. The results raise some significant questions for large time lags -- 40 to 250 days -- where the smoothness of the data does not require such a complex model; nevertheless, we also provide some statistical evidence in favour of the Heston model for small time lags -- 1 and 5 days -- compared with the traditional Gaussian model assuming constant volatility."
Inductive Inference: Theory and MethodsNote: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.
Refactoring object-oriented frameworks
Automatic inheritance hierarchy restructuring and method refactoring
"Object-oriented programming: an objective sense of styleWe introduce a simple, programming language independent rule (known in-house as the Law of Demeter™) which encodes the ideas of encapsulation and modularity in an easy to follow form for the object-oriented programmer. You tend to get the following related benefits when you follow the Law of Demeter while minimizing simultaneously code duplication, the number of method arguments and the number of methods per class: Easier software maintenance, less coupling between your methods, better information hiding, narrower interfaces, methods which are easier to reuse, and easier correctness proofs using structural induction. We discuss two important interpretations of the Law (strong and weak) and we prove that any object-oriented program can be transformed to satisfy the Law. We express the Law in several languages which support object-oriented programming, including Flavors, Smalltalk-80, CLOS, C++ and Eiffel."
From objects to classes: algorithms for optimal objection-oriented design
"Refactoring Object-Oriented FrameworksThis thesis defines a set of program restructuring operations (refactorings) that support the design, evolution and reuse of object-oriented application frameworks. The focus of the thesis is on automating the refactorings in a way that preserves the behavior of a program. The refactorings are defined to be behavior preserving, provided that their preconditions are met. Most of the refactorings are simple to implement and it is almost trivial to show that they are behavior preserving. However,..."
Impact of configuration errors on DNS robustness
"A thymic precursor to the NK T cell lineage.CD1d-restricted autoreactive natural killer (NK1.1+) T cells function as regulatory cells in various disease conditions. Using improved tetramer tracking methodology, we identified a NK1.1- thymic precursor and followed its differentiation and emigration to tissues by direct cell transfer and in situ cell labeling studies. A major lineage expansion occurred within the thymus after positive selection and before NK receptor expression. Surprisingly, cytokine analysis of the developmental intermediates between NK and NK+ stages showed a T helper cell TH2 to TH1 conversion, suggesting that the regulatory functions of NK T cells may be developmentally controlled. These findings characterize novel thymic and postthymic developmental pathways that expand autoreactive cells and differentiate them into regulatory cells."
Direction and Scope of Comprehension-Related Activities by Procedural and Object-Oriented Programmers: An Empirical Study
"Integration of a membrane-based desalting step in a microfabricated disposable polymer injector for mass spectrometric protein analysis.A simple desalting procedure for the coupling of a polymer microchip injector to mass spectrometry is proposed. The overall process is based on the adsorption of proteins on a poly(vinylidene difluoride) (PVDF) membrane, which are then directly eluted in the spraying solution. This microchip-based approach has been successfully applied to small drugs, peptides and proteins originally diluted in phosphate-buffered saline (PBS). Moreover, when eluting the retained proteins in small volumes, a preconcentration is obtained. The combination of single-use, mass-produceable, low-sample-consumption, easy-to-automate, miniaturized polymer injectors with easy-to-handle solution-exchange membranes makes this system particularly amenable to screening applications."
"Change impact analysis for object-oriented programsSmall changes can have major and nonlocal effects in object-oriented languages, due to the use of subtyping and dynamic dispatch. This complicates life for maintenance programmers, who need to fix bugs or add enhancements to systems originally written by others. Change impact analysis provides feedback on the semantic impact of a set of program changes. This analysis can be used to determine the regression test drivers that are affected by a set of changes. Moreover, if a test fails, a subset of changes responsible for the failure can be identified, as well as a subset of changes that can be incorporated safely without affecting any test driver."
"Biologic and physical fractionation effects of random geometric errors. We are developing a system to model the effect of random and systematic geometric errors on radiotherapy delivery. The purpose of this study was to investigate biologic and physical fractionation effects of random geometric errors and respiration motion and compare the resulting dose distributions with Gaussian blurring of the planned dose. A hypothetical dose distribution with Gaussian penumbra was used. Random errors drawn from a normal distribution, optionally combined with simulated respiration motion (in the cranio-caudal direction), were used to displace the dose distribution for N simulated fractions. To simulate biologic effects of fractionation, the physical dose was converted to a biologically effective dose using the linear-quadratic model (including repopulation), then summed and converted back to physical dose for comparison. Differences between dose distributions were quantified in terms of the distance between selected isodose levels. A limited number of fractions led to an uncertainty in the position of isodose levels in the total dose with as standard deviation (SD) the SD of the random error divided by radical N. Due to biologic fractionation effects, the total dose distribution became slightly wider: 0.4 mm for alpha/beta = 1 Gy and a random error SD of 3 mm. The widening increased with random error and reduced with increasing alpha/beta but does not depend on the number of fractions or on repopulation. Respiration motion caused an asymmetric deviation in the shape of the total dose distribution, but no additional dose widening was seen from the biologic effect of fractionation. With a random error SD of 3 mm and respiration amplitude, A, of 1 cm or less (SD < 0.36 cm), the asymmetry was negligible. For larger respiration amplitudes (combined with the same random error), the shift of the 95% isodose level was about 0.25*A caudally, and 0.45*A cranially. Gaussian blurring with a combined SD of organ motion, setup error, and respiration motion is a valid approximation for the effect of purely random errors in fractionated radiotherapy. For respiration motion in excess of 1 cm in amplitude, isodose lines shift in a distinctly asymmetric fashion and asymmetric margins need to be used. "
"Precise and real-time measurement of 3D tumor motion in lung due to breathing and heartbeat, measured during radiotherapy. In this work, three-dimensional (3D) motion of lung tumors during radiotherapy in real time was investigated. Understanding the behavior of tumor motion in lung tissue to model tumor movement is necessary for accurate (gated or breath-hold) radiotherapy or CT scanning. Twenty patients were included in this study. Before treatment, a 2-mm gold marker was implanted in or near the tumor. A real-time tumor tracking system using two fluoroscopy image processor units was installed in the treatment room. The 3D position of the implanted gold marker was determined by using real-time pattern recognition and a calibrated projection geometry. The linear accelerator was triggered to irradiate the tumor only when the gold marker was located within a certain volume. The system provided the coordinates of the gold marker during beam-on and beam-off time in all directions simultaneously, at a sample rate of 30 images per second. The recorded tumor motion was analyzed in terms of the amplitude and curvature of the tumor motion in three directions, the differences in breathing level during treatment, hysteresis (the difference between the inhalation and exhalation trajectory of the tumor), and the amplitude of tumor motion induced by cardiac motion. The average amplitude of the tumor motion was greatest (12 +/- 2 mm [SD]) in the cranial-caudal direction for tumors situated in the lower lobes and not attached to rigid structures such as the chest wall or vertebrae. For the lateral and anterior-posterior directions, tumor motion was small both for upper- and lower-lobe tumors (2 +/- 1 mm). The time-averaged tumor position was closer to the exhale position, because the tumor spent more time in the exhalation than in the inhalation phase. The tumor motion was modeled as a sinusoidal movement with varying asymmetry. The tumor position in the exhale phase was more stable than the tumor position in the inhale phase during individual treatment fields. However, in many patients, shifts in the exhale tumor position were observed intra- and interfractionally. These shifts are the result of patient relaxation, gravity (posterior direction), setup errors, and/or patient movement.The 3D trajectory of the tumor showed hysteresis for 10 of the 21 tumors, which ranged from 1 to 5 mm. The extent of hysteresis and the amplitude of the tumor motion remained fairly constant during the entire treatment. Changes in shape of the trajectory of the tumor were observed between subsequent treatment days for only one patient. Fourier analysis revealed that for 7 of the 21 tumors, a measurable motion in the range 1-4 mm was caused by the cardiac beat. These tumors were located near the heart or attached to the aortic arch. The motion due to the heartbeat was greatest in the lateral direction. Tumor motion due to hysteresis and heartbeat can lower treatment efficiency in real-time tumor tracking-gated treatments or lead to a geographic miss in conventional or active breathing controlled treatments. The real-time tumor tracking system measured the tumor position in all three directions simultaneously, at a sampling rate that enabled detection of tumor motion due to heartbeat as well as hysteresis. Tumor motion and hysteresis could be modeled with an asymmetric function with varying asymmetry. Tumor motion due to breathing was greatest in the cranial-caudal direction for lower-lobe unfixed tumors. "
"Sensitivity of treatment plan optimisation for prostate cancer using the equivalent uniform dose (EUD) with respect to the rectal wall volume parameter.BACKGROUND AND PURPOSE: To analyse the sensitivity of plan optimisation of prostate cancer treatments with respect to changes in the volume parameter (n), when the EUD is used to control the dose in the rectal wall. PATIENTS AND METHODS: A series of plans was defined, by varying n over a range between 0.08 and 1, and testing different cost functions and beam arrangements. In all cases, the aim was to minimise the EUD in the rectal wall, while ensuring specific dose coverage of the PTV, and limiting the dose in the other OARs. The results were evaluated in terms of 3-D dose distribution and with respect to the current clinical knowledge about late rectal toxicity after irradiation. RESULTS: Different values of n lead to very similar dose distributions over the PTV (differences in mean dose <1Gy, differences in dose given to 99% of the volume <1%). For the rectal wall, the following observations were made: (a) all cumulative DVH curves crossed each other around 60Gy; (b) the rectal wall volume receiving doses between 30 and 45Gy could change by 45 and 30%, respectively, depending on the value of n; (c) for doses higher than 70Gy the differences were typically within 5%. Different values of n also affected the position of isodose surfaces. The distance between the 70 and the 30Gy isodose curves changed in the AP direction by a factor of 3 when n decreased from 1 to 0.08. High values of n were associated with less dose conformity and a larger volume (at least 20%) of normal tissues receiving 50Gy or more. All DVHs for the rectal wall were below published dose toxicity thresholds except when the prescribed dose was escalated up to 86Gy. CONCLUSIONS: In most cases, the solutions associated with n values up to 0.25 produced similar dose distribution in the rectal wall for doses above 45Gy, complying with the dose-toxicity thresholds we analysed. The choice of a specific value of n in the optimisation requires an analysis of its effects on the dose distribution for the rectal wall, but also on other aspects, such as the value of the dose to the non-involved normal tissues."
"Simplified intensity-modulated radiotherapy using pre-defined segments to reduce cardiac complications in left-sided breast cancer.BACKGROUND AND PURPOSE: Left-sided breast cancer patients pose a difficult clinical challenge when significant heart and contralateral breast irradiation are present, particularly with tangential uniform beams. The aims of the study are: (1) to design and evaluate a simplified intensity-modulated radiotherapy (IMRT) (SI) solution using pre-defined segments, (2) to compare the SI technique with a conformal (CN) and a full fluence IMRT (FI) approach using two sets of beam orientations, clinical (-C) and optimal (-O), and (3) to quantify the benefits of treatment technique and beam orientation. PATIENTS AND METHODS: Nine left-sided breast cancer patients with a maximum heart distance of at least 2.0 cm were planned using three different techniques and two different beam orientations. All three techniques were planned using clinical orientations (i.e. CN-C, FI-C and SI-C). Two techniques were planned using more optimal orientations (i.e. FI-O and SI-O). Dose-volume histograms and radiobiologic modelling are used for plan evaluation. RESULTS: The average mean planning target volume (PTV) doses are 91.6+/-4.5, 98.4+/-6.3, 102.0+/-8.7, 100.0+/-5.9 and 103.9+/-8.3% for the CN-C, FI-C, SI-C, FI-O and SI-O plans, respectively. The average normal tissue complication probabilities for late excess cardiac mortality are 2.1+/-0.6, 0.2+/-0.1, 0.2+/-0.1, 0.1+/-0.0 and 0.1+/-0.0%, respectively. For a given beam orientation, FI plans are the best and CN plans are the worst. The dose distributions for the SI-C and FI-C plans are almost identical with significant heart sparing but at a cost of some target underdosage. The dose distributions are better conformed around the PTV with more optimal beam orientations, resulting in better sparing of adjacent organs at risk. FI-C plans are inferior to SI-O plans. CONCLUSIONS: For clinical uniform two-beam orientations, significant heart sparing is possible with the addition of intensity modulation but at the expense of worsening target coverage. Simplified IMRT can, for all intents, be substituted for full IMRT with clinical beam orientations. Applying more optimal non-uniform beam orientations improves PTV coverage while maintaining significant heart sparing but increases the PTV dose heterogeneity."
"Comparison between manual and automatic segment generation in step-and-shoot IMRT of prostate cancer.PURPOSE: To compare two methods to generate treatment plans for intensity-modulated radiotherapy (IMRT) of prostate cancer, delivered in a step-and-shoot mode. The first method uses fluence optimization (inverse planning) followed by conversion of the fluence weight map into a limited number of segments. In the second method, segments are manually assigned using a class solution (forward planning), followed by computer optimization of the segment weights. METHODS: Treatment plans for IMRT, utilizing a simultaneous integrated boost, were created. Plans comprise a five-field technique to deliver 78 Gy to the prostate plus seminal vesicles. Five patients were evaluated. Optimization objectives of both planning approaches concerned dose coverage of the target volumes and the dose distribution in the rectal wall. The two methods were evaluated by comparing dose distributions, the complexity of the resulting plan and the time expenditure to generate and to deliver the plan. RESULTS: For both planning approaches 99% of the target volumes received 95% of the prescribed dose, which complies with our planning objectives. Inverse planning resulted in more conformal dose distributions than forward planning (conformity index: 1.37 versus 1.51). Inverse planning reduced the dose to the rectal wall compared to a manually designed plan, albeit to a small extent. The theoretical probability of severe rectal proctitis and/or stenosis was reduced on average by 1.9% with inverse planning. Maximal sparing of the rectal wall was achieved with inverse planning for a patient whose target volume was partly wrapped around the rectum. The number of segments generated with inverse planning ranged between 33 and 52, and between 9 and 13 segments for manually created segments. CONCLUSION: Dose coverage of the planning target volumes is adequate for both approaches of planning. Inverse planning results in slightly better dose distributions with respect to the rectal wall compared to manual planning, at the cost of an increase of the number of segments by a factor of 3."
"Importance of accurate dose calculations outside segment edges in intensity modulated radiotherapy treatment planning.BACKGROUND AND PURPOSE: To assess the effect of differences in the calculation of the dose outside segment edges on the overall dose distribution and the optimisation process of intensity modulated radiation therapy (IMRT) treatment plans. PATIENTS AND METHODS: Accuracy of dose calculations of two treatment planning systems (TPS1 and TPS2) was assessed, to ensure that they are both suitable for IMRT treatment planning according to published guidelines. Successively, 10 treatment plans for patients with prostate and head and neck tumours were calculated in both systems. The calculations were compared in selected points as well as in combination with volumetric parameters concerning the planning target volume (PTV) and organs at risk. RESULTS: For both planning systems, the calculations agree within 2.0% or 3 mm with the measurements in the high-dose region for single and multiple segment dose distributions. The accuracy of the dose calculation is within the tolerances proposed by recent recommendations. Below 35% of the prescribed dose, TPS1 overestimates and TPS2 underestimates the measured dose values, TPS2 being closer to the experimental data. The differences between TPS1 and TPS2 in the calculation of the dose outside segments explain the differences (up to 50% of the local value) found in point dose comparisons. For the prostate plans, the discrepancies between the TPS do not translate into differences in PTV coverage, normal tissue complication probability (NTCP) values and results of the plan optimisation process. The dose-volume histograms (DVH) of the rectal wall differ below 60 Gy, thus affecting the plan optimisation if a cost function would operate in this dose region. For the head and neck cases, the two systems give different evaluations of the DVH points for the PTV (up to 22% differences in target coverage) and the parotid mean dose (1.0-3.0 Gy). Also the results of the optimisation are influenced by the choice of the dose calculation algorithm. CONCLUSIONS: In IMRT, the accuracy of the dose calculation outside segment edges is important for the determination of the dose to both organs at risks and target volumes and for a correct outcome of the optimisation process. This aspect should therefore be of major concern in the commissioning of a TPS intended for use in IMRT. Fulfilment of the accuracy criteria valid for conformal radiotherapy is not sufficient. Three-dimensional evaluation of the dose distribution is needed in order to assess the impact of dose calculation accuracy outside the segment edges on the total dose delivered to patients treated with IMRT."
"A comparison of forward and inverse treatment planning for intensity-modulated radiotherapy of head and neck cancer.BACKGROUND AND PURPOSE: To compare intensity-modulated treatment plans of patients with head and neck cancer generated by forward and inverse planning. MATERIALS AND METHODS: Ten intensity-modulated treatment plans, planned and treated with a step&shoot technique using a forward planning approach, were retrospectively re-planned with an inverse planning algorithm. For this purpose, two strategies were applied. First, inverse planning was performed with the same beam directions as forward planning. In addition, nine equidistant, coplanar incidences were used. The main objective of the optimisation process was the sparing of the parotid glands beside an adequate treatment of the planning target volume (PTV). Inverse planning was performed both with pencil beam and Monte Carlo dose computation to investigate the influence of dose computation on the result of the optimisation. RESULTS: In most cases, both inverse planning strategies managed to improve the treatment plans distinctly due to a better target coverage, a better sparing of the parotid glands or both. A reduction of the mean dose by 3-11Gy for at least one of the parotid glands could be achieved for most of the patients. For three patients, inverse planning allowed to spare a parotid gland that had to be sacrificed by forward planning. Inverse planning increased the number of segments compared to forward planning by a factor of about 3; from 9-15 to 27-46. No significant differences for PTV and parotid glands between both inverse planning approaches were found. Also, the use of Monte Carlo instead of pencil beam dose computation did not influence the results significantly. CONCLUSION: The results demonstrate the potential of inverse planning to improve intensity-modulated treatment plans for head and neck cases compared to forward planning while retaining clinical utility in terms of treatment time and quality assurance."
"A Fast Elitist Non-Dominated Sorting Genetic Algorithm for Multi-Objective Optimization: NSGA-IIMulti-objective evolutionary algorithms which use non-dominated sorting and sharing have been mainly criticized for their (i) -4 computational complexity (where  is the number of objectives and is the population size), (ii) non-elitism approach, and (iii) the need for specifying a sharing parameter. In this paper, we suggest a non-dominated sorting based multi-objective evolutionary algorithm (we called it the Non-dominated Sorting GA-II or NSGA-II) which alleviates all..."
"Imperative Functional ProgrammingWe present a new model, based on monads, for performing input/output in a non-strict, purely functional language. It is composable, extensible, efficient, requires no extensions to the type system, and extends smoothly to incorporate mixed-language working and in-place array updates. 1 Introduction Input/output has always appeared to be one of the less satisfactory features of purely functional languages: fitting action into the functional paradigm feels like fitting a square block into a round ..."
"Auditory cues support place navigation in rats when associated with a visual cue.Rats, like other crepuscular animals, have excellent auditory capacities and they discriminate well between different sounds [Heffner HE, Heffner RS, Hearing in two cricetid rodents: wood rats (Neotoma floridana) and grasshopper mouse (Onychomys leucogaster). J Comp Psychol 1985;99(3):275-88]. However, most experimental literature concerning spatial orientation almost exclusively emphasizes the use of visual landmarks [Cressant A, Muller RU, Poucet B. Failure of centrally placed objects to control the firing fields of hippocampal place cells. J Neurosci 1997;17(7):2531-42; and Goodridge JP, Taube JS. Preferential use of the landmark navigational system by head direction cells in rats. Behav Neurosci 1995;109(1):49-61]. To address the important issue of whether rats are able to achieve a place navigation task relative to auditory beacons, we designed a place learning task in the water maze. We controlled cue availability by conducting the experiment in total darkness. Three auditory cues did not allow place navigation whereas three visual cues in the same positions did support place navigation. One auditory beacon directly associated with the goal location did not support taxon navigation (a beacon strategy allowing the animal to find the goal just by swimming toward the cue). Replacing the auditory beacons by one single visual beacon did support taxon navigation. A multimodal configuration of two auditory cues and one visual cue allowed correct place navigation. The deletion of the two auditory or of the one visual cue did disrupt the spatial performance. Thus rats can combine information from different sensory modalities to achieve a place navigation task. In particular, auditory cues support place navigation when associated with a visual one."
"Library services to distant students: An equity issueThis article reviews the reasons for providing library services to off-campus/distance education students, discusses changing accreditation guidelines as they relate to off-campus and multi-campus programs, and provides an overview of several models of service and issues for consideration."
